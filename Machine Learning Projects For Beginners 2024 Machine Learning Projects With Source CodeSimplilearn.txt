hello everyone welcome to Simply learns
YouTube channel today we will learn
machine learning projects with source
code that said if these are the types of
videos you would like to watch then hit
the like And subscribe button and the
bell icon to get notified and just a
quick info for you if you want to
upscale yourself master artificial
intelligence and machine learning skills
and learn your dream job or grow in your
then you must explore simply learn's
cohort of various a ml programs simply
learn offers various certification and
postgraduate programs in collaboration
with some of the world's leading
universities like won Purdue keltech I
kpur and many more through our courses
you will gain knowledge and work ready
expertise and skills like generative AI
promt engineering explainable AI machine
learning algorithms and over a dozen
others and that's not all you also get
the opportunity to work on multiple
projects and learn from industry experts
working in top typ product companies and
academicians from top universities after
completing these courses thousands of
Learners have transitioned into an AI or
ml role as a fresher or moved on to a
higher paying job and profile if you are
passionate about making your career in
this field then make sure to check out
the link in the pin command and
description box to find an AI n ml
program that fits your experience and
areas of Interest the ideal way to
display your machine learning is in the
form of portfolio of data science and
machine learning projects a solid
portfolio of projects will illustrate
that you can utilize those machine
learning skills in your profile as well
projects like movie decementation system
fake news detection and many more are
the best way to improve your early
programming skills you may have the
knowledge but putting it to use what is
keep you competitive here are 10 machine
learning projects that can increase your
portfolio and enable you to acquire a
job as a machine learning engineer at
number 10 we have loan approval
prediction system in this machine
learning project we will analyze and
make prediction about the loan approval
process of any person this is a
classification problem in which we must
determine whether or not the loan will
be approved a classification problem is
a predictive modeling problem that
predict a class label for a given
example of input data some
classification problem include spam
email cancer detection sentiment
analysis and many more you can check the
project link from the description box
below to understand classification
problem and how to build a loan
prediction system at number nine we have
fake news detection system do you
believe in everything you read in social
media is it true that not all news is
true but how will you recognize fake
news ml is the answer you will able to
tell the difference between real and
fake news by practicing this project of
detecting fake news this ml project for
detecting fake news is concerned with
the fake news and the true news on our
data set we create a tfid vectorizer
with escalan the model is then fitted
using a passive aggressive classifier
that has been initialized finally the
accuracy score and the confusion Matrix
indicate how well our model performs the
link for the project is in the
description box below at number eight we
have personality prediction system the
idea is based on determining an
individual personality using machine
learning techniques a person personality
influences both his personal and
professional life nowadays many company
are shortlisting applicant based on
their personality which increases job
efficiency because the person is working
on what he is good at rather than what
is is compelled to do in our study we
attempted to combine personality
prediction system using machine learning
techniques such as SVD na Bas and istic
regression to predict a personal
personality and talent prediction using
phrase frequency method this model or
method allows users to recognize their
personality and Technical abilities
easily to learn about mod this project
check the link in the description box
below at number seven we have Parkinson
disease system Parkinson disease is a
progressive central nervous system
element that affects movement and cause
tremors and stiffness it comprises five
stages and affects more than 1 million
worldwide each other in this machine
learning project we will develop an svm
model using python modules psyched learn
numpy and pandas and svm we will import
the data extract the features and label
and scale the features split the data
set design an N model and calculate the
model accuracy and at the end we will
check the Parkinson disease for the
individual to learn about more this
project check the link in the
description box below at number six we
have text to speech converter
application the machine learning domain
of audio is undoubtly cutting as right
now the majority of the application
available today are the commercial the
community is building several audio
specific open source framework and
algorithm other text to speech apis are
available for this project we will
utilize pyttsx3 pyttsx3 is a python text
to speech conversion Library it operates
offline unlike other libraries and is
compatible with python 2 and Python 3
before API various pre-trained models
were accessible in Python but changing
the voice of volume was often difficult
it also needed additional computational
power to learn more about this project
check the link in the description box
below at number five we have speech
recognition system speech recognition
often known as speech to text is the
capacity of a machine or program to
recognize and transfer word spoken
allowed into readable text MLS speech
recognition uses algorithm that model
speech in terms of both language and
sound to extract the more important
parts of the speech such as words
sentences and acostic modeling is used
to identify the phenones and the
phonetics on the speech for this project
we will utilize pyttsx3
pyttsx3 is a python text to speech
conversion Library it operates offline
unlike other libraries and is compatible
with python 2 and Python 3 to learn more
about this project check the link in the
description box below at number four we
have sentiment analysis sentiment
analysis also known as opinion mining is
a straightforward process of determining
the author's feeling about a text what
was the user intention when he or she
wrote something to determine what could
be personal information we employ a
variety of natural language processing
and text analysis technology we must
detect
extract and quantify such information
from the text to enable classification
and data manipulation in this project we
will use the Amazon customer review data
set for the sentiment analysis check the
link in the description box below at
number three we have image
classification using CNN deep learning
is a booving field currently most
projects and problem statement use deep
learning is and any sort of work many of
you like myself would choose a
conventional neural network as a deep
learning technique for answering any
computer vision problem statement in
this project we will use CN to develop
an image processing project and learn
about its capabilities and why it has
become so popular we will go over each
stage of creating a CNN model and our
first spectacular project we will use
the CFI 10 data set for image
classification in this project to learn
more about this project check the link
in the description box below at number
two we have face recognition system
currently technology absolutely amazes
people with Incredible invention that
makes life easier and more comfortable
face recognition has shown to be the
least intrusive and fastest form of the
biometric VAR ification over time this
project will use open CV and face
recognition libraries to create a pH
detection system open CV provides a
real-time computer vision tool library
and Hardware we can create amazing
real-time projects using opencv to learn
how to create face recognition system
for you check the link in the
description box below and last but not
the least we have movie recommendation
system almost everyone today use
technology to stream movies and
television show while figuring out what
to stream next can be disheartening
recommendation are often made based on a
viewer history and preferences this is
done through a machine learning and can
be a fun and the easy project for the
beginners new programmers can practice
by coding in either python or R and with
the data from the movie lens dat set
generated by the more than 6,000 users
to learn how to create movie
recommendation system for yourself or
for your loved on check the project in
the description box below in a world
where email is crucial spam messages
play our in boxes disrupting our digital
lives but fear note a hero emerges the
email spam classifier this intelligent
system learns from past encounters
uncovering the tricks employed by
spammers deceitful subject lines
promising riches unreasonable low prices
it sports signs like excessive capital
letters misspellings and suspicious URLs
yet the battle doesn't end here spammers
constantly evolve their tactics but the
email spam classifier doesn't Flinch it
adapts refining its knowledge and
staying up to date with the latest
traits every new spam email it
encounters it provides insights enhan
its accuracy and ensuring our protection
thanks to Dedicated minds and Ai and ml
power the fight against email spam
continues the email spam classifier
stands as a faithful Guardian a symbol
of Technology's victory over digital
adversaries it reclaims our inboxes and
restore order to our virtual world
according to recent studies Ai and
machine learning related job postings
have increased by staggering 344 per in
the past 5 years companies across the
global actively seeking professionals
who can harness the power of data and
build intelligent systems the average
salary is
$150,000 in the US And1 15 lakhs perom
in India accelerate your career in Ai
and machine learning with a
comprehensive post-graduate program in
Ai and machine learning gain expertise
in machine learning deep learning NLP
computer vision and reinforcement
learning you will receive a prestigious
certificate exclusive alumni membership
and hackathon and ask me anything
sessions by IBM with three capston and
25 plus industry projects using real
data sets from Twitter Uber and more you
will gain practical experience master
classes by Purdue faculty and IBM
experts ensure topnotch education simply
Larn job assist help you notice by
Leading companies live sessions on AI
trends like jat JP generative Ai and
explainable AI this program C statistics
python supervised and unsupervised
learning NLP neural networks computer
vision GN caras tens of flow and many
more skills enroll now and unlock
exciting Ai and ml opportunities the
link is mentioned in the description box
below let's take a minute to hear from
our Learners who have experienced
massive success in their careers you
need to keep updating your skills on a
regular basis no matter what level you
at I recently completed the professional
certificate program in Ai and machine
learning from Simply learn in
partnership with P University the course
material was comprehensive and the
faculty was extremely experienced uh The
Faculty was able to adjust their
teaching style in order to cater to the
overall skill set of the class in the
rapidly evolving world of technology
it's important to keep upskilling for
every working professional stay relevant
with that having said hey everyone
welcome to Simply LS YouTube channel but
before we dive into that don't forget to
like subscribe and share and now over to
our training
experts so hello and welcome to to this
new video by simply learn email spam
classifier okay so first we will change
this name to
email spam
classifier okay let's rename
it so first what we going to do so first
what we going to do we will import some
libraries then the main main libraries
like n p skon and uh logistic regression
algorithm and then we will move on to
this importing of data set of spam mail
and hmail ham is known as like which is
not a Spam okay so we will do some
categorization of spam email and ham
email then we will split into the
training test and the testing of the
data set okay then we will transform the
text data to feature vectors that can be
used as input to the logistic regression
and then we will convert the white train
and the white test values as integers
and then moving forward we will some see
the features the model
extractions and then we will train the
model using logistic regression and
after that we will predict the accuracy
how much the training data is giving how
much the testing data is giving and at
the end we will build a predictive
system which will tell whether a
particular email is Spam or not spam
Okay cool so let's move on to the coding
part then okay so first I will import
some major lities like
import
numpy as
NP okay then numpy so numai is a
powerful python library for numerical
Computing so it stands for numerical
Python and provides support for
efficient array operations and
mathematic iCal function L algebra
random number generation and more with
numai you can work with
multi-dimensional array known as ND
arrays and these arrays are highly
optimized for performance and allow you
to perform mathematical and logical
operations on large data set efficiently
so numai provides a wide range of
function and methods to manipulate and
analyze these
arrays and the second one
is
import pandas
as
PD okay this PD and NP is nothing we
don't want to write again and again
pandas and
napai so what is
pandas so pandas is a powerful python
Library used for data
manipulation and Analysis it provides
easy to use data structure and data
analysis tool making it essential tool
for working with structur data so the
the third third one is psyched
learn okay so I will write here
from okay I will write here
from
skar do
model
selection
Bo
train
test
split okay so what is escalan model
selection and the train test
split so SK learn or psychic learn is a
popular python library for machine
learning it provides a wide range of
tools and algorithms for various machine
learning tasks including classification
regression and the clustering
dimensionally reduction and the model
evaluation okay and this train test
split this one so the train times split
function is a utility in psychic learn
that helps in splitting the data set
into training and the testing subset
later we will split the data into
training and the testing so this
function is commonly used in machine
learning task to assess the performance
of a model on unseen data okay so move
on to the next algorithm we will write
from we will write
here
from
eSalon
dot
feature
extraction dot text
import T
FID
vectorizer okay so what is tfid
vectorizer so tfid vectorizer is nothing
is a feature of extraction technique
commonly used in natural Lang language
processing NLP and textt Mining task so
it is a part of psychic learn library in
Python so tfid vectorizer transform a
collection of text documents into a
numerical representation that machine
learning algorithm can work
with Okay so move on to we
will import from
Escalon
dot
linear
model
bort
logistic
regression okay so what is logistic
regression so logistic regression is a
popular classification algorithm used in
machine learning it is a part of the
psychic learn library in Python logistic
learn and the regression is suitable for
binary classification problems where the
target variable has the two classes okay
and the last CL we will import accuracy
score
okay so here I will write
from escalan do
Matrix
import
accuracy score okay so let me tell you
first what is that accuracy score the
accuracy score function is a performance
metric provided by the psych learn
library in Python it is commonly used to
evaluate the performance of a
classification model by measuring the
accuracy of the predictions okay so let
me run
it okay okay there is some
error maybe the spelling
mistake okay what I will do I will write
it
again
running it
again yeah it's working so now what I
will do I will import the data set so I
will write here dfal to data frame = to
pd.
read underscore
CSV
mailor
data.
CSV you can find this data set link in
the description box below okay I'll run
it yeah so let's
see the data frame what's in it for us
so as you can see here is category then
message so these are the you know the
males ham means not spam and spam is
Spam okay those males which are not spam
known as
ham so there are two columns 5 five7 two
rows so moving for forward what I will
do I
will convert this male data okay to Nal
so I will write
here data equals to
raw. Raw data equals to DF dot
where PD dot not
null not
null is
[Music]
DF okay
then okay let me give you some spaces
for the better visual yeah so now I will
print data dot
head top so what is the meaning of head
here head means if you want to print the
top five lines of the particular data
set it is you can use the head and if
you want to PR the last five rows of the
data set so you can use the tail instead
if you will write here
10 instead of giving it blank then run
it so it will give you the top 10 rows
of the particular data set okay so these
are the spam mail this ham mails so
later on what we will do we will train
this data set using this particular data
set okay so let's move on to
and see the
info okay of the data set so data do
info so info you can see there are
columns this n n count this data type so
there are two columns like category and
the message and the particular rows are
the 5572 on the both and the data type
is object okay see the memory usage and
you can see
everything and there is one more you can
see the DAT
shape is 5572 comma 2 the these are the
rows and these are the columns two
columns and 5572 rows okay so now what I
will do I will assign the category to
spam M and ham mail okay so what I will
do
here I will write here data dot
Lo then
data ver this
category equals to equals
to
spam
comma
category okay
comma equals to zero so if the zero will
show it is known at the spam and if one
will show it is known as the Hamil okay
I will write here data
dot loc location and
data
then
category equals
to
ham
then
category will
be
one okay then let me run it okay it's
running smoothly so I will write here x
equals to
data
then
message
okay and the Y value will
Beals to main so not
data then
category okay then let
me run
it so now what I will do
first so now what I will do I will write
here
print
X okay so these are only the messages
and
category
print
y so now as you can see 1 1 0 1 1 1 0 so
here zero means what is the zero means
zero means it's
spam and the one means it's Hamil
okay so moving forward what I will do I
will split this data set into testing
and the training okay so I will write
here x
train this is the most important part
and the X
test okay
then y
train then y
t Okay equals to
train test
split X comma y
comma test
size equals to
0.2
then
random okay random
State equals
to
three okay I will write
it
so this is
X train for the training set and X test
is the testing okay then the same why
you know that what is the X and Y here
and here we are splitting using train
test split then X comma y test size
equal to
0.2 okay 0.2 means it will be 80 and 20%
and 80% will be training and the testing
will be 20% okay we will train data 80%
of data using this data set will be
trained and then for the test the 20%
will DET okay the random State equals to
three and the random state is a hyper
parameters used to control any such
Randomness involved in machine learning
model to get consistent result okay when
splitting a data set splitting a node in
a decision tree or a you know logistic
regression ining centroids in clustering
takes place so that is why we use random
streate okay so let me run it it's
working fine so now I will show
print x.
shape okay then
print
xcore
train do
ship I will show you about the I'm
talking about the test size now
print
xor test.
ship now see carefully okay this x will
be
Capital so as you can see total rows are
5572 total row of 80% is 4457 or else
you can calculate and the 20% is for the
testing is
the15 same goes for the Y so moving
forward okay let me show you for the Y
also so I will copy paste it here so
it's
y
y
y see same goes for the Y
also okay so now what I will do here I
will transform the text data to feature
vectors that can be used as input to the
logistic
regression
so
feature extraction
equals to T
FID
vectorizer where the minimum difference
will
be one comma stop
words okay stop
words equals
to
English and the lower
case
true okay here I'm transforming the test
data to the feature
vector and okay so here
x okay let me tell you so this is a
feature extraction we are using TF Dev
vectorizer okay we have import here as
you can see for the EXT of the
text and this is the minimum difference
equal to one and then what is the stop
words stop words are the English words
which does not add much meaning to the
sentence they can safely be ignored
without sacrificing the meaning of the
sentence okay like for example you can
see the words like the he have such
words already computerized and the
capture this is a corpus name of the cor
okay and this lower case equals to two
true so here here I will write X
Trin
features equal to
Features
featur
extraction
fit
transform
xcore xcore test
features
feature
extraction do
transform to the X
test
okay yeah so moving forward I will
convert y train and Y test values as an
integers okay why train because they are
0 1 0 1 0 train equals to Y
train.
as
int okay then y
tests to Y test. as
type
in so
okay there is spelling
mistake we'll copy from
here paste it
here okay I will run
it okay white test it
is yeah it's rning so now what I will do
I will
print the X
train
train
as you can see the
xtrain so these are the messages and if
I will
print
exrain
features we created here now see extend
features okay then you can
see so these are the features accuracy
okay is 0 0 0 means spam 1 one means H
okay so moving forward what I will do I
will now the Train the model OKAY
logistic regression so I will write here
model equals
to okay
logistic
regression so now we will you know train
the model so here I will
write model equals to
logistic
regression okay so we don't want to
write again and again again and again
logistic regession so I'm here assigning
model to it so let me run it so here I
will train the logistic regression model
with the training data so here I will
write model.
fit
exrain
features comma white
train okay here we are training the
logistic regression model with a
training
data let me run it yeah fine it's
running
fine so moving forward we will uh do the
evaluating of the training model train
model and the prediction of the training
data so for that I will write here
prediction
on
training
data equals to model dot
predict
extr
features okay then I will write here
accuracy
on training data to
accuracy score
y
train comma prediction okay I will write
from
here PR of the training
data okay let me run
it so now we will see the prediction so
I will write here
prediction or simply I will write
print accuracy
on
training
data
comma okay I will copy it leave it
accuracy
on
training data okay let me run this so as
you can see accuracy on training data is
0.96 means almost 97 1% which is not bad
very very good okay we will see print
okay now we have to do for the testing
data this is for the training data and
let's see the accuracy for the testing
data so for that I will write same
prediction on test data equals to model
do
predict X
test
features okay then
accuracy
on test data equals to
accuracy
score then y
test comma
prediction prediction
on tested
okay
right okay accuracy
scod so here I will write
print the accuracy on test
data
okay comma then I will write
accuracy on
test
data okay so as you can see the accuracy
on test data is almost same as the
training data okay almost 95% 97% sorry
so now what we will do we will build a
predictive system now okay
so I will write here like
input okay you have to input the mail
here
[Music]
then okay we will input later and we
will now write the line for the convert
text to feature Vector so for that I
will write here
input
data
features
to
feature
extraction do transform
input
okay okay this is a functions so I will
write here
input
input
your
mut
me
okay so here we will make the
prediction okay I will write the
prediction to model do
predict
input
data
featers okay so I have some spam
mails with myself so I will try to copy
them and let's
see
okay I have some mail so I will copy
it
okay and I will paste it
here okay this is the second time we
have tried to contact you you have want
this this this these type of Mals are
spam
actually like you also know so I will
try to run
it let me run it
okay I forgot to write print
print
prediction okay so zero so here as you
can
see already zero means
spam okay so this is a spam mail
actually this is a spam Ma so okay wait
let me write here
if
prediction is showing zero equals to
equals to
true
then
print printed
to
H
and
as then
print
[Music]
spam
spam M okay the prediction will be zero
it's not equals to one okay so it will
show the ham mail or else the spam mail
it's simple pretty simple see Zero spam
mail okay I will try to put it put
here one
Hamil okay
okay let me copy it paste it
here okay let me delete this
quickly okay let me run this so it is
showing ham mail means not spam so
quickly let me run one more spam
mail okay
okay copy this and paste it
here you can try with your own like own
email with the you
got okay so let me run this so it is a
spam mail okay so here is one question
question for you I will give you one
minute for this you can comment or you
can give your answer in the chat section
so I can see if the answers given by you
are right or wrong so the question is
which keyword is used for function in
Python language option one python option
two DF option C
fnc option D
Define so let us know your answer in the
comment section below okay
so I'm starting off timer 1 minute
type your answer in the comment section
or in the chat section do let me know
your answers please I kindly ask that
everyone take part in this to make the
live session exciting so I'm starting
the timer of 1
minute which keyword is used for
function in Python language option one
function option two def option C Punk
option D
Define which keyword is used for
function in Python
language 47
remaining 30 seconds let us know your
answer in the comment section
below this is the easy one which keyword
is used for function in Python language
function Dev Funk or
Define I kindly ask that everyone take
part in this to make this
exciting second
more yeah after that a lotted time has
passed Those Who provided the correct
response will re receive a response and
those Who provided the incorrect
response will receive
one so now let's move to our programming
part to implement loan approval
prediction system so first we will open
a command prom to write a command to
open jupyter notebook so here we will
write
Jupiter
notebook press
enter so this is the landing page of
jupyter notebook and here you have to
select new Python 3
file this is how the Jupiter notebook UI
looks like so at first we will import
some major libraries of python which
will help us creating a loan approval
prediction system so here I will write
import
numpy as
NP so numai is a python Library used for
working with arrays it also has a
function for working in domain of linear
algebra and matrices it is an open
source project and and you can use it
freely numai stand for numerical
Python and the second one
is
Port pandas SD panda is a software
Library written for the Python
programming language for data
manipulation and Analysis in particular
it offers data structure and operations
for manipulating numerical tables and
time
series and the third one is
import matplot
lip
pyplot as
PLT so M plotly Python scripts can be
used to create 2D graphs and plots using
the matplot lab module with features to
control line Styles font attributes
formatting AIS and other features it
offers a module called pip plot that
makes things simple for
plotting so the fourth one
is
import
cbon s
SNS so cbon an open source python
Library based on M plot lip is called
cbon it is utilized for data exploration
and data visualization with data frames
and the Panda's Library C1 function with
these so there is one more like promp
from
eSalon
Port
svm so after importing libraries let's
move forward and import data set so DF
equals
to pd.
read uncore
CSV
tone. CSV
you can download this data set from the
description box
below so
yeah so data set is imported let's see
our data set so we will write DF do
head
here yeah here you can see we have data
set of top five rows so basically head
is used for showing first five rows of
the data set if we will use tail instead
of head so it will show the last five
rows of the data set so let's move
forward and use info function to see the
information about the data
set okay so here we will write DF
doino so the data frame information is
printed by the info method the data
includes the total number of columns
their labels data kinds memory use range
index and the number of cells in each
column that is non-null values note that
the info method does indeed print the
information okay so here you can see
loan ID is object then this applicant
income is N64 then co- applicant income
is float so non-null values like
this so we know all the column names
data types and information let's move
forward and see missing values in the
data set so for that we will use here I
will write DF dot is
null then
bases dot
sum yeah isnel do sum the data set total
number of missing values is returned bya
sum es skipe rows in the data set that
have missing values as a straightforward
solution for the missing value data so
we have missing values in loan ID is
zero gender is 13 then loan amount is 22
selfemployed is
32 so I hope you guys understand till
here if you have any questions or any
query regarding any code so just put as
in commments our team will shortly
provide you the correct solution I'm
repeating again I hope you guys
understand till here if you have any
questions or any query regarding any
code or any question related to python
just put as in comments our team will
shortly provide you the correct solution
moving forward we will create one more
column that is loan amount log using
loan amount detail and then we will
display a histogram for that okay so let
me do first for the better view I can do
this yeah I will write here
DF
Stone amount _ log
Yeahs to
np.
logf now we will do
DF loan amount underscore
log dot his for the histogram then bins
I will take
20 n. log a mathematical function that
helps user to calculate natural
logarithms of X where X belongs to all
the input array elements you can see
histograms it's looking fine let's see
the null values in our new
column so I will write
here here F dot
isnull
sum so here you can see in loan amount
log there are 22 missing
values so moving forward let's create
one more column named total income in
this we will add two columns applicant
income and co- applicant income and we
will display histogram for the
same
EF like total
income equals to
DF applicant
income and we will add one more data
front
TF that
is co applicant
again
F total
income underscore
log to NP
DOT
log
DF
to
DF
income _
log
h p equals to
20
yeah so here you can
see histogram of the total income log
moving forward let's fill those null
values in all the respective columns so
here for that we will
write
DF
gender Phill
na
DF
gender dot
mode
zero comma in
place to
true and what I will do I will copy from
here
change here gender to
married they also
married and here for selfemployed
I will do
self
loyed for
dependent just everything will be same
so here I will write DF
dot own amount
was
to DF
do loan
amount fill
na PF dot loan
amount do
me so here I will write instead of this
I will copy from here and paste it here
yeah SC
log l is
small so here I will write again that we
can take it from
here change column
name to
loan
amount
some
one
amount
um credit underscore
history
again credit
underscore
history so here I will write DF F dot
isnull
sum okay it's it's for giving
error s selfemployed
okay what the issue is that is
capital
in
dependent okay okay it's
dependence
okay yeah so there is no missing values
now what we going to do is we will
select some specific columns and rows
for the training and testing so for that
I will WR write
here x =
to dot
iog dot
R column 11 col comma 13 column
15 okay dot
values y = to DF do
iog then colon comma
12 dot
values let me see the X
values okay so mail no these are the X
values and let me see the Y
values okay so the iog function in
Python is defined in the pandas module
that helps us to select a specific row
or column from the data set using the
ilog method in Python we can easily
retrieve any particular value from a row
or column by using index values so
moving forward let's see the percentage
of missing genders from the data set and
we will do it for many other
columns okay so it if it will be zero so
it will be great for us so we will write
print
percent
of
missing
gender
is percent
to
f
then we will write
thisf in gender
column do
isnull dot
sum F do
shape
zero multiply by
100 is saying function object has no
attributes
some okay
why
because
here percent of missing gender is zero
great so like so moving forward we will
see number of people who take loan as a
group by
gender okay so for that we will will
write
print numbers like of
people who take loan as
Group by
gender for
that
print
DF
sender dot value
value
counts SS do
count
plot xals
to
Zender
comma data equals to
DF
itals to set one you can use either set
two either set
three let me see okay so here you can
see like male is 502 female are 112 you
can see the bar plot so the number of
observation in each category beans are
displayed using bars using the count
plot technique the following parameters
are accepted by the procedure and are
listed below this parameter accept
optional variable names for data or
vector data inputs for long form data
plotting so moving forward we will do
for the same like number of people who
take a loan Group by marital states so
what I will do I will just copy from
here and I will change it to
here so I will
write
metal St
us and the guys were
married here I have to write
the
eight so here you can see like
401 are yes like and 213 are
no okay so moving forward we will see
number of people who t loan Group by
dependents so same what I will do I will
paste it here I will just change the
name
here
[Music]
dependent change it to
here
here you can see the dependence and the
Y label is the count so like 0 R 360 102
101 and 51 and many more so moving
forward we will see number of people who
take loan group as a
self-employed okay for that what we have
to do is we have to just change
names
e is capital
here okay let's see the graph so moving
forward we will see number of people who
take loan Group by loan amount for that
I have to write
here wait let me make a better
visibility yeah so as a loan
[Music]
amount
loan
amount
Capital
yeah here you can
see bar
graph so at the end we will see the
number of people who take loan Group by
credit
history okay so I will write
here
same
as credit
history credit history
three credit
underscore
history
okay yeah so here you can see
525 and this
89
So based on my assessment we don't have
any missing values in the data set now
so moving forward let's import psychic
learn library for training and testing
data set so here I will write from SK
learn.
model model
underscore
selection
Port
train underscore test underscore
split so here we WR train comma X test
comma y train comma
y test
okay so here I will
write
train underscore test underscore
split comma
y comma
test underscore
size equals to
0.2 random
State equals to
Zero from
SK SK
Lear dot
preprocessing
processing
import label encoder
okay so
label score X = to
label
encoder SK SK
learn my
bad
X is not
defined
there we
have so psychic learn or SK learn is the
one of the most robust library for
machine learning it is open source and
built upon numpy scipi and M plot Li it
provides a range of tools of machine
learning and statical modeling and train
test split function of the skarn model
selection package in Python splits
arrays or matrices into random subsets
for train and test data and label
encoder encode label with a value
between zero and N classes minus one
where and is the number of distinct
label moving forward let's fit and
transfer data for
training so here we will write
for I
in I in
range 0 comma
5 xcore
train comma
I equals to
label and
orderer underscore X do
fit
transform and xcore
train colon comma
I
then xcore
train
7 equals
to
_
x dot
fit transform
and xcore
train
7 let's see
xcore oh
sorry let go
train and yeah this I
this is capital
x fit transform joins these two steps
and used for the initial fitting of the
parameter on the TR set while also
returning the transformed X internally
the transer object just calls first fit
and then transform on the same data and
we will perform same for the Y so
I have I will write
here
label encoder underscore
y so
label
label
encoder
okay Yore
10al to
label
encoder underscore y
do
fitore
transform me see the results
yeah so training of the data set is done
let's do for same for the testing
data so I will write here for
I in
range 0 comma
5 underscore
test
I equals to
label
coder underscore X do
fitore
transform underscore
test
I then again
xcore
test col comma
7 equals
to
label encoder
underscore dot
fitore
transform underscore
test then colon comma
7 yeah then see the results xcore
test okay it seems cool
all the
values so we will do for the same y
test so we will write here
label
encoder let me
put underscore yals to
label so why and _ test equals
to
order underscore y do
fitcore
transform
test let's
see
okay moving forward we will import is
standard Scala for the further process
so for that we will write
here from
Escalon do
preprocessing
import
[Music]
standard
scalar say equals
to like we assign this
standard I will do I will copy it from
here so X
train equals to SS do
fitore
transform
xcore TR
then xcore test equals to SS do
fitore
transform underscore
test okay skillon do
preprocessing okay escal and
pre-processing standard
scalar okay
sorry and again like standard okay
ER yeah so standard scaler removes the
mean and scales each feature variable to
unit variance this operation is
performed feature-wise in an independent
way everything is done let's see which
classify is best for prediction by
seeing their
accuracy so for that I will write
here let me do one
thing
yeah so like I will write
from
kear do
emble sample yeah import
random
Forest
classifier so I will write if
under class clf
classifier equals
to random
Forest sorry my
bad so
RF underscore
clf do
fit
xcore
train comma ycore
train so I will WR here from
skar
import
Matrix ycore prediction equals to RF
underscore
classifier do
predict do
predict xcore
test
so here I will
print
accuracy of
random random
Forest classifier
is comma
Matrix dot accuracy
score
score then y underscore
prediction comma Yore
test Yore
prediction so let's see the prediction
from the using random forest classifier
and the accuracy a random Forest is a
meta estimator that employs averaging to
increase predicted accuracy and reduce
overfitting if Boost St equals to true
the size of the subsample is determined
by the max sample argument otherwise
each three is constructed using the
entire data set so here you can see the
accuracy is like
78% and here prediction you can see like
here one denotes that loan approved and
zero means loan will not approved so
accuracy is quite less so let's see for
another classification methods Nave
base so here I will write from
Escalon
Port gos
NB na
base okay so NB
classifier equals
to Goan n
b bore
classifier equals
to sorry do
fit
strain comma y
train
so a not equals
to like go Okay g is
capital
sorry
yeah so let's predict the
value Yore
predict to
[Music]
NB
classifier do
predict
xcore
test and
print
accuracy
of Na
base
is comma like
Matrix dot
accuracy score
score y underscore
prediction comma y
underscore test so accuracy of goian NB
is 0.8 means
82% let's predict the value why
predict prediction like one is like loan
approved and zero is loan or not
approved so Nave base is a
classification algorithm for binary two
classes and multiclasses classification
problem it is called n base the
calculation of the probabilities for
each class are simplified to make their
calculation tractable so the accuracy is
82% and here prediction you can see one
denotes loan approved and zero means
loan will not approved so let's see for
another classification method like
decision tree
classifier for that I will write
here
from
Escalon dot
tree
import
report
decision
tree
classifier here I will write
dtore
classifier
to I will copy it from
here
I will write here DT uncore
clf equals
to so dot
fit xcore
train comma ycore
train y small
here I will see the
accuracy to
DT underscore
classifier dot
predict
underscore
test
so here I will
print accuracy
of
dentry
is comma
Matrix
accuracy
underscore underscore
predict comma
ycore test
so here you can see the accuracy is
70% so let me
predict so decision Tre the
non-parametric supervised learning
approach used for classification and
regression application it is organized
hierarchically as and has a not root
branches internal nodes and leaf nodes
the so the accuracy is 70% and here
prediction you can see one denotes the
loan approved and zero means loan will
not approve so let's do one more
classification we will do it from the
kers using
kers so here we will write
from
Gan
dot verse
import K
neighbors
pacifier K
classifiers we will
assign
this
so here we will write Kore
classifier dot
fit X
train comma Yore
train okay SK
skar
sorry then
[Music]
again okay it's Capital
here
here
yeah wait
yeah so here I will see the
accuracy
okay by prediction equals to
K underscore
classifier
dot
predict xcore
test
print
accuracy
of K neighbors
is
Matrix do accuracy
score
score Yore
prediction comma y underscore
test so let's see the accuracy so
accuracy is 79% and it is quite good so
the K neighbors the five closed
neighbors are sought for the kers
classifier the classifier must be
splitly instructed to utilize ukan
distant to determine the proximity of
nearby points so the accuracy is
79% and here prediction you can see one
denotes the loan approved and zero means
loan will not
approved so you can
see Nave
base where's name yeah so here you can
see we have name base classifier with
the best accuracy of 82% so we can use
it for the loan approval prediction
system
so I hope you guys understand till here
if you have any questions or any query
regarding any code just put as in
comments our team will shortly provide
you the correct solution I hope you guys
must have understood the concept of how
we can Implement loan approval
prediction system using python if you
have any queries you can ask in the
comment section below our team will
shortly respond to you as soon as
possible and if you want this full code
and is you want this full code just
comment for the same thank you so much
for being here if you enjoyed this video
video please do subscribe to our YouTube
channel and give a like to this video
what is fake news false or misleading
information that is reported as news is
called fake news a common goal of fake
news is to harm someone or something
reputation or to profit through
advertising the term fake news was first
used in 1890s a time when dramatic
newspaper reports were common even
though incorrect information has always
been dissed throughout
history however the the phrase has no
clear definition and is often used to
refer to all misleading information
high-profile individuals have also used
it to refer to any news that is not
favorable to
them so dear Learners if you want to
upskill your AI and machine learning
skills so give yourself a chance to
Simply learn professional certificate
program in Ai and machine learning which
comes with a completion certificate and
in-depth knowledge of AI and machine
learning check this course details from
the description box below now now let's
move to our programming
part so first we will open a command
prom to write a command to open jupyter
notebook so here we will write
Jupiter
notebook
Center and here I have to select new
python Kel file okay so this is how the
Kel look lies so first we will import
some major libraries of python so here I
will write
import pandas
aspd and
inut numai as
NP then
import
cbor as
SNS okay then import
skarn do model
selection
Port train
underscore test underscore
split before that I will
import M plot
Li
do p
plot as
PLT okay
then I will write here from
Escalon dot
matrix
import
accuracy
four then
from
Escalon do
Matrix
import
classification to
report and import R then import
string
okay then press enter so it is
saying okay
here I have to write
from everything seems
good loading let's
see okay till then numai is a python
Library used for working with arrays it
also has function for working with
domain of linear algebra and
matrices it is an open source project
and you can use it freely
number stand for numerical
python pandas so panda is a software
Library written for Python programming
language for data manipulation and
Analysis in particular it offers data
structure and operation for manipulating
numerical tables and time
series then cbor an open source python
Library based on M plot lib is called
cbon it is utilized for data exploration
and data visualization with data frames
and Panda's Library cbone functions with
ease then M PL lip for Python and its
numerical extension numpy met plot Li is
a cross platform for the data
visualization and graphical charting
package as a result it presents a strong
open source suitable for matlb the apis
for met plot Li allow programmers to
incorporate graphs into gii applications
then this train test split we may mild
our training data and the test data with
the aid of escal learn train test split
function this is so because the original
data set often serves as both the
training data and the test data starting
with a single data set we divide it into
two data sets to obtain the information
needed to create a model like H and test
accuracy score the accuracy score is
used to gge the model's Effectiveness by
calculating the ratio of total true
positive to Total true negative across
all the model prediction this re
expression the functions in the model
allow you to determine whether a given
text fits a given regular expression or
not which is known as
re okay then string a collection of
letters words or other character is
called a string it is one of the basic
data structure that serves as the
foundation of manipulating data the Str
Str class is a built in string class in
Python because python strings are
immutable they cannot be modify after
they have been
formed okay so now let's import the data
set we will be going to import two data
set one for the fake news and one for
the True News or you can say not fake
news okay so I will write here BF
underscore f equals
to PD
do read uncore
CSV or what can I say DF fake
okay _
fake
okay then fake dot CSV you can download
this data set from the description box
below then data do true equals to PD do
read underscore
CSV sorry
CSV then fake news sorry true true.
CSV okay then press
enter so these are the two data set you
can download these data set from the
description box below so let's see the
board data set okay then I will write
here data go
fake do
head so this is the fake data okay
then data underscore
true
do and this is the two
data okay this is not fake so if you
want to see your top five rows of the
particular data set you can use head and
if you want to see the last five rows of
the data set you can use tail instead of
head
okay so let me give some space for the
better
visual so now we will insert column
class as a Target feature okay then I
will write here data let's go
fake
CL equals to
0 then data underscore
true and
plus = to
1
okay
then I will write here data underscore
fake dot shape and data underscore
true do
shap okay then press
enter so the shape method return the
shape of an array the shape is a tle of
integers these number represent the
length of the corresponding array
dimension in other words a tle
containing the quantities of entries on
each axis is an array shape Dimension so
what's the meaning of
shape in the fake word in this data set
we have we have 2 3 48 1 rows and five
columns and in this data set true we
have 21 417 rows and five column okay so
these are the rows column rows column
for the particular data
set so now let's move and let's remove
the last 10 rows for the manual testing
okay then I will write here data
underscore
fake let's go
manual
testings to dataor
fake dot
tail for the last 10 rows I have to
write here
10 okay so for
I in
range 2 3
4 8 1 sorry
zero
comma 2
3
470 comma
minus1
okay
then DF uncore not DF
data underscore
fake dot
drop
one instead of one I can write here
I
comma is equal to
0 in
place equals to
true then
data not
here data
underscore same I will write for I will
copy from
here and I will paste it here and I will
make the particular changes so here I
can write
true here I can write
true
okay then I have to change a number
2
1
416
write 21 40
6 -
1 same
so press
enter x equal
Z since X maybe you mean d0 or of
this okay we will put here double
course
I'm putting
this. drop i z in place
okay also write equals
toal yeah
so okay AIS is not
find now it's working
so let me
see now data
underscore pick.
shape
okay and data dot
true and data underscore
true.
shape as you can
see 10 rows are deleted from each data
set yeah so I will write here data
underscore fake underscore
manual
testing
class =
to0 and data
underscore true
underscore manual underscore
testing CR equals
to
one
okay just ignore this fing
then let's
see data
underscore
bore
manual
testing.
head as you can see we have this and
then data dot sorry underscore true
_
manual
testing dot
at this is this is the uh true data
set so here I will merge data underscore
merge to
PD
do
concat concat is used for the
concatination
data underscore
fake data
underscore comma
XIs = to
zero then data underscore merge
do
head the top 10
rows
yeah as you can see the data is merged
here okay first it will come for the
fake news and then with the for the True
News and let's merge true and fake data
frames
okay we did this
and let's Mery column then data do
merge dot columns or let's see the
columns it is not defined but data
underscore
Mar these are the column name title Tex
subject date class
okay
now let's remove those columns which are
not required for the further process so
here I will write data
underscore or equals to data uncore
merge
prop right we don't
need
then subject we don't need
then
one so let's check some null
values it's giving error
here because of this
that's good then
data dot
isnull
some
Center so no null values okay then let's
do the random shuffling of the data
frames okay for that we have to write
here data equals to data do
sample
one
then data okay
data do
head okay now you can see here the
random shuffling is done
and one for the true data set and zero
for the fake news one
okay then let me write here data
dot
reset underscore
index
Place equal
true data dot drop
comma XIs = to
1 then comma in
place equals to
True
okay then let me see columns now data do
columns so here we have two columns only
rest we have deleted
okay me see data dot
add yeah everything seems
good let's proceed further and let's
create a function to process the text
okay for that I will right
[Music]
here
but okay you can use any
name
text then text equals
to text.
lower okay and
texts to dot for the substring
remove these
things uh from
the datas okay so for that I'm writing
herea
okay then text equals to R do
substring
comma comma text
okay then I have to write text equals
to do
substring W ww
dot
s+
comma comma
text okay then text equals
to R do
substring
then
comma okay then text equals to R do
substring then
percentage
as again percentage for r. SK
function right here
string do
punctuation
okay
comma then comma then
text
right then text equals to R do
substring and
N
comma TT equals to
r
dot
substring right
here and again
D then
again okay then
comma then again text here okay then at
the end I have to write here return
return
text so everything like uh this this
type of special character will be
removed from the data set okay let's run
this let's
see yeah so here I will addite DF sorry
not DF
data
data
then
text to data
okay dot
apply to the function name wordp word
opt
okay press enter yeah so now let's uh
Define the dependent and independent
variables okay x equals to
data
text and yals
to D
data
class okay then splitting training and
testing
data okay sorry so here I will write
xcore
train comma xcore
test uh then Yore
train comma Yore testal to train
underscore testore
split then X comma
y comma
test let's go size equals to
0.25 okay press
enter so now let's convert X to vectors
for that I have to write
here that it's X
so here I will write from
Escalon dot
feature
extraction dot text
import T
vectorizer
okay then vectorize
equals to T
FID
vectorizer okay
then V
underscore
train equals to
vectorization
R
vectorization do
fit then
transform xcore
train okay then X Vore test equals
to
factorization
dot
transform xcore
test okay then press
enter
uh so now let's see our first model
logistic
regression so here I will write
from eSalon
dot linear uncore model
okay
import
logistic then lot equals
to
logistic
regression have to write here LR Dot
fit then XV
dot not DOT train
comma X Vore
test okay press
enter XV
TR okay here I have to write y train
okay then press
enter will work so here I will write
prediction
underscore linear
regression
to l r do
predict sore
test okay let's see the accuracy score
for that I have to write LR do
score then XV uncore
test comma
Yore
test okay let's see the accuracy so here
as you can see accuracy is quite good
98% now let's
print the classif
ification
ort Yore test
comma prediction of linear regression
okay so this is you can see Precision
score then F1 score then support value
accuracy okay so now we will uh do this
same for the decision free gradient
boosting classifier random Forest
classifier okay then we will do model
testing then we will predict the
score okay so now for the decision tree
classification so for that I have to
import from
skon dot
tree
import
decision
three classifier
okay then at the short form I will write
here I copy it from
here
then okay then I have to write the same
as this so I will copy it from
here
and
yeah
let change linear
regression to se tree
classific
okay then I will write here
same go
DT equals to DT
predict X
Vore
test let
B still loading it's it will take
time
okay till then let me write here for the
accuracy D do
score
underscore test comma
y
okay let's wait
okay
run yeah accuracy so as you can see
accuracy is good than this linear
regression okay logistic
regression okay so let
me
you the let me
predict
print so this is the accuracy score this
is the all the
report
yeah now let's move for the uh gradient
boosting classifier okay for that I
write from
Escalon dot
emble
Port
radiant
boosting
classifier classify
I will write here
GB equals to let me copy it from
here
okay I will give here
random let's go
State equals to
zero wait wait wait wait so I will write
here GB dot fit
X Vore train comma Yore train okay then
press
enter here I will write predict
underscore
GB to GB dot pit sorry
predict
three DOT test
_
test till then it's loading so I will
write here uh for the score then I will
addite GB do
score then Vore test
comma Yore test okay so let's wait it is
running this
part
then let me write for the printing
this okay it's taking
time taking time still taking
time 45 will run
this it's not coming because of
this yeah it's done now so you can see
the accuracies
is uh not good
than decision tree but yeah it is also
good
99.4 something okay
so now let's check for the last one
random
Forest first I will
do
for the random Forest we have to write
from Escalon
dot
symbol
import
random
Forest
classifier
okay and here I will write
RF
to right I will copy it from
here
then random
State equal
to Z
then RF dot
fit ccore train
comma Yore
train okay then press
enter and predict
underscore
RC R
fals
to RF do
predict 3core test
okay till then I will write here it's
still loading it will take time so till
then I will write for the score score
accuracy
score XV uncore test comma Yore
test okay then I will write here till
then
print
classification
port
and Yore
test
comma will take time little
bit
so uh it run the accuracy score is 99 it
is also
good so now I will write the code for
the model testing so so I will get back
to you but after writing the code
so so I have made two functions one for
the output label and one for the manual
testing okay so it will predict the all
the from the all models from
the repeat so it will
predict the it the news is fake or not
from all the models okay so for that let
me me write here
news to
string
put
okay then I will write here manual
underscore
testing so
here I will you can add any news from
the you can copy it from the Internet or
whatever from wherever you want so I'm
just copying from the internet okay from
the Google the news which is not fake
okay I'm adding which is not fake
because I already know I searched on
Google so I'm entering this so just run
it let's see what is showing
okay string input object is not callable
okay let me check this
first okay I have to give here s Str
only yeah let's
check okay I have to add here again the
script yeah manual testing is not
defined let me see manual testing
okay I have to edit
something it is just GB and it is just
RF GBC is not defined okay okay so what
I have to do I have to remove
this
this okay everything seems
sorted
now as I said to you I just copied this
news from the internet I already know
the news is not fake so it is showing
not a fake news
okay so now what I will do I will
copy one fake news from the
internet and let's see it is detecting
it or not
okay so let me run
this and let me add the news for
this
so all the models are predicting right
it is a fake news or you can add your
own own script like this is the fake
news
okay I hope you guys understand till
here so I hope you guys must have
understand how to detect a fake news
using machine learning you can you can
copy any news from the internet and you
can check it is fake or not okay or if
your model is predicting right or not so
if you have any queries you can ask in
the comment section below our team will
respond you as as soon as possible okay
don't forget to check the course link
from the description box below and you
can download this data set from the
description box below and if you want
this full Code full code just comment
for the same what is image
classification the process of
classifying an entire image is known as
image
classification images are anticipated to
have just one class per image models for
image classification taken an image as
input and produce a prediction of the
class to which the image belongs so we
can utilize image classification models
when we are not interested in individual
instance of items with position
information or their
shape so let's see what is
CNN machine learning includes
convolutional neural networks also known
as convents or CNN it is a subset of the
several artificial neural network models
that are employed for diverse purp and
data sets a CNN is a particular type of
network designed for deep learning
algorithm that is utilized for task like
image recognition and pixel data
processing and so more okay although
there are different kinds of neural
network in deep learning CNN are
preferred neural architect for
identifying and recognizing object
therefore they are rely suited for
computer vision activities and
applications where accurate object
recognition is is crucial such as facial
and self-driving automobile system so
moving ahead so dear Learners if you
want to upscale your AI and machine
learning skills so give yourself a
chance to Simply andarn professional
certificate program in Ai and machine
learning which comes with the completion
certificate and in-depth knowledge of AI
and machine learning check this course
out details from the description box
below so now let's move to our
programming part of how to do image
classification using CNN if getting your
learning started is half the battle what
if you could do that for free visit
scaleup by simply learn click on the
link in the description to know more so
first we we will open a command prompt
to write a command to open jupyter
notebook so here we will write
Jupiter
notebook press
enter so this is the landing page of
jupyter notebook so here you can select
new python
file so this is how the kerners look
like okay jupyter notebook kerners look
like so first we will import some major
libraries of python which will help us
in like analyzing the data okay so in
this file we will classify small images
of C 10 data set from tlow data set
there are total 10 classes as shown
below so we will use CNN for the
classification purpose okay so here I
will write
import tensor
flow as
TF okay so from tensor
flow dot
Kus
import data
sets comma layers
models okay so we will
import numi as
NP right and
import M plot
Li as
PLT right okay so here I will write P
plot as
PLT right so tens oflow this one this so
tensorflow is a free and open source
machine learning and artificial
intelligence software Library it can be
used for variety of applications but it
focuses on mainly deep neural network
training and the inference purpose okay
got it and this numpy numai is a python
Library used for working with the arrays
it also has a function for working with
the domain of linear algebra and
matrices it is an open source project
and you can use it freely numai stand
for numerical
Python and this third one matplot lip
for Python and its numerical extension
numai matplot lib is a crossplatform
data visualization and graphical
charting package as a result it present
a strong open source substitute for
matlb the apis application programming
interfaces for matplot Li allow
programmers to incorporate graphs into
GUI
applications got
it so let's run
this let me change
image
classification
using
CNN
okay so let's load the data set okay we
will load the data set from the
uh load data
function so here I will write
xcore
train comma Yore
TR okay and one for test
xcore test comma Yore
test okay then equals to data
set
dat sets dot we are using CER 10 C 10 f
10 do
load dot
uncore data
okay it will load our data so let's load
the
data so data is loaded let's see
X
score test dot
shape
okay
yeah so as you can see so we have th000
rows and one more
X underscore train do
shape let me run
this so here you can
see like we see like training data like
training images are 50,000 and the test
images are 10,000
okay so this is for testing this is for
training and so moving ahead we will see
for the
Y
r dot
shape
okay th000 and here we will see the
array so Yore
train five okay that's on this first let
me give some space yeah
so here Yore train is a 2d array like
for our classification having 1D arrays
are good enough so what we will do we
will convert this to now 1D array this
is 2D array we will convert into 1D
array okay for
that we'll write here ycore
train equals to yore
train dot
reshape minus one
comma then y underscore
train and again semicolon
5 let's run this okay so now this is 1D
array so Yore
test
= to Yore
test
dot
reshape in minus
one here I will
write
classes to there are some classes okay
in the data set like
airplane comma automobile
but
comma cat
comma
here
dog
Rog
Course
Truck okay so these are the some
classes like airplane automobile bird
cat deer so it will be help in
classifying the images so let's plot
some images to see like what they what
they exactly are okay so we will what we
will do we will create one
function for that let me write
here def plot uncore
sample okay then X comma
y comma
index
okay then I will write here plot do
figure lt.
figure then figure size should
be comma 2 equals
to PLT do
show image show to I am
show
X
index PLT do X
label
classes y index
okay so let's see some samples of the
images so I will write a
plot underscore
sample uh _
train comma Yore
train okay okay comma let's see the
fifth image okay then
enter should be
Capital so as you can see this is a car
so it is showing automobile okay so
let's see once
more like plot underscore
sample xcore
train comma y underscore
test comma we'll see the 10th
one okay it is not quite
visible so we'll go for the
11 okay okay I'm am why is showing wrong
because I use here test I have to use
here train instead of test then it will
show I think correct yeah you can see
HSE then HSE then what about 2011
image see you can
see so we will see once more
500y frog okay it's not quite
visible yeah so you can see
here the proper shape
okay so what we will do now we will
normalize the images to a number from 0
to 1 image has three channels like RGB
colors so and each value in the channel
can range from 0 to
255 hence to normalize in 0 to 1 range
we need to divide it by 255 okay
so now what we will do we will normalize
the
data so here what we'll do at xcore
train equals to xcore
train divided by 255
and0
okay and same for
test to X
test divided
by
25.0 okay to range between 0 to
1 yeah we will build simple artificial
Nal Network for image classification
first okay so we will write here
Ann to models dot
sequential
okay then I will write here
layers
dot
plat inut
underscore shape equals
to 32 comma 32 comma
three
okay then again layers dot
10
3,000 comma
activation to
rlu got
it then again for the th000 so I will
what I will do I will copy it and paste
it here okay so
th000
so uh let me add one more one more layer
dot
10s then add 10 comma
activation to soft
Max
okay and I will okay let me give for the
better
visuals yeah an
n n do
compile
Optimizer okays to
SGD then
comma I will write here
loss equals
to
sparse
categorical
cross entropy
okay so here I will write comma then
Matrix equals
to
accuracy Ann dot
fitore train
comma Yore
train comma
EPO
okay so number I will give a box = to
5 right so it will take time to
run it's
running here there is some
[Music]
issue
underscore
train box equals
to
five but it is
saying in user code the file program
from C engine
okay I will copy
it and P it
again run it
again okay now it's
working
okay so it will take take time and then
I will get back to you
okay then
import numai you guys already know what
numai is
NP Yore
predictions to ann.
predict
prict
xcore
test okay then y
underscore prediction
underscore
classes equals
to NP
do Argent
Max
element for
element
in ycore
prediction
print
classification
Port comma
classification
report then y underscore test comma y
underscore
prediction
underscore
classes okay so let me run
this
this
Capital yeah it will take less
time now we will create a graph
okay
like X text is like we have thousand
images so CL graph will be like messed
up still let's see so I write
import
cbor as
SNS
Okay Okay C
Bor yeah
me give some
space here I will write PLT dot
bigger size should
be 14 comma
7 okay then as soon as we will create a
heat map for this then Yore
prediction
not equals to
true then PLT doy
label this
truth PLT do X
label
addtion then PLT do title should
be
Fusion okay then PLT do
show let me run
this
okay see why prediction has X
text which is still
running let's
wait so now let's make CNN model okay to
train our images so for that I will WR
CNN equals
[Music]
to models Dot
sequential
okay write paste here yeah so let me run
this so this is our CNN model from which
we will train our
images and CNN like
compile then
optimize
Optimizer equals to
addm
okay okay
comma right here then loss equals
to
sparse
categorical then
cross entropy
okay and comma I will write here
Matrix equals
to
ur run this
okay
l
yeah same goes for
[Music]
you okay
loss
I do I will rewrite
this okay now let's check CNN model for
the 10 EPO
okay let's see the accuracy is
increasing or not CNN
dot SC
train comma Yore
train
comma
box let just start
started it will take less time than the
previous one
okay
see you want this whole code you can
comment down the same okay
after completing this I will get back to
you so it is almost done like 27 seconds
or the 10
epox and then let me write cnn.
evaluate xcore test comma y underscore
test
okay so with CNN the end five aox
accuracy was around like 70% and which
is a significant improvement over Ann
okay Ann we have like this
49 okay and CNN are the best for image
classification and gives the superb
accuracy also computation is the much
less compared to simple Ann as Max
pooling reduces the image Dimension
while still uh preserving these uh
features okay so let me run
this take some
time till then I will write Yore
prediction equals to
CNN dot
predict then xcore
test
okay then I will write here Yore
prediction then colum
five let me run
this
so you can see the accuracy and all the
array
okay yeah so
let's classes equals to NP
dog
Max
El
for element in y
prediction okay then y underscore
classes
then these are the number of classes
then Yore
test is column
five these are the array so it's
converted into array then now let's see
the it is predicting Right image or
wrong image okay by not with the
training data here we predict from the
training data y training X train okay
now we will predict from the test data
so here I will write
plot _
sample then xcore test comma Yore test
and you can write the random one
so here I will write
60 let's see so you can easily see here
this is ORS and it is predicting right
horse and let me okay plot let's go
sample then
xcore test comma Yore
test comma
100 okay press enter
okay X is
capital yeah so you can see this is
D okay so our model is predicting the
correct image okay then what we like
let's see it is predicting the right
class or not okay we made the classes
like random
classes okay where are these these so
let's see it is predicting right or
wrong
okay for that I have to write
classes Yore
classes like which number 60 okay
60 60 is not defined because like number
of
classes okay okay so there are 1 2 3 4 5
6 7
okay 0 to 9 I can
choose so here what I will
do I will take small one like will
five okay this is
frog
okay this frog right so I will take
instead of 60 here I will see
frog y class is not defined
Yore
classes is defined C okay there are 3 S
yeah so as you can see frog this is frog
so our classes is defining right so here
I will write it again like
60 it was HS and let me write here
60 you can see the right prediction
okay
so this is what how you can you do image
classification using CNN I hope you guys
must have understood this concept like
how to do image classification using CNN
you can ask in the comment section below
if you have any queries uh regarding
code or python machine learning or
any course related query so our team
will respond you as soon as possible
don't forget to check the course link
from the description box below and if
you want this full code you can just
comment for the
same so what really is stock
market a stock market is a place or a
public market where you can buy and sell
shares for publicly listed companies the
stocks which are also known as equities
represent ownership in the company
the stock exchange is the mediator that
allows the buying and selling of shares
Amsterdam stock exchange is the oldest
Stock Exchange that were established in
16002 the top stock exchanges in the
United States are the New York Stock
Exchange NASDAQ American Stock Exchange
and Chicago Board operations Exchange in
India we have the Bombay Stock Exchange
or the BSC that was established in 1875
and it's Asia's first Stock Exchange we
also have the National Stock Exchange or
NSE now let's understand the importance
of stock
market stock markets help companies to
raise Capital if stock markets did not
exist then companies would have to
resort to borrowing loans from the banks
to raise money for
expansion this would be a trouble for
the company as they would have to repay
the loans with interest with stock
markets companies have the free hand to
create an initial public offering and
raise large amounts of cash without
having to worry about
repayment another reason why the stock
market is important is it helps generate
personal wealth for an individual
investor the stock market provides a
platform to invest your income and earn
a share of the company's profit stock
markets serve as an indicator of the
state of the economy that is the stock
market serves as a barometer for the
economy a rise of fall in the prices of
shares indicates what cycle the economy
is in such as a recession or a boom the
stock market is considered to be one of
the most widely used sources for people
to invest money in investors are always
looking to invest in companies with high
growth potential if the stock market is
performing well this increases
investment from local investors it also
attracts foreign direct investment as
people abroad invest in the local Stock
Exchange
with that let's Now understand stock
market
prediction stock market prediction helps
to determine the future value of company
stock and other financial instruments
traded on an exchange the whole idea of
predicting stock prices is to gain
significant profits predicting how the
stock market will perform is a difficult
task to do there are a lot of other
factors involved in the prediction such
as physical and psychological factors
rational and irrational Behavior Etc
all these factors combined to make share
prices Dynamic and
volatile this makes it very difficult to
predict stock prices with high
accuracy so we will use machine learning
techniques to predict the stock prices
of two different companies Tesla and
Google we'll be using linear regression
algorithm and long short-term memory
networks for building our prediction
models so first let's understand the
basics of linear
regression linear regression is a very
popular statistical technique used for
solving machine learning problems it is
a supervised learning algorithm for
predicting the output of a continuous
Target variable it can be used to
predict the total revenue of a company
or the total units expected to be sold
of a certain product it can also be used
for weather prediction and stock price
prediction now here is an example to
predict the total number of ice creams a
vendor or a company can sell based on
the temp creature of the
day you can see the green dots represent
the actual data points so the x-axis has
the input variable that is temperature
and the y- axis has the target variable
that is unit
sold linear regression uses the linear
equation formula Y is = mx + C where m
is the slope of the line C is The
Intercept we find the coefficients and
plot the regression line
so in this graph the red line is a
regression line the best fit line should
have the least Square distance between
the original data points and the
predicted
values now let's see how to predict the
stock prices of Tesla using the linear
regression
model so this is the CSV data set that
we will be using for our
prediction we have information from the
29th of June
2010 till the 15th of May
2019 here open column means the price at
which a stock started trading when the
market opened on a particular
day the close column refers to the price
of an individual stock when the Stock
Exchange closed market for the day it
represents the last Buy sell order
executed between two
Traders the high column is the highest
price at which a stock traded during a
period the low is the lowest price of
the
period volume is the total amount of
trading activity during a period of
time the adjusted closing price is a
calculation adjustment made to the
Stock's closing price it is more complex
and accurate than the closing price the
adjustment made to the closing price
depicts the true price of the stock
because the outside side factors could
have altered the true
price now before I begin the demo I want
to tell you that if you want to get a
copy of the source code files and the
data sets that I'll be using in this
session then please put your email IDs
in the chat section of the video also
please subscribe to our Channel and hit
the Bell icon to stay updated with all
the latest trending
Technologies so here is my jupyter
notebook where I have implemented my
linear regression
code so I'll run through each cell of
code and explain what it
does first we'll import the necessary
libraries for building our model so I'm
importing pandas numpy and matplot lib
for numerical computation data
manipulation and data
visualization we'll also import the
plotly library for building our graphs
now if you are using plotly for the
first time you'll have to install it and
then import it onto
Jupiter let me run this
cell so I have successfully imported all
my
libraries
next I load the Tesla stock price data
set using the pandas library and the
read CSV function I'll also give the
location where my CSP data set is
present let me import the data set I'll
hit shift enter
so now I have successfully imported my
data set now let's see my data set for
that I'll use the head
function I'll write Tesla do
head so this will return the top five
rows from the data
set in the next cell I'm using the info
function to find the total rows and
columns in my data set the info function
will also return the dat data type of
the variables and check if there are any
null
values there you go so we have total
seven columns and there are
2,193 entries here you can see the data
type of each column and each column has
non-null
values moving ahead in the next step we
are converting the date column into date
time format using using Panda's library
and 2core datetime
function up next let's do some
exploratory data analysis and get more
insights from our
data I'm using the print function and a
formatted string leral that is f these
strings contain replacement fields which
are expressions delimited by curly
braces you can see
here
here I'm finding out the data frame
contains stock prices between what dates
and the total number of
days so the total number of days can be
calculated by subtracting the maximum
date value and the minimum date
value so let me go ahead and run
it you can
see our stock prices are from 29th of
June
2010 till 15th of March 201 19 and the
total number of days are 3,181
days now let's see some summary
statistics for our data using the
describe
function so the describe function gives
you the count mean standard deviation
the maximum and minimum from each column
the 25th quartile the 50th quartile and
the the 75th
quartile let me now go ahead and create
a box plot to visually check our
outliers I'm considering five columns
open high low close and adjusted
close so this is how our box plot looks
like in this cell we'll plot a graph
using the plotly library that we have
imported we are setting the layout for
our graph using the go layout function
I'm providing a title to the graph I'm
also setting my x-axis for giving the
title so the x-axis will have the date
column you can see it
here we're also defining the title font
the family size and
color similarly I'm providing the layout
for the Y AIS you can see it
here finally I'm passing my data list
and the layout created to plot
variable let me go ahead and run
it now I'll plot My Graph using the
iplot
function
there you go so we have the stock prices
of Tesla plotted in this graph on x-
axis we have the year from 2011 till
2019 and on the y axis you have the
price which is basically the close
column you can see from the graph that
that initially during 2011 or 2010 the
stock prices were growing a little lower
than expected but towards 2015 16 and 17
onwards the stock prices grew
higher now coming to the most important
part that is to build the linear
regression model so in this cell I'm
importing the necessary libraries and
the respective functions first I'm
importing the Trainor testore split
function from the psyit learn
library next I'm also importing some
pre-processing functions like mean Max
scaler and standard scaler from a SK
learn
Library also for evaluating the model
and finding the accuracy we'll use the
mean squ error and R squ error from
Psychic learn Matrix
Library let me run
it
so we have successfully imported our
required
libraries moving
ahead in the current
step we are splitting the data into
training and testing sets the X variable
contains the independent features and
the Y variable has the dependent
variable or the target variable that is
close
column I'm taking the test data size as3
or 30% of the total and I'm assigning a
random stateus
101 let's run
it
okay
now I'll perform feature scaling on the
extra data
set for that I'm using the standard
scaler do fit function and passing in my
xtrain
data standardization of a data set is a
common requirement for any machine
learning algorithm they might behave
badly if the individual features are not
normally distributed
so that's why feature scaling is
important with that it's time for us to
import the linear regression function
from the pyit learn
library
now using a variable LM which stands for
linear model I'll declare a linear
regression function and then I'll use
the fit method to pass the training data
sets that is X train and Y train so let
me run
it now we have successfully created our
linear regression
model next we'll plot the graph for
actual and predicted values for the
training data set here we'll be creating
a scatter plot and draw our prediction
line so I have used the go. scatter
function I'm using markers for plotting
the actual data points and I have used a
line to draw the prediction
line let me run
it now to plot the graph I use the iplot
function if I scroll
down you can see on the x- axis we have
the day column or the day variable
and on the y- AIS we have the prices of
our stocks the blue dots represent the
actual stock values if I H over this
blue dots you can see the actual values
and the red line is a predicted
regression
line the final step we'll calculate the
scores for evaluating our model so here
we are using two Matrix one is R squ
error and mean squ error for finding the
r squ error we have used R2 uncore score
function and I'm passing my y train as
well as X train using the LM predict
function similarly for finding the r squ
error for testing data set I'm using Y
test and LM predict for X
test likewise to find the mean squared
error value and I've used the Y train
and white test data along with predicted
xra and X test
data now let me run
it below you can see the two Matrix
scores so our R squ error score is
around 86 for the training set and it's
around the same value of 86 for testing
data set and similarly you can see the
mean squ error as
well with that you saw how to predict
the Tesla stock prices using linear
regression model in Python if you want
to get a copy of the source code files
and the data sets that I'm using in this
session then please put your email IDs
in the chat section we'll share the
files over email also please subscribe
to our Channel and stay updated with all
the latest
Technologies now we will understand
about long short-term memory
networks so lstms are a type of
recurrent neural networks for learning
long-term dependencies
it is commonly used for processing and
predicting on the basis of Time series
data from the image on the left you can
see lstms have a chain-like
structure instead of having a single
neural network layer there are four
interacting layers communicating with
each other in a very special
way now lstms work in a three-step
process the first step in lstm is to
decide which information to be omitted
from the cell in in that particular time
step it is decided by the help of a
sigmoid
function it looks at the previous state
that is HT minus1 and the current input
state that is XT and computes the
function in the second layer there are
two parts one is the sigmoid function
and the other is the tan function or the
hyperbolic tangent function in the
sigmoid function it decides which values
to let through that is zero or one
the hyperbolic tangent function gives
the weightage to the values which are
passed deciding their level of
importance from minus1 to + 1 in the
third step it decides what will be your
final output first it will run a sigmoid
layer which decides which parts of the
cell State make it to the output then we
put the cell State through the tan H
function to push the values to be
between min-1 and +1 and multiply it by
the output of the sigmoid gate
now let's go to a jupyter notebook and
Implement a long shortterm memory
Network to predict the stock prices of
Google before that let me first show you
the data set that we will be
using so this is my Jupiter lab and on
the left you can see we have our Google
data sets so we will be using two data
sets for this demo a training data set
and a testing data set let me show you
how the training data set looks like
I'll open let's see V
table so this is our training data set
of
Google it has the same columns like date
open high low close and
volume and if I scroll down you can
see we have data from 2012 till
2016 me close
this now let me open my Google test data
set so this is my test data set and
we'll be using this data set to evaluate
our
model so
first let me go ahead and import all the
libraries that we'll be needing to build
our lstm
model you can see I'm importing the nump
pandas and matplot Li library for
numerical computation data manipulation
and data
visualization we are also importing
minmax scaler function from pyit learn
pre-processing library then we have some
built-in functions from the kis Library
such as sequential to analyze a sequence
of data then dens lstm and Dropout to
measure the dropout rate I'll hit shift
enter to run this
cell
you can see it says we are using
tensorflow
backend now let me go ahead and import
the Google training data set using reor
CSV function from
pandas I have imported my data set now
if you want to check the head of the
data set you can use data do
head run again so it will display the
top five rows from the data
set
similarly now let's see the total rows
and columns we have in this data set and
the data types of each
variable we'll use the info function for
this you can
see this is my output so we have a total
of six columns and 1258
entries and here you can see the data
type so date it has taken as object
open it has taken as float High it has
taken as float similarly close and
volume column it has taken as
object now we will do some
pre-processing of data to transform our
closing price variable to a numeric type
drop the non-available data and keep
only the close column for training the
data now to convert the close column
into numeric I have used PD do 2or
numeric function
now to drop my missing values I have
used drop any function and
similarly to consider only closing
column as my training data I'm using
ilock or index
location now let me run
it now let's once again see the data
types if I scroll down you can see we
have changed the close column data type
to
float earlier it was object now it's
float next we will rescale our data into
values between 0o and one for better
performances for that you can use the
minmax scalar function and give the
range then I have used fitore transform
method to transform the
values and then I'm also printing the
shape of my training data
let me run
it now we'll prepare our data for
training first we need to prepare our
input sequences with 60 time steps of XT
train data alongside the respective y
train labels next we'll be adding
another AIS for the batch size since the
input for an lstm network is a 3D tensor
so it will have a sequence length the
time steps and batch
size now we'll build a model containing
four layers of LSM Network all followed
by a Dropout
layer on the top we'll also have a final
dense layer which is this
one all of this compiled using an Adam
Optimizer and a mean squ error as a loss
function
let me run
it next I'll train the data using 20
epox and bat size of 32 using the model
do fit function and passing my X train
and Y train
data this will take some time to run
since it will complete 20 iterations so
you can see it has started with first
oke and it will run for 20
AO now we are into our second Epoch you
can see the loss that was incurred
during the training of the first
Epoch meanwhile when our mod is getting
trained if you have any questions please
put it in the chat
section you can see we have completed
our fifth EPO as well now we we are into
our seventh
Oke
now we have entered our 15th
EPO now we are almost almost about to
finish our
training we have entered into our final
Epoch
now I think we have successfully
completed training our
model next let's visualize the loss that
was incurred during the training process
for each
Epoch I'm using the Mt plot Li library
and the plot function I have given a
title to my visualization I've also
defined my X labels and Y
labels So Below you can see this is how
the graph looks like on the top you can
see the title that is training model
loss you can see the loss has been a
steep
decline
with that let's test the model using a
new data set we'll continue with the
same steps of inputting the data set so
you can see I'm using the read CSV
function to import my test Google data
set then we'll convert the close column
into a numeric
type I'll then drop the missing values
and select the closing price columns for
testing next I'm selecting the labels
for y test data finally we are providing
the input array for the model and
converting the X test data into an NPI
array and printing its
shape let me hit shift enter to run
it in the next cell I'm predicting the
model output using the model. predict
function and passing the X test data so
let me run
it now if you want to check the values
of Y
prediction you can just give the
variable name and hit shift enter so
these are my values it's not in a proper
order or a proper
format now to plot the data between
actual and predicted stock prices we'll
use the inverse uncore transform
function over ypr
data and finally we'll plot the graph in
order to visualize the actual stock
price and the predicted stock price I'm
using the mat plot lib library and I'll
pass in the data we're also providing a
title to the plot the X labels and the Y
labels so this is how the graph looks
like on the xais you have time and on
the y axis you have the stock
price the the red line indicates actual
stock price while the green line
indicates the predicted stock
price with that we have successfully
created our model and predicted the
stock price values using long short-term
memory networks if you have any
questions please put it in the chat
section we'll be happy to help you also
if you want to get the source code files
and data sets I have used for linear
regression and lstm then please put your
email address in the chat section we'll
send it to you over email
we have reached the end of this session
on machine learning projects with source
code should you need any assistance PP
and other resources used in this session
please let us know in the comment
section below and our team of experts
will be happy to help you as soon as
possible until next time thank you and
keep learning stay tuned for more from
Simply loar staying ahead in your career
requires continuous learning and
upskilling whether you're a student
aiming to learn today's top skills or a
working professional looking to advance
your career we've got you covered
explore our impressive catalog of
certification programs in cuttingedge
domains including data science cloud
computing cyber security AI machine
learning or digital marketing designed
in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
of our programs and set yourself on the
path to Career Success click the link in
the description to know
more hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos to nerd up and get certified
click
here