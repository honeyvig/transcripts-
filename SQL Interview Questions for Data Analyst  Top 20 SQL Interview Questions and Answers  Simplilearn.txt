welcome back to our Channel where we
dive deep into the world of data
analysis in today's video we are going
to help you prepare for your SQL data
analyst job interview SQL or structured
query language is a critical tool for
data professionals and mastering it is
key to Landing that dream job we'll be
covering some common SQL data analyst
interview questions and providing
detailed answers to help you succeed
whether you are just starting your
career in data analysis or looking to
take the next step this video is packed
with valuable insights to boost your
confidence and Excel in your interviews
so let's get started and before we begin
if you are someone who is interested in
building a career in data analysis by
graduating from the best universities or
a professional who elicits to switch
careers with data analyst by learning
from the experts and try giving a show
to Simply learns Purdue University post
graduate program in data analytics in
collaboration with IBM the course link
is mentioned in the description box
below that will navigate you to the
course page with the program and the
complete overview of the program is
being word and remember to hit the like
button subscribe button and tap the
notification Bell so you are always in
the know which video will come up next
so let's Dive Right In we'll start with
the interview questions and our first
question is mention the differences
between Data Mining and data profiling
so data mining it's the process of
discovering relevant information that
has not yet been identified before and
if we see about data profiling data
profiling is done to evaluate a data set
for its uniqueness logic and consistency
and in data mining raw data is converted
into valuable information and in data
profiling it cannot identify inaccurate
or correct data values so this is the
main differences between Data Mining and
data profiling moving on to the next
question and the next question is Define
the term data wrangling in data
analytics so data wrangling it's the
process wherein row data is cleaned
structured and enriched into a desired
usable format for better decision making
it involves discovering structuring
cleaning and reaching validating and
analyzing data the process can turn and
map out large amounts of data extracted
from various sources into a more useful
format techniques such as merging
grouping concatenating joining and
sorting are used to analyze the data
thereafter it gets ready to be used with
another data set so this was about data
wrangling in data analytics moving on to
the next question that is what are the
common problems that data analyst
encountered during analysis so now we'll
discuss about the common problems and
the common problems include in data
analytics project are the first is
handling duplicates and the next is
collecting the meaningful write data and
the right time so the first is how to
handle the duplicate data the second is
get the right data and the right time
and there are more problems that are
handling data purging and storage
problems and then we have making data
secure and dealing with compliance
issues so these are the common problems
that data analysts face or encounter so
moving on to the next question
that are what are the best methods for
data cleaning so here we will discuss
three or four methods and starting with
the first is created data cleaning plan
by understanding with the common errors
take place and keep all the
communications open before working with
data identify and remove the duplicates
this will lead to an easy and effective
data analysis process and the next is
focus on the accuracy of the data set
Cross Field validation maintain the
value types of data and provide
mandatory constraints number four
normalize the data at the entry point so
that it is less chaotic you will be able
to ensure that all information is
standardized leading to fewer errors on
Entry so this was the best methods for
data cleaning so you should follow these
steps
and now moving on to the fifth question
that is what are the various steps
involved in any analytics project so
this is one of the most basic data
analyst interview questions the various
steps involved in any common analytics
projects are as follows the number one
understanding the problem understand the
business problem Define the
organizational goals and plan for a
lucrative solution next is collecting
data gather the right data from various
sources and other information based on
your priorities and then cleaning data
clean the data to remove unwanted
redundant and missing values and make it
ready for analysis and then we have
exploring and analyzing data that is
pure data visualization and business
intelligence tools data mining
techniques and predictive modeling to
analyze data and then interpreting the
results interpret the results to find
out hidden patterns future Trends and
gain insights so this was all about the
various steps involved in any analytics
project and moving on to the next
question that is what is the
significance of exploratory data
analysis IDI so moving on to the answer
we'll find out significance that is
exploratory data analysis Eda helps to
understand the data better it helps to
obtain confidence in your data to a
point where you are ready to engage a
machine learning algorithm it allows you
to refine your selection of feature
variables that will be used later for
model building you can discover hidden
Trends and insights from the data so
these are the significance of Eda that
is exploratory data analysis moving on
to the next question that is explain
descriptive predictive and prescriptive
analytics so we'll start with
descriptive so it provides insights into
the past to answer what has happened and
whereas in predictive it understands the
future to answer what could happen and
if we see about prescriptive it suggests
various courses of action to answer what
should you do and another point for
descriptive is it uses data aggregation
and data mining techniques and for
predictive it uses statistical models
and forecasting techniques and for
prescriptive it uses simulation
algorithms and optimization techniques
to advise possible outcomes and now just
listen to an example that is for
descriptive an ice cream company can
analyze how much ice cream was sold
which flavors were sold and where the
more or less ice cream was sold than the
day before and for predictive an ice
cream company can analyze how much ice
cream was sold which flavors were sold
and whether more or less ice cream was
sold than the day before
and for prescriptive lower prices to
increase the sale of ice cream produce
more or fewer quantities of a specific
flavor of ice cream so this was all
about descriptive predictive and
prescriptive analytics moving on to the
next question that is what are the
different types of sampling techniques
used by data analyst so we will talk
about the sampling first sampling is a
statistical method to select a subset of
data from an entire data set to estimate
the characteristics of the whole
population and there are majorly five
types of sampling methods the number one
is simple random sampling number two
systematic sampling number three cluster
sampling number four stratified sampling
number five judgmental or purposive
sampling so this was all about the
sampling techniques used by data analyst
moving on to the next question that is
describe univariate by variate and
multivariate Analysis so we'll just
describe all the three
and we'll start with univariate so we'll
start with an example or just we will
have a little definition about it let us
univariate analysis is the simplest and
easiest form of data analysis with the
data being analyzed contains only one
variable example studying the heights of
players in the NBA and univariate
Analysis can be described using Central
tenancy dispersion quartiles bar charts
histograms pie charts and frequency
distribution tables and moving on to the
bivariate the bivariate analysis
involves the analysis of two variables
to find causes relationships and
correlations between the variables for
example analyzing the sale of ice creams
based on the temperature outside the
bivariate analysis can be explained
using correlation coefficients linear
regression logistic regression Scatter
Plots and box plots now talking about
the multivariate analysis the
multivariate analysis involves analysis
of three or more variables to understand
the relationship of each variable with
the other variables example analyzing
Revenue based on expenditure and
multivariate Analysis can be performed
using multiple regression factor and
Analysis classification and regression
trees cluster analysis principle
component analysis dual access charts
Etc so this was all about the three
univariate bivariate and multivariate
Analysis and move on to the next
question that is how can you handle
missing values in a data set so this is
one of the most frequently Asked data
analyst interview questions and the
interviewer expects you to give a
detailed answer here and not just the
name of the method there are four
methods to handle missing values in a
data set so we'll see one by one the
first is list wise deletion in the
listwise deletion method an entire
record is excluded from analysis if any
single value is missing the next is
average imputation take the average
value of the other participants
responses and fill in the missing value
the next is regression substitution you
can use multiple regression analysis to
estimate a missing value now before
multiple imputations it creates
plausible values based on the
correlations for the missing data and
then averages the simulated data sets by
incorporating random errors in your
predictions so these are the four
methods to handle missing values in a
data set now moving on to the next
question that is explain the term normal
distribution normal distribution refers
to a continuous probability distribution
that is systematic about the mean in a
graph normal distribution will appear as
a bell curve so the mean median and mode
are equal all of them are located in the
center of the distribution and moving on
to the next that is 68 of the data Falls
within one standard deviation of the
mean the next is 95 of the data lies
between two standard deviations of the
mean and then we have 99.7 percent of
the data that lies between three
standard deviations of the mean so this
was all about the term normal
distribution now moving on to the next
question that is what is time series
analysis so time series analysis is a
statistical procedure that deals with
the ordered sequence of values of a
variable and equally spaced time
intervals time series data are collected
at adjacent periods so there is a
correlation between the observations
this feature distinguishes time series
data from cross-sectional data so this
was about the time series analysis now
moving on to the next question that is
how is overfitting different from
underfitting so this is another
frequently Asked data analyst interview
questions and you are expected to cover
all the given differences so we'll start
with the differences between overfitting
and under fitting so in overfitting the
model trains the data value using the
training set and while in underfitting
the model neither trains the data well
nor can generalize to new data in
overfitting the performance stops
considerably over the test set and in
under fitting it performs poorly both on
the train and the test set in
overfitting it happens when the model
learns the random fluctuations and noise
in the training data set in detail in
under fitting this happens when there is
lesser data to build an accurate model
and when we try to develop a linear
model using non-linear data and now I
have an announcement for you guys that
is if you are someone who is interested
in building a career in data analysis
while graduating from the best
universities for a professional who
elicits to switch careers with data
analysis by learning from the experts
then try giving a show to Simply learn
skeleton data analytics bootcamp in
collaboration with IBM The Bootcamp link
is mentioned in the description box that
will navigate you to the course page
where you can find a complete audio of
the program being offered and now moving
on to the next question that is 14
question and our question is what are
the different types of hypothesis is
testing so this is also a very
frequently Asked question and hypothesis
testing is the procedure used by
statisticians and scientists to accept
or reject statistical hypothesis there
are mainly two types of hypothesis
testing number one is null hypothesis
number two is alternative hypothesis so
in null hypothesis it states that there
is no relation between the predictor and
outcome variables in the population and
h0 denotes it for example there is no
association between a patient's BMI body
mass index and diabetes and about
talking about alternative hypothesis it
states that there is some relation
between the predictor and outcome
variables in the population it is
denoted by H1 and for example there
could be an association between a
patient's BMI and diabetes so this was
about the two hypothesis testing move on
to the next question that is explain the
type 1 and type 2 errors in statistics
so moving on in hypothesis testing
uh type 1 error occurs when the null
hypothesis is rejected even if it is
true it is also known as a false
positive so in type 2 it occurs when the
null hypothesis is not rejected even if
it is false it is also known as a false
negative moving on to the next question
that is what is the difference between
count count a count blank and countif in
Excel so these are the functions in
Excel and we'll see the differences so
count function Returns the count of
numeric cells in a Range whereas count a
function counts the non-blank cells in a
range and count blank function gives the
count of blank cells in a range and
countif functions return the count of
values by checking a given condition so
these are the differences between all
the four functions and moving on to the
next question that is can you provided
dynamic range in data source for a pivot
table
so the answer is yes you can provide and
you can provide a dynamic range in data
source of pivot tables so to do that you
need to create a named range using the
offset function and base the pivot table
using a named range constructed in the
first step so this was about how you can
provide a dynamic range in data source
and we'll go to the next question that
is what is the difference between a very
close and a having close in SQL so these
are the two Clauses that is where close
and having close and now we'll see the
differences between them so where close
operates on Raw data whereas the having
close operates on aggregated data and in
the where close the filter occurs before
any groupings are made and in having
close it is used to filter values from a
group and in where close aggregate
functions cannot be used whereas in
having close aggregate functions can be
used and now we'll see the syntax for
both that is where close and having
close so syntax of where Clause that is
you could just start with select the
name of the columns column one column 2
and then from table name and then the
condition where condition
and talking about the having close you
could just select column names write the
column names from the table name and
where condition and then Group by column
names having that condition and order by
from which you want to sort or filter
that is order by so these are the syntax
and we have seen the difference between
a where clause and a having close and
now move on to the next question that is
explain how vlookup Works in Excel so we
look up it's also a very general
question so vlookup is used when you
need to find things in a table or a
range viral so we look up accepts the
following four parameters the number one
is lookup underscore value so the value
to look for in the First Column of a
table for that we use lookup underscore
value and we use the table from where
you can extract value and column index
col underscore index the column from
which to extract value and then we have
range underscore lookup so here true
equal to approximate match that is
default that is approximate values are
matched and if it is false that means it
is a exact match
so this is all about the vlookup and
moving on to the next question that is
20th question and that is how can you
handle missing values in a data set so
this is one of the most frequently Asked
data analysis interview questions and
the interview expects you to give a d
date answer here and note just the name
of the methods there are four methods to
random missing values the number one is
list wise deletion in the listwise
deletion method an entire record is
excluded from analysis if any single
value is missing and then we have
average inputation take the average
value of the other participants
responses and fill in the missing value
then we have regression substitution you
can use multiple regression analysis to
estimate a missing value and then we
have multiple imputations it creates
plausible values based on the
correlations of the missing data and
then averages the simulated data sets by
incorporating random errors in your
predictions
so this was all about how you can handle
missing values in a data set and thanks
for joining us today as we talked and
tackled some essential SQL data analyst
into equations we hope you find this
video informative and valuable in your
job preparation Journey and now let's
take a minute to hear from our Learners
who have experienced massive success in
their careers upskilling is extremely
essential for any working professional
nowadays after completing the
professional certificate program in data
analytics from Simply learn in
partnership with Purdue University my
career took a significant turn
I was able to change my career domain
from teaching kids to providing
Supportive Services to adults at the
Department of Rehabilitation in San
Francisco the experience that I have
would simply learn was amazing The
Faculty was very encouraging excited
about my future and I encourage all
professionals and if you have any more
questions or want to see more content
like this please let us know in the
comment section below don't forget to
like share and subscribe for more
insightful videos on data analysis and
best of luck with your upcoming
interviews and remember with the right
knowledge and practice you have got this
see you in the next video get simplified
get ahead
staying ahead in your career requires
continuous learning and upskilling
whether you're a student aiming to learn
today's top skills or a working
professional looking to advance your
career we've got you covered explore our
impressive catalog of certification
programs in Cutting Edge domains
including data science cloud computing
cyber security AI machine learning or
digital marketing designed in
collaboration with leading universities
and top corporations and delivered by
industry experts choose any of our
programs and set yourself on the path to
Career Success click the link in the
description to know more
foreign
hi there if you like this video
subscribe to the simply learned YouTube
channel and click here to watch similar
videos to nerd up and get certified
click here