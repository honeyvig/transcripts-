hey everyone welcome to a newal network
crash course if you're fascinated by the
world of artificial intelligence and
eager to learn how neural networks power
today's most exciting Tech Innovations
you are in the right place I'm absar and
in this series we will dive into the
basics of neural networks explore their
architecture and understand how they
learn and make decisions whether you are
a student a professional or just a
curious mind this course is designed to
domestify neural networks for you so
grab your notebooks and let's get
started on this exciting journey into
the world of neural networks and just a
quick info for you if you want to
upskill yourself master artificial
intelligence and machine learning skills
and land your dream job or grow in your
career then you must explore simply
learns cohort of various a ml programs
simply learn offers various
certifications and postgraduate programs
in collaboration with some of the
world's leading universities like waron
Purdue Caltech it kpur and many more
through our courses we will gain
knowledge and work ready expertise in
skills like generative AI prompt
engineering explainable AI machine
learning algorithms and over a dozen
others and that's not all you also get
the opportunity to work on multiple
projects and learn from industry experts
working in top tier product companies
and academicians from top universities
after completing these courses thousands
of Learners have transitioned into an AI
or ml role as a fresher or moved on to
higher paying job and profile if you're
passionate about making your career in
this field then make sure to check out
the link in the pin comment and
description books to find an AI nml
program that fits your experience and
areas of Interest let's start with a
brief history of the artificial
intelligence hello I am the human brain
this one's seeking Enlightenment and has
sat and meditated I am the most complex
organ in the human body and I help you
to think understand and make decisions
and the secret being behind all my power
is a neuron I'll get back to that in
some time ever since the 1950s
scientists have been trying to mimic the
functioning of a neuron and use it to
build smarter robots after a lot of
trial and error humans finally designed
a computer that can recognize human
speech it was only after 2000 that
humans were able to give birth to deep
learning that was able to see and
distinguish between different images and
videos so looking at that let's dive
into what is deep learning now your
first thought might be it's the opposite
of shallow learning no deep learning I
like into a magic box and let's go in
there and just take a look as to why is
kind of a magic box so what exactly is
deep learning these are the images of
dogs deep learning is a machine learning
technique that teaches computers to do
what comes naturally to humans learn by
example the robot gets trained with
photos as example now this is very
different than hardwiring a computer
program so that it recognizes something
it actually learns and that's where it's
a magic box because you don't really
control how it learns you control the
aspects that go in the computer comes
back and says wait I know what you are
looks at the photograph of the dog and
it's able to identify that it saw in the
images it says you are a dog woof woof
so that's an example of deep learning
you'll notice we didn't go in we'll go
into the actually how it works behind
the scenes for a neural network but
there's a bit filling of magic and
that's where the term deep learning
comes in and that's also the term well I
like to call it a magic box you put
these things in here into the program
and it starts running the Deep learning
and you have to understand those
settings but you don't have to follow
the exactly what's going on in the Deep
learning model that brings us to the
question how does deep learning do it
remember the neuron scientists manag to
build an artificial form of it that
powers any deep learning based machine
so let's talk about artificial neural
networks what is an artificial neural
network to understand how an artificial
neuron works we need to understand how
the real one works first we have a
dendrite input to the neuron and you can
see these little hairs that come in and
they receive information then we have
the cell body information processing
happens here so it takes all these
different dendrite and information
coming in from the different dendrites
and it looks at that information and
then you have your axon which is the
output to the neuron so there goes your
axon and you see it goes all the way out
and at the very end it flanges out each
one of those little flanges connects to
the dendrite or the hairs on the next
one now let's see what an artificial
neural network looks like so an
artificial neural network we have an
input layer so that could be an array of
data each one of those white dots in the
yellow bar would represent say a pixel
in a picture then you have the lines
that connected to the hidden layers
which are your weights and they add all
those up on the hidden layers in each
one of those dots kind of like a cell
does something with all the inputs and
then it puts an output into the next
hidden layer and so on into the output
layer so information processing happens
here input to the neuron output to the
neuron so you can see how they are
similar we have an input which is our
yellow bar coming in and then you like
it in each of the Hidden layers to being
a neuron and it passes it to the next
one and so on and then you have an
output to the next neuron or an output
to the real world a neural network is a
system of Hardware Andor software
patterned after the operation of neurons
in the human brain neural networks also
called artificial neural networks is a
way of achieving deep learning how does
artificial neural networks work let us
find out how does an artificial neuron
Network work hey Siri what is the time
now it's 12:30 in the morning thanks
let's find out how she recognizes speech
here is a neural network and the
different layers on it so we have our
input layer our hidden layers and the
output layer this is the sentence that
needs to be recognized by the network
what is the time so when it comes in
each one comes in as a pattern of sound
so what is the time first let's consider
the word what and you have wh ha A T and
you can see each one of those in the
sound bar probably looks a little
different than that just a
representation comes com in as a
different pattern now we will split the
sound wave for the letter W into smaller
segments so we split off W and then we
take W and we analyze just W as the
amplitude is varying in the sound wave
for w we collect the values at different
intervals and form an array so we have
0.5 1.5 1.7 1.9 that might be the
different amplitudes coming in and we
feed the array of amplitudes to the
input layer so each one of those goes
into its own box on the input layer
random weights are assigned to each
interconnection between input and hidden
layer so remember all those little lines
I said those are special weights now
we're going to start by doing it
randomly we always start with random
because we start with some kind of
preset identical pattern like if you set
them all to three take forever to train
it and you're less likely to get a good
result where random works really well in
this the weights are multiplied with the
inputs and a bias is added to form the
transfer function so we make a sum of
all the weights times the value so you
take 0 five which is your X coming in
and we're going to multiply that by W1
W2 W3 so on and then we get to the next
level we're going to add those together
coming in what's coming in so we add the
weight time x and there's always a bias
added in if you ever build your own
neural network don't forget to add the
bias in otherwise tends to not work
quite as well you need that extra layer
in there to help it weights are assigned
to the interconnection between the
hidden layers the output of the transfer
function is fed as an input to the
activation function so the output from
one hidden layer becomes the input to
the next hidden layer acoustic model
contains the statistical representation
of each distinct sound that makes a word
and so we start building these
acoustical models and as these layers
separate them out they'll start learning
what the different models are for the
different letters lexicon contains the
data for different pronunciations of
every word so we have the Lexicon at the
end where we end up with the a b c d and
it identifies the different letters in
there now the term acoustic model and
the term lexicon are specific to this
domain the domain of understanding
speech certainly when you're doing
photographs and other things you'll have
different labels on here but the process
is going to be the same and finally we
get our output later following the same
process for every word and letter the
neural network recognizes the sentence
you said what is the time so it
identifies a w ha A T and then
identifies it that's one word what is
the time and so on it's 12:30 that way
Siri can look up the time and read it
back to you so let's look at the
advantages of an artificial neural
network so gentlemen could you tell me
the advantages of an artificial neural
network it's amazing how many times I've
been in that situation where I have to
explain to the people making the
decisions in the company it's amazing
how many times I've been in that space
where I have to explain to the owner of
the company what the artificial
intelligence and the neural network
actually do what are the advantages of
an artificial neural network and what it
can do for them and how it works so an
artificial neural network outputs aren't
limited entirely by inputs and results
given to them initially by an expert
system this disability comes in handy
for Robotics and pattern recognition
systems artificial neural networks have
the potential for high fault tolerance
artificial neural networks are capable
of debugging or diagnosing a network on
their own very common use these days is
to go through all the log files and sort
them out thousands of log files if
you're in working as an admin nonlinear
systems have the capability of finding
shortcuts to reach computational
expensive Solutions so we see this in
banking where by hand they have an Excel
spreadsheet and then they start building
codes around that Excel spreadsheet and
over 20 years they might build a
repertoire of all these functions and
the neural network comes up with the
same answers done in days weeks or even
a month for a huge bank so let's take a
look a little bit more cuz I mentioned a
couple applications of artificial
intelligence there but let's dig deeper
into the applications of artificial
intelligence let's look at some of the
real life this is stuff going on right
now in our world and we're in such an
exciting time with the neural networks
and the Machine learning and the
artificial intelligence development so
let's take a little look at some of the
current applications going on in real
life and you can use your imagination to
dig for some new ones that we don't have
listed here because it's so Limitless
the amount of applications that are
being worked on right now or being
implemented handwriting recognition
neural network is used to convert
handwritten characters into digital
characters that the system can recognize
Stock Exchange prediction if you've ever
worked with Stock Exchange which I have
it is so ficked to track I mean it is
really hard to understand there are many
factors that affect the stock market
neural network can examine a lot of
factors and predict the prices on a
daily basis helping the stock Brokers so
right now it's still at the intro phase
where it helps them and they really have
to look closely at it when you realize
that we generate over 3 terabytes a day
just from the stock exchange here in the
United States that's a lot of data to
dig through and you have to sort it out
before you even start focusing on even
one stock traveling salesman problem it
refers to finding the optimal path to
travel between all cities in an area
neural network helps solve the problem
providing higher Revenue at a minimal
cost Logistics is huge just the
logistics we talk about salesman
traveling from town to town Logistics
are used by Amazon Amazon loves to ship
their packages and they have empty space
on their trucks so they'll pre- ship
packages and fill that empty space on
who they think will buy it saves them a
lot of time and people are a lot happier
cuz they get it tomorrow instead of
having to wait 3 weeks image compression
idea behind data compression neural
network is to store encrypt and recreate
the actual image again so we can
optimize our compression and data images
are the biggest one but it's used in all
kinds of data wonderful application to
save hard drive and to optimize being
able to read it back out again those are
just a few and like I said use your mind
to dig deeper and let's take even
further we're going to go a step further
here and let's look at the future of
deep learning and here we are that's not
me thank goodness wonderful person there
reading her crystal ball I'll tell you
what I see in the future more
personalized choices for users and
customers all over the world I certainly
like that when I go in there and
whatever online ordering system starts
referring stuff to me local company here
where I live that uses this where you
can take a picture and it starts looking
for what you want based on your picture
so if you see a couch you like starts
looking for furniture like that or
clothing I think it's mainly clothing
hyper intelligent virtual assistants
will make life easier if you played with
Google assistant or Siri or any of those
you can see how they're slowly evolving
and they're just now getting over that
hump where a virtual assistant can do
all kinds of things even pre-write your
email response for you new forms of
algorithm for learning methods would be
discovered there's always something
rolling out and they've had some really
cool research in this area again this
stuff is such a we're just in the infant
stage of artificial intelligence and
neural networks and actually applying
them to the real world wonderful time to
jump in neural networks will be a lot
faster in the future neural network
tools will be embedded in every design
surface we already see that that you can
buy a little mini neural network that
plugs into a really cheap processing
board or into your laptop so the
hardware is starting to come out that
goes right in there where you can dump
it on there and that makes it all faster
so because it's on the hardware instead
of the software side neural networks
will be used in the field of medicine
agriculture physics discoveries just
everything you can imagine we see this
today where it's going from a PhD
student in medicine trying to understand
te- cells and understand the statistic
analysis of that to cure people to help
keep them healthy to help find out how
we heal to something that anybody can go
access and process the data on they're
working on shared Data Systems this
concept of it being used in these
different fields and these different
domains is huge the world's wide open
for anybody jumping out there to start
exploring them and start learning neural
networks so looking at that let's dive
into what is deep learning now your
first thought might be it's the opposite
of shallow learning learning no deep
learning I liken to a magic box and
let's go in there and just take a look
as to why is kind of a magic box so what
exactly is deep learning these are the
images of dogs deep learning is a
machine learning technique that teaches
computers to do what comes naturally to
humans learn by example the robot gets
trained with photos as example now this
is very different than hardwiring a
computer program so that it recognizes
something it actually learns and that's
where it's a magic box because you don't
really control how it learns you control
the aspects that go in the computer
comes back and says wait I know what you
are looks at the photograph of the dog
and it's able to identify that it saw in
the images it says you are a dog woof
woof so that's an example of deep
learning you'll notice we didn't go in
we'll go into the actually how it works
behind the scenes for a neural network
but there's a bit filling of magic and
that's where the term deep learning
comes in and that's also the term well I
like to call it a magic box you put
these things in here into the program
and it starts running the Deep learning
and you have to understand those sets
settings but you don't have to follow
the exactly what's going on in the Deep
learning model that brings us to the
question how does deep learning do it
remember the neuron scientists managed
to build an artificial form of it that
powers any deep learning based machine
so let's talk about artificial neural
networks what is an artificial neural
network to understand how an artificial
neuron works we need to understand how
the real one works first we have a
dendrite input to the neuron and you can
see these little hairs that come in and
they receive information then we have
the cell body information processing
happens here so it takes all these
different dendrite and information
coming in from the different dendrites
and it looks at that information and
then you have your axon which is the
output to the neuron so there goes your
axon and you see it goes all the way out
and at the very end it flanges out each
one of those little flanges connects to
the dendrite or the hairs on the next
one now let's see what an artificial
neural network looks like so an
artificial neural network we have an
input layer so that could be an array of
data each one of those white dots in the
yellow bar would represent say a pixel
in a picture then you have the lines
that connected to the hidden layers
which are your weights and they add all
those up on the hidden layers in each
one of those dots kind of like a cell
does something with all the inputs and
then it puts an output into the next
hidden layer and so on into the output
layer so information processing happens
here input to the neuron output to the
neuron so you can see how they are
similar we have an input which is our
yellow bar coming in and then you each
of the Hidden layers to being a neuron
and it passes it to the next one and so
on and then you have an output to the
next neuron or an output to the real
world a neural network is a system of
Hardware Andor software patterned after
the operation of neurons in the human
brain neural networks also called
artificial neural networks is a way of
achieving deep learning how does
artificial neural networks work let us
find out how does an artificial neuron
Network work hey Siri what is the time
now it's 12:30 in the morning thanks
let's find out how she recognizes speech
here is a neural network and the
different layers on it so we have our
input layer our hidden layers and the
output layer this is the sentence that
needs to be recognized by the network
what is the time so when it comes in
each one comes in as a pattern of sound
so what is the time first let's consider
the word what and you have W ha and you
can see each one of those in the sound
bar probably looks a little different
than that just a representation comes in
as a different pattern now we will split
the sound wave for the letter W into
smaller segments so we split off W and
then we take W and we analyze just W as
the amplitude is varying in the sound
wave for w we collect the values at
different intervals and form an array so
we have 0.5 1.5 1.7 1.9 that might be
the different amplitudes coming in and
we feed the array of amplitudes to the
input layer so each one of those goes
into its own box on the input layer
random weights are assigned to each
interconnection between input and hidden
layer so remember all those little lines
I said those are special weights now
we're going to start by doing it
randomly we always start with random
because if we start with some kind of
preset identical pattern like if you set
them all to three take forever to train
it and you're less likely to get a good
result where random works really well in
this the weights are multiplied with the
inputs and a bias is added to form the
transfer function so we make a sum of
all the weights times the value so you
take 0. five which is your X coming in
and we're going to multiply that by W1
W2 W3 so on and then we get to the next
level we're going to add those together
coming in what's coming in so we add the
weight times x and there's always a bias
add it in if you ever build your own
neural network don't forget to add the
bias in otherwise tends to not work
quite as well you need that extra layer
in there to help it weights are assigned
to the interconnection between the
hidden layers the output of the transfer
function is fed as an input to the
activation function so the output from
one hidden layer becomes the input to
the next hidden layer acoustic model
contains means the statistical
representation of each distinct sound
that makes a word and so we start
building these acoustical models and as
these layers separate them out they'll
start learning what the different models
are for the different letters lexicon
contains the data for different
pronunciations of every word so we have
the Lexicon at the end where we end up
with the a b c d and it identifies the
different letters in there now the term
acoustic model and the term lexicon are
specific to this domain the domain of
understanding speech certainly when
you're doing photographs and other
things you'll have different labels on
here but the process is going to be the
same and finally we get our output later
following the same process for every
word and letter the neural network
recognizes the sentence you said what is
the time so it identifies a w ha A T and
then identifies that that's one word
what is the time and so on it's 12:30
that way Siri can look up the time and
read it back to you so let's look at the
advantages of an artificial neural
network so gentlemen could you tell me
the advantages of of an artificial
neural network it's amazing how many
times I've been in that situation where
I have to explain to the people making
the decisions in the company it's
amazing how many times I've been in that
space where I have to explain to the
owner of the company what the artificial
intelligence and the neural network
actually do what are the advantages of
an artificial neural network and what it
can do for them and how it works so an
artificial neural network outputs aren't
limited entirely by inputs and results
given to them initially by an expert
system this ability comes in handy for
Robotics and pattern recognition systems
artificial neural networks have the
potential for high fault tolerance
artificial neural networks are capable
of debugging or diagnosing a network on
their own very common use these days is
to go through all the log files and sort
them out thousands of log files if
you're in working as an admin nonlinear
systems have the capability of finding
shortcuts to reach computational
expensive Solutions so we see this in
banking where by hand they have an Excel
spreadsheet and then they start building
codes around that Excel spreadsheet and
over 20 years they might build a
repertoire of all these functions and
the neural network comes up with the
same answers done in days weeks or even
a month for a huge bank so let's take a
look a little bit more CU I mentioned a
couple applications of artificial
intelligence there but let's dig deeper
into the applications of artificial
intelligence let's look at some of the
real life this is stuff going on right
now in our world we're in such an
exciting time with the neural networks
and the machine learning and the
artificial intelligence development so
let's take a little look at some of the
current applications going on in real
life and you can use your imagination to
dig for some new ones that we don't have
listed here because it's so Limitless
the amount of applications that are
being worked on right now or being
implemented handwriting recognition
neural network is used to convert
handwritten characters into digital
characters that the system can recognize
Stock Exchange prediction if you've ever
worked with Stock Exchange which I have
it is so ficked to track I mean it is
really hard to understand there are many
factors that affect the stock market
neural network can examine a lot of
factors and predict the prices on a
daily basis helping the stock Brokers so
right now it's still at the intro phase
where it helps them and they really have
to look closely at it when you realize
that we generate over 3 terabytes a day
just from the stock exchange here in the
United States that's a lot of data to
dig through and you have to sort it out
before you even start focusing on even
one stock traveling salesman problem it
refers to finding the optimal path to
travel between all cities in an area
neural network helps solve the problem
providing higher Revenue at a minimal
cost Logistics is huge just the
logistics we talk about salesman
traveling from town to town Logistics
are used by Amazon Amazon loves to ship
their packages and they have empty space
on their trucks so they'll pre- ship
packages and fill that empty space on
who they think will buy it saves them a
lot of time and people are a lot happier
cuz they get it tomorrow instead of
having to wait 3 weeks image compress
idea behind data compression neural
network is to store encrypt and recreate
the actual image again so we can
optimize our compression in data images
are the biggest one but it's used in all
kinds of data wonderful application to
save hard drive and to optimize being
able to read it back out again those are
just a few and like I said use your mind
to dig deeper and let's take even
further we're going to go a step further
here and let's look at the future of
deep learning and here we are that's not
me thank goodness wonderful person there
reading her crystal ball I'll tell you
what I see in the future
more personalized choices for users and
customers all over the world I certainly
like that when I go in there and
whatever online ordering system starts
referring stuff to me local company here
where I live that uses this where you
can take a picture and it starts looking
for what you want based on your picture
so if you see a couch you like starts
looking for furniture like that or
clothing I think it's mainly clothing
hyper intelligent virtual assistant will
make life easier if you played with
Google assistant or Siri or any of those
you can see how they're slowly evolving
and they're just now getting over that
hump where a virtual assistant can do
all kinds of things even pre-write your
email response for you new forms of
algorithm for learning methods would be
discovered there's always something
rolling out and they've had some really
cool research in this area again this
stuff is such that we're just in the
infant stage of artificial intelligence
and neural networks and actually
applying them to the real world
wonderful time to jump in neural
networks will be a lot faster in the
future neural network tools will be
embedded in every design surface we
already see that that you can buy a
little mini neural network that plugs
into a really cheap processing board or
into your laptop so the hardware is
starting to come out that goes right in
there where you can dump it on there and
that makes it all so faster so because
it's on the hardware instead of the
software side neural networks will be
used in the field of medicine
agriculture physics discoveries just
everything you can imagine we see this
today where it's going from a PhD
student in medicine trying to understand
t cells and understand the statistic
analysis of that to cure people to help
keep them healthy to help find out how
we heal to something that anybody can go
access and process the data on they're
working on shared Data Systems this
concept of it being used in these
different fields and these different
domains is huge the world's wide open
for anybody jumping out there to start
exploring them and start learning neural
networks let's dive in and say how does
a neural network work so now we've come
far enough to understand how neural
network works let's go ahead and walk
through this in a nice graphical
representation they usually describe a
neural network as having different
layers and you'll see that we've
identified a Green Layer an orange layer
and a red layer the Green Layer is the
input so you have your data coming in it
picks up the input signals and passes
them to the next layer the next layer
does all kinds of calculations and
feature extraction it's called The
Hidden layer a lot of times there's more
than one hidden layer we're only showing
one in this uh picture but we'll show
you how it looks like in a more detail
in a little bit and then finally we have
an output layer this layer delivers the
final result so the only two things we
see is the input layer and the output
layer now let's make use of this neural
network and see how it works wonder how
traffic cameras identify Vehicles
registration plate on the road to detect
speeding vehicles and those breaking the
law they got me going through a red
light the other day well last month
that's like the horrible thing they send
you this picture of you and all your
information cuz they pulled it up off of
your light Li plate and your picture
that shouldn't have gone through the red
light so here we are and we have an
image of a car and you can see the
license plates on there so let's
consider the image of this vehicle and
find out what's on the number plate the
picture itself is 28x 28 pixels and the
image is fed as an input to identify the
registration plate each neuron has a
number called activation that represents
the grayscale value of the coresponding
pixel range and we range it from 0o to
one one for a white pixel and zero for a
black pixel and you can see down here we
have an example where one of the pixels
is registered as like 082 meaning it's
probably pretty dark each neuron is lit
up when its activation is close to one
so as we get closer to black on white we
can really start seeing the details in
there and you can see again the pixel
shows this one up there it's like part
of the car and so it lights up so pixels
in the form of arrays are fed to the
input layer and so we see here the pixel
of a car image fed as an input and
you're going to see that the input layer
which is green is one dimension while
our image is two Dimension now when we
look at our setup that we're programming
in Python it has a cool feature that
automatically does the work for us if
you're working with an older neural
network pattern package you then convert
each one of those rows so it's all one
array so you'd have like Row one and
then just tack row two onto the end you
can almost feed the image directly into
some of these neural networks the key is
though is that if you're using a 28x 28
and you get a picture of this 30x30
shrink the 30x30 down to fit the 28x 28
so you can't can't increase the number
of input in this case Green Dots it's
very important to remember when you're
working on neural networks and let's
name the inputs X1 X2 X3 respectively so
each one of those represents one of the
pixels coming in and the input layer
passes it to the hidden layer and you
can see here we now have two hidden
layers in this image in the orange and
each one of those pixels connects to
each one of those hidden layers and the
interconnections are assigned weights at
random so they gets these random weights
that come through if X1 lights up then
it's going to be X1 * this weight going
into the hidden layer and we sum those
weights the weights are multiplied with
the input signal and a bias is added to
all of them so as you can see here we
have X1 comes in and it actually goes to
all the different hidden layer nodes or
in this case uh whatever you want to
call them network setup the orange dots
and so you take the value of X1 you
multiply it by the weight for the next
hidden layer so X1 goes to Hidden layer
one X1 goes to Hidden layer 2 x one goes
hidden layer one node two hidden layer
one node three and so on and the bias a
lot of times they just put the bias in
as like another Green Dot or another
orange Dot and they give the bias a
value one and then all the weights go in
from the bias into the next note so the
bias can change we always just remember
that you need to have that bias in there
there's things that can be done with it
generally most the packages out there
control that for you so you don't have
to worry about figuring out what the
bias is but if you ever dive deep into
neural networks you got to remember
there's a bias or the answer won't come
out correctly the weighted sum of the
input is fed as an input to the
activation function to decide which
nodes to Fire and for feature extraction
as a signal flows within the hidden
layers the weighted sum of inputs is
calculated and is fed to the activation
function in each layer to decide which
nodes to fire so here's our feature
extraction of the number plate and you
can see these are still hidden nodes in
the middle and this becomes important
we're going to take a little detour here
and look at the activ ation function so
we're going to dive just a little bit
into the math so you can start to
understand where some of the games go on
when you're playing with neural networks
in your programming so let's look at the
different activation functions before we
move ahead here's our friendly red tag
shopping robot and so one is the sigmoid
function and the sigmoid function which
is 1 over 1 + e to the minus X takes the
x value and you can see where it
generates almost a zero and almost a one
with a very small area in the Middle
where it crosses over and we can use
that value to feed into another function
so if it's really uncertain it might
have a 0.1 or Point 2 or3 but for the
most part it's going to be really close
to one and really close to this case
Zero 0 to one the threshold function so
if you don't want to worry about the
uncertainty in the middle you just say
oh if x is greater than or equal to zero
if not then uh X is zero so it's either
zero or one really straightforward
there's no in between in the middle and
then you have the what they call the ru
relo function and you you can see here
where it puts out the value but then it
says well if it's over one it's going to
be one and if it's uh less than zero
it's zero so it kind of just dead ends
it on those two ends but allows all the
values in the middle and again this like
the sigmoid function allows that
information to go to the next level so
it might be important to know if it's a
0.1 or a minus 0.1 the next hidden layer
might pick that up and say oh this piece
of information is uncertain or this
value has a very low certainty to it and
then the hyperbolic t function and you
can see here it's a 1 - e - 2x over 1 +
e - 2x and it's very much along the same
theme a little bit different in here and
that it goes between minus one and one
so you'll see some of these they go 0 to
one but this one goes minus one to one
and if it's less than zero it's you know
it doesn't fire and if it's over zero it
fires and it also still puts out a value
so you still have a value you can get
off of that just like you can with the
sigmoid function and the relo function
very similar in use and I believe the
originally used to be everything was
done in the sigmoid function that was
the most uh commonly used and now they
just kind of use more the relo function
the reason is one it processes faster
because you already have the value and
you don't have to add another compute
the one over 1 plus e to the minus X for
each hidden node and the data coming off
works pretty good as far as putting it
into the next level if you want to know
just how close it is to zero how close
is it not to functioning you know is it
minus .1 minus point2 usually they're
float values get like minus pointus 0138
or something so you know important
information but the relu is most
commonly used these days as far as the
setup we're using but you'll also see
the sigmoid function very commonly used
also now that you know what an
activation function is let's get back to
the neural network so finally the model
would predict the outcome of applying a
suitable activation function to the
output layer so we go in here we look at
this we have the optical character
recognition OCR is used on the images to
convert it into a text in in order to
identify what's written on the plate and
as it comes out you'll see the red node
and the red node might actually
represent just a letter A so there
usually a lot of outputs when you're
doing text identification we're not
going to show that on here but you might
have it even in the order it might be um
what order the license plates in so you
might have AB bcde e FG you know the
alphabet plus the numbers and you might
have the 1 2 3 4 5 6 7 8 nine 10 places
so it's a very large array that comes
out it's not a small amount of uh you
know we show three dots coming in eight
hidden layer nodes you know two sets of
four we just show one red coming out a
lot of times this is uh you know 28 * 28
if you did 30 * 30 that's you know 900
nodes so 28 is a little bit less than
that uh just on the input and so you can
imagine the hidden layer is just as big
each hidden layer is just as big if not
bigger then the output is going to be
there's so many digits you know it's a
lot it's a huge amount of input and
output but we're only showing you just
you know be hard to show in one picture
and so it comes up and this is what it
finally gets out in the output is
identifies a number on the plate and in
this case we have 08- D-
03858 error in the output is back
propagated through the network and
weights are adjusted to minimize the
error rate this is calculated by a cost
function when we're training our data
this is what's used and we'll look at
that in the code when we do the data
training so we have stuff we know the
answer to and then we put the
information through and it says yes yes
that was correct or no because remember
we randomly set all the weights to begin
with and if it's wrong we take that
error how far off are you you know are
you off by is it if it was like minus
one you're just a little bit off if it's
like minus 300 was your output remember
when we're looking at those different
options you know hyperbolic or whatever
and we're looking at the re the RL could
doesn't have an limit on top or bottom
it actually just generates a number so
if it's way off you have to adjust those
weights a lot but if it's pretty close
you might adjust the weights just a
little little bit and you keep adjusting
the weights until they fit all the
different training models you put in so
you might have 500 training models and
those weights will adjust using the back
propagation it sends the error backward
the output is compared with the original
result and multiple iterations are done
to get the maximum accuracy so not only
does it look at each one but it goes
through it and just keeps cycling
through these the data making small
changes in the network until it gets the
right answers with every iteration the
weights at every interconnection are
adjusted based on the error we're not
going to dive into that math because it
is a differential equation and it gets a
little complicated but I will talk a
little bit about some of the different
options they have when we look at the
code so we've explored a neural network
let's look at the different types of
artificial neural networks and this is
like the biggest area growing is how
these all come together let's see the
different types of neural network and
again we're comparing this to human
learning so here's a human brain I feel
sorry for that poor guy so we have a
feed for forward neural network simplest
form of a they call it an Ann a neural
network data travels only in One
Direction input to Output this is what
we just looked at so as the data comes
in all the weights are added it goes to
the hidden layer all the weights are
added it goes to the next hidden layer
all the weights are added and it goes to
the output the only time you use the
reverse propagation is to train it so
when you actually use it it's very fast
when you training it it takes a while
because it has to iterate through all
your training data and you start getting
into Big Data because you can train
these with a huge amount of data the
more data you put in the better trained
they get the applications vision and
speech recognition actually they're
pretty much everything we talked about a
lot of almost all of them use this form
of neural network at some level radio
basis function neural network this model
classifies the data point based on its
distance from a Center Point what that
means is that you you might not have
training data so you want to group
things together and you create Central
points and it looks for all the things
you know some of these things are just
like the other if you've ever watched
the Sesame Street as a kid that dates me
so it brings things together and this is
a great way if you don't have the right
training model you can start finding
things that are connected you might not
have noticed before applications power
restoration systems they try to figure
out what's connected and then based on
that they can fix the problem if you
have a huge power system and self
organizing neural network vectors of
random dimensions are input to discrete
map comprised of neurons so they
basically find a way to draw they call
them they say Dimensions or vectors or
planes because they actually chop the
data in one dimension two Dimension
three dimension four five six they keep
adding dimensions and finding ways to
separate the data and connect different
data pieces together applications used
to recognize patterns in data like in
medical analysis the hidden layer saves
its out outut to be used for future
prediction recurrent neural networks so
the hidden layers remember its output
from last time and that becomes part of
its new input uh you might use that
especially in robotics or flying a drone
you want to know what your last change
was and how fast it was going to help
predict what your next change you need
to make is to get to where the Drone
wants to go applications text to speech
conversation model so you know I talked
about drones but you know just
identifying on Lexus or Google assistant
or any of these they're starting to add
in I'd like to play a song on my Pandora
and I'd like it to be at volume 90% so
you now can add different things in
there and it connects them together the
input features are taken in batches like
a filter this allows a network to
remember an image in Parts convolution
neural network today's world in photo
identification and taking apart photos
and trying to you know have you ever
seen that on Google where you have five
people together this is the kind of
thing separates all those people people
so then it can do a face recognition on
each person applications used in signal
and image processing in this case I use
facial images or Google picture images
as one of the options modular neural
network it has a collection of different
neural networks working together to get
the output so wow we just went through
all these different types of neural
networks and the final one is to put
multiple neural networks together and I
mentioned that a little bit when we
separated people in a larger photo in
individuals in the photo and then do the
facial recognition on each person so one
network is used to separate them and the
next network is then used to figure out
who they are and do the facial
recognition applications still
undergoing research this is a Cutting
Edge you hear the term Pipeline and
there's actual in Python code and in
almost all the different neural network
setups out there they now have a
pipeline feature usually and it just
means you take the data from one neural
network and maybe another neural network
or you put it into the next neural
network and then you take three or four
other neural networks and feed them into
another one so how we connect the neural
networks is really just Cutting Edge and
it's so experimental I mean it's almost
creative in its nature there's not
really a science to it because each
specific domain has different things
it's looking at so if you're in the
banking domain it's going to be
different than the medical domain than
the automatic car domain and suddenly
figuring out how those all fit together
is just a lot of fun and really cool so
we have our types of artificial neural
network we have our feed forward neural
network we have our radial basis
function neural network we have our
cohenon self-organizing neural network
recurrent neural network convolution
neural network and modular neural
network where brings them all together
and U Know the colors on the brain do
not match what your brain actually does
but they do bring it out that most of
these were developed by understanding
how humans learn and as we understand
more and more of how humans learn we can
build something in the computer IND
industry to mimic that to reflect that
and that's how these were developed so
exciting part use case problem statement
so this is where we jump in this is my
favorite part let's use the system to
identify between a cat and a dog if you
remember correctly I said we're going to
do some python code and you can see over
here my hair is kind of sticking up over
the computer cup of coffee on one side
and a little bit of old school a pencil
and a pen on the other side yeah most
people Now take notes I love the
stickies on the computer that's great
that's that is my computer I have sticky
notes on my computer in different colors
so not too far from uh today's
programmer so the problem is is where we
want to classify photos of cats and dogs
using a neural network and you can see
over here we have quite a variety of
dogs in the pictures and cats and you
know just sorting out it is a cat is
pretty amazing and why would anybody
want to even know the difference between
a cat and a dog okay you know why well I
have a cat door it'd be kind of fun that
instead of it identifying instead of
having like a little collar with a
magnet on it which is what my cat has
the door would be able to see oh that's
the cat that's our cat coming in oh
that's the dog we have a dog too that's
a dog I want to let in maybe I don't
want to let this other animal in cuz
it's a raccoon so you can see where you
could take this one step further and
actually apply this you could actually
start a little startup company idea
self-identifying door so this use case
will be implemented on python I am
actually in Python 3.6 it's always nice
to tell people the version of python cuz
that does affect sometimes which modules
you load and everything and we're going
to start by importing the required
packages I told you we're going to do
this in carass so we're going to import
from carass Models a sequential from the
carass layers conversion 2D or Co NV 2D
Max pooling 2D flatten and d and we'll
talk about what each one of these do in
just a second but before we do that
let's talk a little bit about the
environment we're going to work in and
uh you know in fact let me go ahead and
open a uh the website cross's website so
we can learn a little bit more about
carass so here we are on the carass
website and it's uh
k. that's the official website for
carass and the first thing you'll notice
is that carass runs on top of either
tensorflow cntk and I think it's
pronounced thano or theano what's
important on here is that tensorflow and
the same is true for all these but
tensorflow is probably one of the most
widely used currently packages out there
with the carass and of course you know
tomorrow this is all going to change
it's all going to disappear and they'll
have something new out there so make
sure when you're learning this code that
you understand what's going on and also
know the code I mean when you look at
the code it's not as complicated once
you understand what's going on the code
itself is pretty straightforward and the
reason we like carass and the reason
that people are jumping on it right now
it's such a big deal is if we come down
here let me just scroll down a little
bit they talk about user friendliness
modularity easy extensibility work with
python Python's a big one because a lot
of people in data science now use python
although you can actually access caros
other ways is if we continue down here
is layers and this is where it gets
really cool when we're working with
carass you just add layers on remember
those hidden layers we were talking
about and we talked about the
ru activation you can see right here let
me just up that a little bit in size
there we go that's big I can add in an
Ru layer and then I can add in a softmax
layer the next instance we didn't talk
about soft Max so you can do each layer
separate now if I'm working in some of
the other kits I use I take that and I
have one setup and then I feed the
output into the next one this one I can
just add hidden layer after hidden layer
with the different information in it
which makes it very powerful and very
fast to spin up and try different setups
and see how they work with the data
you're working on and we'll dig a little
bit deeper in here and a lot of this is
very much the same so when we get to
that part I'll point that out to you
also now just a quick side note I'm
using Anaconda with python in it and I
went ahead and created my own own
package and I called it the carass
python 36 cuz I'm in Python 36 Anaconda
is cool that way you can create
different environments really easily if
you're doing a lot of different
experimenting with these different
packages probably want to create your
own environment in there and the first
thing is you can see right here there's
a lot of dependencies a lot of these you
should recognize by now if you've done
any of these videos if not kudos for you
for jumping in today pip install numpy
scipi the S kit learn pillow and
h5py are both needed for the tensor flow
and then putting the carass on there and
then you'll see here uh and pip is just
a standard installer that you use with
python you'll see here that we did pip
install tensorflow since we're going to
do carass on top of tensor flow and then
pip install and I went ahead and used
the GitHub so get plus get and you'll
see here github.com this is one of their
releases one of the most current release
on there that goes on top of tensorflow
and you can look up these instructions
pretty much anywhere this is for doing
it on Anaconda certainly you'd want to
install these if you're you're doing it
in auntu server setup you you want to
get I don't think you need the h5py and
a buntu but you do need the rest in
there because they are dependencies in
there and it's pretty straightforward
and that's actually in some of the
instructions they have on their website
so you don't have to necessarily go
through this just remember their website
on there and then when I'm under my uh
Anaconda Navigator which I like you'll
see where I have environments and on the
bottom I created a new environment and I
called it carass python 36 just to
separate everything you can say have
python 3.5 and Python 3 6 I used to have
a bunch of other ones but I kind of
cleaned house recently and of course
once I go in here I can launch my
Jupiter notebook making sure I'm using
the right environment that I just set up
this of course opens up my um in this
case I'm using uh Google Chrome and in
here I could go and just create a new
document in here and this is all in your
um browser Winer when you use the
Anaconda do you have to use anaconda in
Jupiter notebook no you can use any kind
of python editor whatever setup you're
comfortable with with and whatever
you're doing in there so let's go ahead
and go in here and paste the code in and
we're importing a number of different
settings in here we have import
sequential that's under the models
because that's the model we're going to
use as far as our neural network and
then we have layers and we have
conversion 2D Max pooling 2D flatten DSE
and you can actually just kind of guess
at what these do we're talking we're
working in a 2d photograph and if you
remember correctly I talked about how
the actual input layer is a single array
it's not in two Dimensions just one
dimension all these do is these are
tools to help flatten the image so it
takes a two dimensional image and then
it creates its own proper setup you
don't have to worry about any of that
you don't have to do anything special
with the photograph you let the carass
do it we're going to run this and you'll
see right here they have some stuff that
is going to be depreciated and changed
because that's what it does everything's
being changed as we go you don't have to
worry about that too much if you have
warnings if you run it a second time the
warning will disappear and this has just
imported these packages for for us to
use Jupiter's nice about this that you
can do each thing step by step and I'll
go ahead and also zoom in there a little
control plus that's one of the nice
things about being in a browser
environment so here we are back another
sip of coffee if you're familiar with my
other videos you notice I'm always
sipping coffee I always have a my case
latte next to me an espresso so the next
step is to go ahead and initialize we're
going to call it the CNN or classifier
neural network and the reason we call it
a classifier is cuz it's going to
classify between two things it's going
to be cat or dog so when you're doing
classification you're picking specific
objects you're specific it's a true or
false yes no it is something or it's not
so first thing we're going to create our
classifier and it's going to equal
sequential so their sequential setup is
the classifier that's the actual model
we're using that's the neural network so
we call it a classifier and uh the next
step is to add in our convolution and
let me just do a uh let me shrink that
down inside so you can see the whole
line and let's talk a little bit about
what's going on here I have my
classifier and I add something what am I
adding well I'm adding my first layer
this first layer we're adding in is
probably the one that takes the most
work to make sure you have it set
correct and the reason I say that is
this is your actual input and we're
going to jump here to the part that says
input shape equals 64 by 64 by three
what does that mean well that means that
our picture's coming in and there's
these pictures remember we had like the
picture of the car was 128x 128 pixels
well this one is 64x 64 pixels and each
pixel has three values that's where
these numbers come from and it is so
important that this matches I mentioned
a little bit that if you have like a
larger picture you have to reformat it
to fit this shape if it comes in as
something larger there's no input notes
there's no input neural network there
that will handle that extra space so you
have to reshape your data to fit in here
now the first layer is the most
important because after that carass
knows what your shape is coming in here
and it knows what's coming out and so
that really sets the stage most
important thing is that input shape
matches your data coming in and you'll
get a lot of Errors if it doesn't you'll
go through there and picture number 55
doesn't match it correctly and guess
what it does it usually gives you an
error and then the activation if you
remember we talked about the different
activations on here we're using the ru
model like I said that is the most
commonly used now because one it's fast
doesn't have the added calculations in
it it just says here's a value coming
out based on the weights and the value
going in and um from there you know it's
uh it's if it's over one then it's good
or over zero it's good if it's under
zero then it's considered not active and
then we have this conversion 2D what the
heck is conversion 2D I'm not going to
go into too much detail in this because
this has a couple things it's doing in
here here a little bit more in-depth
than we're ready to cover in this
tutorial but this is used to convert
from the photo cuz we have 64x 64 by3
and we're just converting it to
two-dimensional kind of setup so it's
very aware that this is a photograph and
that different pieces are next to each
other and then we're going to add in h a
second convolutional layer that's what
the co NV stands for 2D so it's these
are hidden layers so we have our input
layer and our two hidden layers and they
are two-dimensional because we're doing
with a two-dimensional photograph and
you'll see down here that on the last
one we add a Max pooling 2D and we put a
pool size equals 22 and so what this is
is that as you get to the end of these
layers one of the things you always want
to think of is what they call mapping
and then reducing wonderful terminology
from the Big Data we're mapping this
data through all these layers and now we
want to reduce it to only two sets in
this case it already in two sets CU it's
a 2d photograph but we had you know two
Dimensions by we actually have 64x 6 4x3
so now we're just getting it down to a
2X two just the two-dimension
two-dimensional instead of having the
third dimension of colors and we'll go
ahead and run these we're not really
seeing anything on our run script
because we're just setting up this is
all set up and this is where you start
playing CU maybe you'll add a different
layer in here to do something else to
see how it works and see what your
output is that's what makes carass so
nice is I can with just a couple flips
of code put in a whole new layer that
does a whole new processing and see
whether that improves my run or makes it
worse and finally we're going to do the
final setup which is to flatten
classifier add a flatten setup and then
we're going to also add a layer dense
layer and then we're going to add in
another dense layer and then we're going
to build it we're going to compile this
whole thing together so let's flip over
and see what that looks like and we've
even numbered them for you so we're
going to do the flattening and flatten
is exactly what it sounds like we've
been working in a two-dimensional array
of picture which actually is in three
dimensions because of the pict pixels
the pixels have a whole another
dimension to it of three different
values and we' kind of resized those
down to 2x two but now we're just going
to flatten it I don't want to have
multiple Dimensions being worked on by
tensor and by carass I want just a
single array so it's flattened out and
then step four full connection so we add
in our final two layers and you could
actually do all kinds of things with
this you could actually leave out this
some of these layers and play with them
you do need to flatten it that's very
important then we want to use the dents
again we're taking this and we're taking
whatever came into it so once we take
all those different the two Dimensions
or three dimensions as they are and we
flatten it to one dimension we want to
take that and we're going to pull it
into units of 128 they got that you're
say where did they get 128 from you
could actually play with that number and
get all kinds of weird results but in
this case we took the 64 plus 64 is 128
you could probably even do this with 64
or 32 usually want to keep it in the
same multiple whatever the data shape
you're already using is in and we're
using the activation the r l u just like
we did before and then we finally filter
all that into a single output and it has
how many units one why because we want
to know whether true or false it's
either a dog or a cat you could say one
is dog zero is cat or maybe you're a cat
lover and it's one is cat and zero is
dog and if you love both dogs and cats
you're going to have to choose and then
we use the sigmoid activat if you
remember from before we had the reu and
there's also the sigmoid the sigmoid
just makes it clear it's yes or no we
don't want to any kind of in between
number coming out and we'll go ahead and
run this and you'll see it's still all
in setup and then finally we want to go
ahead and compile and let's put the
compiling our um classifier neural
network and we're going to use the
optimizer atom and I hinted at this just
a little bit before where does atom come
in where does an Optimizer come in well
the optimizer is reverse propagation
when we're training it it goes all the
way through and says error and then how
does it readjust those weights there are
a number of them atom is the most
commonly used and it works best on large
data most people stick with the atom
because when they're testing on smaller
data see if their model is going to go
through and get all their errors out
before they run it on larger data sets
they're going to run it on atom anyway
so they just leave it on atom most
commonly used but there are some other
ones out there you should be aware of
that that you might try if you're stuck
in a bind or you might blore that in the
future but usually Adam is just fine on
there and then you have two more
settings you have loss and metrics we're
not going to dig too much into loss or
metrics these are things you really have
to explore carass because there are so
many choices this is how it computes the
error there's so many different ways to
on your back propagation and your
training so we're using the atom model
but you can compute the error by um
standard deviation standard deviation
squared they use binary crossentropy I'd
have to look that up even know what that
is there's so many of these a lot of
times you just start with the ones that
look correct that are most commonly used
and then you have to go read the coros
site and actually see what these
different losses and metrics and what
different options they have so we're not
going to get too much into them other
than to reference you over to the carass
website to explore them deeper but we
are going to go aead and run them and
now we've set up our classifier so we
have an object classifier and if you go
back up here you'll see that we've added
in step one we added in our layer for
the input we added a layer that comes in
there and uses the reu for Activation
and then it pulls the data so this is
even though these are two layers the
actual neural network layer is up here
and then it uses this to pull the data
into a 2X two so into a two-dimensional
array from a three-dimensional array
with the colors then we flatten it so
there's our add our flatten and then we
add another dense what they call dense
layer this dense layer goes in there and
it downsizes it to 128 it reduces it so
you can look at this as uh we're mapping
all this data down the two-dimensional
setup and then we flatten it so we map
it to a flatten map and then we take it
and reduce it down to 128 and we use the
reu again and then finally we reduce
that down to just a single output and we
use the sigmoid to do that to figure out
whether it's yes no true false in this
case cat or dog and then finally once we
put all these layers together we compile
them that's what we've done here and
we've compiled them as far as how it
trains to use the settings for the
training back propagation so if you
remember we talked about training our
setup and when we go into this you'll
see that we have two data sets we have
one called the training set and the
testing set and that's very standard in
any data processing is you need to have
that's pretty common in any data
processing is you need to have a certain
amount of data to train it and then you
got to know whether it works or not is
it any good and that's why you have a
separate set of data for testing it
where you already know the answer but
you don't want to use that as part of
the training set so in here we jump into
part two fitting the classifier nuron
network to the images and then from
caros let me just zoom in there I always
love that about working with Jupiter
notebooks you can really see we're going
to come in here we do the cross
pre-processing an image and we import
image data generator it's so nice of
carass it's such a high-end product
right now going out and since images are
so common they already have all this
stuff to help us process the data which
is great and so we come in here we do
train data gen and we're going to create
our object for helping us train for
reshaping the data so that it's going to
work with our setup and we use an image
data generator and we're going to
rescale it and you'll see here we have
one point which tells us it's a float
value on the rescale over 255 where does
255 come from well that's the scale in
the colors of the pictures we're using
their value from 0 to 255 so we want to
divide it by 255 and it'll generate a
number between 0 and one they have sheer
range and zoom range horizontal flip
equals true and this of course has to do
with if the photos are different shapes
and sizes like I said it's a wonderful
package you really need to dig in deep
to see all the different options you
have for setting up your images for
right now though we're going to just
stick with some basic stuff here and let
me go ahead and run this code and again
it doesn't really do anything because
we're still setting up the preprocessing
let's take a look at this next set of
code and this one is just huge we're
creating the training set so the
training set is going to go in here and
it's going to use our train data gen we
just created flow from directory it's
going to access in this case the path
data set training set that's a folder so
it's going to pull all the images out of
that folder now I'm actually running
this in the folder that the data sets in
so if you're doing the same setup and
you load your data in there and you're
doing this make sure wherever your
Jupiter notebook is saving things to
that you create this path or you can do
the complete path if you need to you
know C colon slash Etc and the target
size the batch size and class mode is
binary so the class is we're switching
everything to a binary value batch size
what the heck is batch size well that's
how many pictures we're going to batch
through the training each time and the
target size 64x 64 a little confusing
but you can see right here that this is
just a general training and you can go
in there and look at all the different
settings for your training set and of
course with different data we're doing
pictures there's all kinds of different
settings depending on what you're
working with let's go ahead and run that
and see what happens and you'll see that
it found 800 images belonging to one
classes so we have 800 images in the
training set and if we're going to do
this with uh the training set we also
have to format the pictures in the test
set now we're not actually doing any
predictions we're not actually
programming the model yet all we're
doing is preparing the data so we're
going to prepare a training set and the
test set so any changes we make to the
training set at this point also have to
be made to the test set so we've done
this thing we've done a train data
generator we've done our training set
and then we also have remember our test
set of data so I'm going to do the same
thing with that I'm going to create a
test data gen and we're going to do this
image data generator we're going to
rescale one over 255 we don't need the
other settings just the single setting
for the test data gen and we're going to
create our test set we're going to do
the same thing we did with the test set
except that we're pulling it from the
test set folder and we'll run that and
you'll see in our test set we found
2,000 images that's about right we're
using 20% of the images as test and 80%
to train it and then finally we've set
up all our data we've set up all our
layers which is where all the work is is
cleaning up that data making sure it's
going in there correctly and we actually
going to fit it we're going to train our
data set and let's see what that looks
like and here we go let's put the
information in here and let's just take
a a quick look at what we're looking at
with our fit generator we have our
classifier do fit generator that's our
back propagation so the information goes
through forward with a picture and it
says oh you're either right or you're
wrong and then the eror goes backward
and reprograms all those weights so
we're training our neural network and of
course we're using the training set
remember we created the training set up
here and then we're going steps per epic
so it's 8,000 steps epic means that that
that's how many times we go through all
the pictures so we're going to rerun
each of the pictures and we're going to
go through the whole data set 25 times
but we're going to look at each picture
during each epic 8,000 times so we're
really programming the heck out of this
and going back over it and then they
have validation data equals test set so
we have our um training set and then
we're going to have our test set to
validate it so we're going to do this
all in one shot and we're going to look
at that and they're going to do 200
steps for each validation and we'll see
what that looks like in just a minute
let's go ahead and run our training here
and we're going to fit our data and as
it goes it says epic 1 of 25 you start
realizing that this is going to take a
while on my older computer it takes
about 45 minutes I have a dual processor
you we're processing uh 10,000 photos
that's not a small amount of photographs
to process so if you're on your laptop
you which I am it's going to take a
while so let's go ahead and uh go get
our cup of coffee and a sip and come
back and see what this looks like so I'm
back you didn't know I was gone that was
actually a lengthy pause there I made a
couple changes and let's discuss those
changes real quick and why I made them
so the first thing I'm going to do is
I'm going to go up here and insert a
cell above and let's paste the original
code back in there and you'll see that
the original thing was steps per epic
8,000 25 epics and validation steps
2,000 and I changed these to 4,000 epics
or 4,000 steps per epic 10 epics and
just 10 validation steps and this will
cause problems if you're doing this as a
commercial release but for demo purposes
this should work and if you remember our
steps per epic that's how many photos
we're going to process in fact let me go
ahead and get my drawing pen out and uh
let's just highlight that right here
well we have 8,000 pictures we're going
through so for each epic I'm going to
change this to 4,000 I'm going to cut
that in half so it's going to randomly
pick 4,000 pictures each time it goes
through an epic and the Epic is how many
processes so this is 25 and I'm just
going to cut that to 10 so instead of
doing 25 runs through 8,000 photos each
which you can do the math of 25 * 8,000
I'm only going to do 10 through 4,000 so
I'm going to run this 40,000 times
through the processes and the next thing
I not you'll you'll want to notice is
that I also changed the validation step
and this would cause some major problems
in releasing because I dropped it all
the way down to 10 but the validation
step does is it says we have 2,000
photos in our training or in our testing
set and we're going to use that for
validation well I'm only going to use a
random 10 of those to validate so not
really the best settings but let me show
you why we did that let's scroll down
here just a little bit and let's look at
the output here and see what that what's
going on there so I've got my drawing
tool back on and you'll see here it
lists a run so each time it goes through
an epic it's going to do 4,000 steps and
this is where the 4,000 comes in so
that's where we have we have epic one of
10 4,000 steps it's randomly picking
half the pictures in the file and going
through them and then we're going to
look at this number right here that is
for the whole epic and that's
2,411 seconds and if you remember
correctly you divide that by 60 you get
minutes if you divide that by 60 you get
hours or you can just divide the whole
thing by 60 * 60 which is 3600 if 3600
is an hour this is roughly 45 minutes
right here and that's 45 minutes to
process half the pictures so if I was
doing all the pictures we're talking an
hour and a half per epic time 36 or no
25 they had 25 up above 25 so that's
roughly a couple days a couple days of
processing well for this demo we don't
want to do that I don't want to come
back the next day plus my computer did a
reboot in the middle of the night so we
look at this and we say okay let's we're
just testing this out my computer that
I'm running this on is a dual core
processor uh runs .9 GHz per second for
a laptop you know it was good about four
years ago but for running something like
this it's probably a little slow so we
cut the time times down and the last one
was validation we're only validating it
on a random 10 photos and this comes
into effect because you're going to see
down here where we have accuracy value
loss value accuracy and loss those are
very important numbers to look at so the
10 means I'm only validating across 10
pictures that is where here we have
value this is ACC is for accuracy value
loss we're not going to worry about that
too much and accuracy now accuracy is
while it's running it's put putting
these two numbers together that's what
accuracy is and value accuracy is at the
end of the Epic what's our accuracy end
of the Epic what is it looking at in
this tutorial we're not going to go so
deep but these numbers are really
important when you start talking about
these two numbers reflect bias that is
really important just put that up there
and bias is a little bit beyond this
tutorial but the short of it is is if
this accuracy which is being our
validation per step is going down and
the value accuracy continues to go up
that means there's a bias that means I'm
memorizing the photos I'm looking at I'm
not actually looking for what makes a
dog a dog what makes a cat a cat I'm
just memorizing them and so the more
this discrepancy grows the bigger the
bias is and that is really the beauty of
the carass neural network it is a lot of
built-in features like this that make
that really easy to track so let's go
ahead and take a look at the next set of
code so here we are into part three
we're going to make a new prediction and
so we're going to bring in a couple
tools for that and then we have to
process the image coming in and find out
whether it's an actual dog or cat if we
can actually use this to identify it and
of course the final step of part three
is to print prediction we'll go ahead
and combine these and of course you can
see me there adding a more sticky notes
to my computer screen hidden behind the
screen and you know last one was don't
forget to feed the cat and the
dog so let's go ah a and take a look at
that and see what that looks like in
code and put that in our Jupiter
notebook all right and let's paste that
in here and we'll start by importing
numpy as NP numpy is a very common
package I pretty much import it on any
python project I'm working on another
one I use regularly is pandas they're
just ways of organizing the data and
then inp is usually the standard in most
machine learning tools as the return for
the data array although you know you can
use the standard data array from Python
and we have coros pre-pressing import
image this that all look familiar
because we're going to take take a test
image and we're going to set that equal
to in this case cat or dog one as you
can see over here and you know what let
me get my drawing tool back on so let's
take a look at this we have our test
image we're loading and in here we have
test image one and this one hasn't data
hasn't seen this one at all so this is
all new oh let me shrink the screen down
let me start that over so here we have
my test image and we went ahead and the
coros processing has this nice image
setup so we're going to load the image
and we're going to alter it to 64 x 64
print so right off the bat we're going
to cross this nice that way it
automatically sets it up for us so we
don't have to redo all our images and
find a way to reset those and then we
use all those to set the image to an
array so again we're all in
pre-processing the data just like we
pre-processed before with our test
information and our training data and
then we use the numpy here's our numpy
that's uh from our um right up here
import nump as NP expand the dimensions
test image axis equal zero so it puts it
into a a single array and then finally
all that work all that pre-processing
and all we do is we run the result we
click on here we go result equals
classifier predict test image and then
we find out well what is the test image
and let's just take a quick look and
just see what that is and you can see
when I ran it it comes up dog and if we
look at those images there it is cat or
dog image number one that looks like a
nice floppy eared lab friendly with his
tongue hanging out it's either that or a
very floppy eared cat I'm not sure which
but according to software it says it's a
dog and uh we have a second picture over
here let's just see what happens when we
run the second picture we can go up here
and change this uh from dog image one to
two we'll run that and it comes down
here and says cat you can see me
highlighting it down there as cat so our
process works you're able to label a dog
a dog and a cat a cat just from the
pictures there we go cleared my drawing
tool and the last thing I want you to
notice when we come back up here to when
I ran it you'll see it has an accuracy
of one and the value accuracy of one
well the value accuracy is the important
one because the value accuracy is what
it actually runs on the test data
remember I'm only testing it on I'm only
validating it on random 10 photos and
those 10 photos just happen to come up
one now when they ran this on the server
it actually came up about
86% this is why cutting these numbers
down so far for a commercial release is
bad so you want to make sure you're a
little careful of that when you're
testing your stuff that you change these
numbers back when you run it on a more
Enterprise computer than your old laptop
that you're just practicing on or
messing with and we come down here and
again you know we had the validation of
cat and so we have successfully built a
neural network that could distinguish
between photos of a cat and a dog
imagine all the other things you could
distinguish imagine all the different
Industries you could dive into with that
just being able to understand those two
difference of pictures what about
mosquitoes could you find the mosquitoes
that bite versus the mosquitoes that are
friendly it turns out the mosquitoes
that bite us are only 4% of the mosquito
population if even that maybe 2% there's
all kinds of industries that use this
and there's so many industries that are
just now realizing how powerful these
tools are just in the photos alone there
is a myriad of Industry sprouting up and
I said it before I'll say it again what
an exciting time to live in with these
tools and that we get to play with back
propagation and gradient descent we're
talking neural networks so we talk about
the neural network this is a simple
nural Network which must be trained to
recognize hatden alphabets a b and c and
you can see here we have our input
coming in in this case we'll look at the
letter a written out on a 28x 28 pixels
so the handwritten outfits are presented
as images of 28x 28 pixels and that
image comes in in this case we have 784
neurons that's 28 * 28 and the initial
prediction is made using random weights
assigned to each Channel and so we have
our forward propagation as you see here
so each node is then their values are
added up and added up and so on going
across and our Network predicts input to
be B with a probability of 0.5 the
predicted probabilities are compared
against the actual probabilities and the
errors calculated so the error is simply
the actual minus predicted and you can
see here where we know it's not C so
it's a minus two we know it's not B so
it's a minus .5 but we do know that it
is a um a so we go ahead and adjust that
by 6 the magnitude indicates the amount
of change while the sign indicates an
increase or decrease in the weight
the information is transmitted back
through the network so here comes our
back propagation weights throughout the
network are adjusted in order to reduce
the loss in prediction so if we look at
this setup right here Here Comes our
error in this case 6 minus5 minus point2
that comes up and adjusts our 1.4.9 all
our multipliers in this manner we keep
training the network with multiple
inputs until it is able to predict with
a high accuracy and you can see here we
have a different a quick quickly
switches from cursive a to maybe more
elongated a similarly our network is
trained with the images for B and C too
so let's take a look at this uh here's a
straightforward data set let's build a
neural network to predict the outputs
given the inputs and so we have an input
zero we expect an output of zero we have
an input of one we expect six 2 equal 12
three should come out as 18 and four is
24 and we're just doing multiples of six
if you take the time to look at it so in
our example we have our input and goes
into our neural network so this box
represents our neural network one of the
cool things about neural networks is are
always this little black box that you
kind of train to do what you want and
you really don't have to know exactly
what the weights are although there are
some very high-end setups to start
looking at those weights and how they
work and what they do and then you get
your output which is going to be in this
case our input's going to be X and our
output's going to be Y and W is the
weight so we have value times the weight
so if we're doing in this case just a
single neuron going through we have x *
W the network starts training Itself by
choosing a random value for w we're
going to guess that W equal 3 just roll
the dice randomly generate the number
three for w and then we put W equals 3
in here we have our input zero our
output zero W = 3al 0 so we have no
error on the first line that actually
comes out correct and then we have uh
one times uh we put the one in we're
looking for a six but we get a three
instead and we put the two in we're
looking for a 12 we get a six in set so
you can see here our predicted output
doesn't match the output we're looking
for and then um we take this we have our
W equal 3 and we come up with the second
model where the W equals 6 now we're
going to look at how we figure out W
equals 6 in just a minute that is part
of the math behind this but you can see
here when we put in W equal 6 and we
build the wal 6 chart we end up with 0 6
12 18 24 which is the output we're
looking for and in that manner we end up
with the correct answer but we'll go
ahead and put in a third model where W
equals 9 so at this point this is one
way of doing this is just to guess what
w equals and you can see with W equals 9
we get the incorrect answers we get 9 18
27 36 we as humans can know just by
taking a look at the data that our
weight should be six but how does the
machine come to this conclusion how do
we program the computer to learn instead
of waiting for us to tell it it has the
right answer what the correct answer is
and you can imagine this is a very
simple problem if we're doing guessing
wal 3 we guess wal 6 we guess wal 9 and
we look at our results and we go oh it's
got to be W equals 6 that's the best
result but as humans we want to take
that element out and have the computer
do that for us so with that we're going
to have a loss function the loss
function is a measure of error which
defines the Precision lost to comparing
the predicted output to the actual
output and it's simply loss equals
actual output minus predicted output and
then we Square the whole thing so let's
apply the loss function to the input
value two loss for our actual output
predicted output squared and our loss
function for the input of two we end up
with an actual output of 12 and you can
see here with W = 3 12 - 6^ 2 = 36 so we
end up with a loss of 36 w = 6 12 12 *
122 = 12 - 122 = 0 or 12 - 182 = 36 and
so you can see we have a huge loss on W
= 3 and W = 9 we now plot a graph for
the weight versus loss and it always
helps to have a nice visual of what's
going on here so this graphical method
of finding the minimal of a function is
called gradient descent and this is the
logic behind this you can see as we come
in here and we go ahead and graph the
loss we have 36 for three and 36 for9 we
happen to guess six which was uh the
correct answer right in the middle and
you can see right here forms a nice
little Parabola and you can see a nice
Mark right in the middle and as a human
being we can look at that we go ah the
answer is six a random point on this
curve is chosen and the slope at this
point is calculated so now we're getting
away from the human aspect of just
looking at it and seeing what the answer
is and we look at what's going on with
the math and so if we have a positive
slope it indicates an increase in the
weight and a negative slope indicates a
decrease in weight this time the slope
is negative hence another random Point
towards its left is chosen and you can
see here we're actually kind of just
playing a little high low game going
back and forth with the gradient descent
we continue checking slopes at various
points in this manner so we have our
input actual output W3 W6 W9 we found
our positive slope increases an increase
in weight a negative slope indicates a
decrease in weight a zero slope
indicates the appropriate weight so our
aim is to reach a point where the slope
is zero and when we talk about neural
networks you're usually processing a
massive amount of information and data
so you're not going to have all your
data nice and neat where it's just a
multiple of six it's going to be messy
and so we're going to keep approaching
that number but you'll never get
everything to fit at zero you're going
to get stuff all over the place and so
you're really looking for the minimum
value you're not looking for an absolute
zero because you're not going to get it
and we're talking about gradient descent
that's what we're talking about on there
is finding the bottom of that curb even
if it doesn't go all the way to zero so
how do we apply that to our neural
network well we use back Prof
propagation back propagation is a
process of updating weights of the
notwork in order to reduce the error in
prediction and so the magnitude of loss
of any point on our graph combined with
the slope is fed back to the network and
you can see here here's our simple model
with just one node of x * W the input
comes in we have our x x w the output
and then we're going to propagate that
loss going the other way a random point
on the graph gives a loss value of 36
with a positive slope and we continue
checking slopes at various points in
this manner so a random point on the
graph gives a loss value of 36 with a
positive slope 36 is quite a large
number this means our current weight
needs to change by a large number a
positive slope indicates that the change
of the weight must be positive similarly
another random point on the graph gives
a loss value of 10 with a negative slope
10 is a small number hence the weight
requires to be tuned quite less a
negative slope indicates that the weight
needs to be reduced rather than
increased after multiple iterations of
back propagation our weights are
assigned the appropriate value you can
see here we have our our input we just
looked at x * 6 in our output and
eventually we get it that the weight is
six for the single node problem that
we're working on right now at this point
our network is trained and can be used
to make predictions let's now get back
to our first example and see where the
back propagation and gradient descent
fall into place and you can see here
we're not looking at a single node
anymore now we have 28x 28 Grid or
784 inputs coming into the first level
which has 784 nodes depending on how you
build your neural network the next layer
might also have 784 nodes or it might
continually smallen depending on what
you need and what's needed for that to
work so as mentioned earlier our
predicted output is compared against the
actual output and you can see our error
over here actual minus prediction and
then we go ahead and compute our loss so
the loss of a is 7^ s = 049 loss of B is
uh. 5^ squ or 0.25 and so on uh so now
we have our first iteration on there so
weights throughout the network are
adjusted in order to reduce the loss in
prediction and of course we do that by
doing a second iteration coming through
with our different losses on there and
then weights throughout the network are
just in order to reduce the loss and
prediction again underneath the second
and we do a third iteration and we just
keep doing these iterations going back
until we get the right value now you got
to remember that when we're doing a
reverse propagation we're not looking at
just one letter A we're looking at
hundreds of letter A's and usually we
propagate that loss going backwards we
only take a small piece of it so our
adjustments are very small because one
of them is not correct we don't want to
create a bias so we talk about back
propagation we're talking about going
through over and over and over this data
until we get minimal loss for our letter
A so let's focus on the minimal loss for
our variable a and you can see here we
look at that we end up uh we'll assume
for below to be our graph for the loss
of prediction with the variable a as
compared to the waist continuing it from
the second layer and we have our loss of
a for 49 for 16 for 004 and you can see
it makes this nice curve where we can
guess where the bottom of this curve is
and I like it on this graph that they
show that the curve doesn't rest yeah on
the x- axis it doesn't rest at where y
equals zero because you usually don't
get that you don't get a perfect fit on
anything or very rarely do you ever get
a perfect fit and so the random points
chosen on the graph is now back
propagated through the network in order
to adjust the weights so we're able to
go back through the network and readjust
those weights until we find that minimal
value the network is run once again with
the new weights this process is repeated
multiple times till provides accurate
predictions the weights are further
justifi adjusted to identify B and C to
uh and this is interesting because you
actually do them at the same time uh so
as the error goes back you kind of find
the overall error for all the inputs
coming in and then that's what gets
propagated going back or the overall
loss kind of have to step away from that
word error because it's not just about
the error it's about the loss the way
are further adjusted to identify B and C
too and so a lot of times you actually
do them all at the same time but um
you'll adjust those weights a b and c as
I was just saying thus through gradient
descent and back propagation our network
is completely trained and we've taught
it to identify a b and c coming forward
one of the interesting things about
neural networks is the training process
takes a lot longer than the predicting
process so you can plan one of these
training neural networks doing the back
propag ation to uh significantly longer
because you're going over thousands of
data points and then when you actually
run it forward it's very quick uh which
makes these things very useful and just
really part of today's world in
Computing today we're going to be
covering the convolutional neural
network tutorial do you know how deep
learning recognizes the objects in an
image and really this particular neural
network is how image recognition works
it's very Central one of the biggest
building blocks for image recognition it
does it using convolution neural network
and we over here we have the basic
picture of a uh hummingbird pixels of an
image fed as input you have your input
layer coming in so it takes that graphic
and puts it into the input layer you
have all your hidden layers and then you
have your output layer and your output
layer one of those is going to light up
and say oh it's a bird we're going to go
into depth we're going to actually go
back and forth on this a number of times
today so if you're not catching all the
image um don't worry we're going to get
into the details so we have our input
layer excepts the pixels of the image as
input in the form of arrays and you can
see up here where they've actually um
labeled each block of the bird in
different arrays so we'll dive into deep
as to how that looks like and how those
matrixes are set up your hidden layer
carry out feature extraction by
performing certain calculations and
manipulation so this is the part that
kind of reorganizes that picture
multiple ways until we get some data
that's easy to read for the neural
network this layer uses a matrix filter
and performs convolution operations to
detect patterns in the image and if you
remember that convolution means to coil
or to twist so we're going to twist the
data around and alter it and use that
operation to detect a new pattern there
are multiple hidden layers like
convolution layer real U is how that is
pronounced and that's the rectified
linear unit that has to do with the
activation function that's used pooling
layer also uses multiple filters to
detect edges corners eyes feathers beak
Etc Etc and just like the term says
pulling is pulling information together
and we'll look into that a lot closer
here so if you're if it's a little
confusing now we'll dig in deep and try
to get you uh squared away with that and
then finally there is a fully connected
layer that identifies the object in the
image so we have these different layers
coming through in the hidden layers and
they come into the final area and that's
where we have say one node or one neural
network entity that lights up that says
it's a bird what's in it for you we're
going to cover an introduction to the
CNN what is convolution neural network
how CNN recognizes images we're going to
dig deeper into that and really look at
the individual layers in the
convolutional neural network and finally
we do a use case implementation using
the CNN we'll begin our introduction to
the CNN by introducing the pioneer of
convolutional neural network Yan leun he
was the director of Facebook AI research
group built the first convolutional
neural network called lenette in
1988 so these have been around for a
while and have had a chance to mature
over the years it was used for character
recognition tasks like reading zip code
digits imagine processing mail and
automating that process CNN is a feed
forward neural network that is generally
used to analyze visual images by
producing data with a grid-like topology
a CNN is also known as a convet and very
key to this is we are looking at images
that was what this was designed for and
you'll see the different layers as we
dig in Mir or some of the other some of
them are actually now used since we're
using uh tensorflow and carass in our
code later on you'll see that some of
those layers appear in a lot of your
other neural network Frameworks uh but
in this case this is very Central to
processing images and doing so in a
variety that captures multiple images
and really drills down into their
different features in this example here
you see flowers are two varieties Orchid
and a rose I think the Orchid is much
more dainty and beautiful and the rose
smells quite beautiful I have a couple
rose bushes in my yard yard uh they go
into the input layer that data is then
sent to all the different nodes in the
next layer one of the Hidden layers
based on its different weights and it's
setup it then comes out and gives those
a new value those values then are
multiplied by their weights and go to
the next hidden layer and so on and then
you have the output layer and one of
those notes comes out and says it's an
orchid and the other one comes out and
says it's a rose depending on how was
well it was trained what separates the
CNN or the convolutional neural network
from other neural networks is a
convolutional operation forms the basis
of any convolutional neural network in a
CNN every image is represented in the
form of arrays of pixel values so here
we have a real image of the digit 8 uh
that then gets put onto its pixel values
representing the form of an array in
this case you have a two-dimensional
array and then you can see in the final
in form we transform the digit 8 into
its representational form of pixels of
zeros and on where the ones represent in
this case the black part of the eight
and the zeros represent the white
background to understand the convolution
neural network or how that convolutional
operation Works we're going to take a
side step and look at Matrix in this
case we're going to simplify it we're
going to take two matrices A and B of
one dimension now kind of separate this
from your thinking as we learn that you
want to focus just on the Matrix aspect
of this and then we'll bring that back
together and see what that looks like
when we put the pieces for the
convolutional operation here we've set
up two Rays we have uh in this case
there a single Dimension Matrix and we
have a = 5
37597 and we have b = 1 2 3 so in the
convolution as it comes in there it's
going to look at these two and we're
going to start by doing multiplying them
a * B and so we multiply the arrays
element wise and we get
566 where five is the 5 * 1 6 is 3 * 2
and then the other 6 is 2 * 3 and since
the two arrays aren't the same size
they're not the same setup we're going
to just truncate the first one and we're
going to look at the second array
multiplied just by the first three
elements of the first array now that's
going to be a little confusing remember
a computer gets to repeat these
processes hundreds of time so we're not
going to just forget those other numbers
later on we'll see we'll bring those
back in and then we have the sum of the
product in this case five + 6 + 6 = 17
so in our a * B our very first digit in
that Matrix of a * B is 17 and if you
remember I said we're not going to
forget the other digits so we now have
325 we move one set over and we take 325
and we multiply that times B and you'll
see that 3 * 1 is 3 2 * 2 is 4 and so on
and so on WE sum it up so now we have
the second digit of our a * B product in
The Matrix and we continue on with that
same thing so on and so on so then we
would go from uh 375 to 759 to 597 this
short Matrix that that we have for a
we've now covered all the different
entities in a that match three different
levels of B now in a little bit we're
going to cover where we use this math at
this multiplying of matrixes and how
that works uh but it's important to
understand that we're going through the
Matrix and multiplying the different
parts to it to match the smaller Matrix
with the larger Matrix I know a lot of
people get lost at is you know what's
going on here with these matrixes uh oh
scary math not really that scary when
you break it down we're looking at a
section of a and we're comparing it to B
so when you break that down your mind
like that you realize okay so I'm I'm
just taking these two matrixes and
comparing them and I'm bringing the
value down into one Matrix a * B we're
deucing that information in a way that
will help the computer see different
aspects let's go ahead and flip over
again back to our images here we are
back to our images talking about going
to the most basic two-dimensional image
you can get to consider are the
following two images the image for the
symbol backs slash when you press the
backslash the above image is processed
and you can see there for the image for
the forward slash is the opposite so we
click the forward slash button that
flips uh very basic we have four pixels
going in can't get any more basic than
that here we have a little bit more
complicated picture we take a real image
of a smiley face um then we represent
that in the form of black and white
pixels so if this was an image in the
computer it's black and white and like
we said saw before we convert this into
the zeros and on so where the other one
would have just been a matrix of just
four dots now we have a significantly
larger image coming in so don't worry
we're going to bring this all together
here in just a little bit layers in
convolutional neural network when we're
looking at this we have our convolution
layer and that really is the central
aspect of processing images and the
convolutional neural network that's why
we have it and then that's going to be
feeding in and you have your Rel U layer
which is you know as we talked about the
rectified linear unit we'll talk about
that a little bit later the reu is an
how it Act is how that layer is
activated is the math behind it what
makes the neurons fire you'll see that
in a lot of other neural networks when
you're using it just by itself is for
processing smaller amounts of data where
you use the atom activation feature for
large data coming in now because we're
processing small amounts of data in each
image the reu layer works great you have
your pooling layer that's where you're
pulling the data together pooling is a
neural network term it's very commonly
used I like to use a term reduce so if
you're coming from the map and reduce
side you'll see that we're mapping all
this data through all these networks and
then we're going to reduce it we're
going to pull it together and then
finally we have the fully connected
layer that's where our output's going to
come out so we have started to look at
matrixes we've started to look at the
convolutional layer and where it fits in
and everything we've taken a look at
images so we're going to focus more on
the convolution layer since this is a
convolutional neural network a
convolution layer has a number of
filters and perform convolution
operation every image is considered as a
matrix of pixel values consider the
following 5x5 image whose pixel values
are only zero and one now obviously when
we're dealing with color there's all
kinds of things that come in on color
processing but we want to keep it simple
and just keep it black and white and so
we have our image pixels uh so we're
sliding the filter Matrix over the image
and Computing the dot product to detect
the patterns and right here you're going
to ask where does this filter come from
this is a bit confusing because the
filter is going to be derived uh later
on we build the filters when we program
or train our model so you don't need to
worry what the filter actually is what
you do need to understand how a
convolution layer works is what is the
filter doing filter and you'll have many
filters you don't have just one filter
you'll have lots of filters that are
going to look for different aspects and
so the filter might be looking for just
edges it might be looking for different
parts we'll cover that a little bit more
detail in a minute right now we're just
focusing on how the filter works as a
matrix remember earlier we talked about
multiplying matrixes together and here
we have our two-dimensional Matrix and
you can see we take the filter and we
multiply it in the upper left image and
you can see right here 1 Time 1 1 * 0 1
* 1 we multiply those all together then
sum them and we end up with a convolved
feature of four we going to take that
and sliding the filter Matrix over the
image and Computing the dot product to
detect patterns so we're just going to
slide this over we're going to predict
the first one and slide it over one
notch predict the second one and so on
and so on all the way through until we
have a new Matrix and this Matrix which
is the same size as the filter has
reduced the image and whatever filter
whatever that's filtering out is going
to be looking at just those features
reduced down to a smaller uh Matrix so
once the feature maps are EXT extracted
the next step is to move them to the reu
layer so the realu layer The Next Step
first is going to perform an element
wise operation so each of those Maps
coming in if there's negative pixels so
it sets all the negative pixels to zero
um and you can see this nice graph where
it just zeros out the negatives and then
you have a value that goes from zero up
to whatever value is um coming out of
the Matrix this introduces nonlinearity
to the network uh so up until now we
have a we say linearity we're talking
about the fact that the feature has a
value so it's a linear feature this
feature um came up and has let's say the
feature is the edge of the beak you know
it's like or the backs slash that we saw
um you'll look at that and say okay this
feature has a value from -10 to 10 in
this case um if it was one and say yeah
this might be a beak it might not might
be an edge right there a minus five
means no we're not even going to look at
it to zero and so we end up with an
output and the output takes all these
feature all these filtered features
remember we're not just running one
filter on this we're running a number of
filters on this image and so we end up
with an rectified feature map that is
looking at just the features coming
through and how they weigh in from our
filters so here we have an input of a
looks like a twocan
bird very exotic looking real image is
scanned in multiple convolution and the
reu layers for locating features and you
can see up here it's turned it into a
black and white white image and in this
case we're looking in the upper right
hand corner for a feature and that box
scans over a lot of times it doesn't
scan one pixel at a time a lot of times
it will Skip by two or three or four
pixels uh to speed up the process that's
one of the ways you can compensate if
you don't have enough resources on your
computation for large images and it's
not just one filter slowly goes across
the image uh you have multiple filters
have been programmed in there so you're
looking at a lot of different filters
going over the different aspects of the
image and just sliding across there and
forming a new Matrix one more aspect to
note about the reu layer is we're not
just having one reu coming in uh so not
only do we have multiple features going
through but we're generating multiple
reu layers for locating the features
that's very important to note you know
so we have a quite a bundle we have
multiple filters multiple railu uh which
brings us to the next step forward
propagation now we're going to look at
the pooling layer the rectified feature
map now goes through a pooling layer
pooling is a down sampling operation
that reduces the dimensionality of the
feature map that's all we're trying to
do we're trying to take a huge amount of
information and reduce it down to a
single answer this is a specific kind of
bird this is an iris this is a rose so
you have a rectified feature map and you
see here we have a rectified feature map
coming in um we set the max pooling with
a 2X two filters and a stride of Two And
if you remember correctly I talked about
not going one pixel at a time uh well
that's where the stride comes in we end
up with a 2X two pulled feature map but
instead of moving one over each time and
looking at every possible combination we
skip a we skip a few there we go by two
we skip every other pixel and we just do
every other one um and this reduces our
rectified feature map which as you can
see over here 16x 16 to a 4x4 so we're
continually trying to filter and reduce
our data so that we can get to something
we can manage and over here you see that
we have the Max uh 3 4 1 and two and in
the max pooling we're looking for the
max value a little bit different than
what we were looking at before so coming
from the rectified feature we're now
finding the max value and then we're
pulling those features together so
instead of think of this as image of the
map think of this as how valuable is a
feature in that area how much of a
feature value do we have and we just
want to find the best or the maximum
feature for that area they might have
that one piece of the filter of the beak
said oh I see a one in this beak in this
image and then it skips over and says I
see a three in this image and says oh
this one is rated as a four we don't
want to sum it together cuz then you
know you might have like five ones and
I'll say ah five but you might have uh
four zeros and 11 10 and that 10 says
well this is definitely a beak where the
ones will say probably not a beak a
little strange analogy since we're
looking at a bird but you can see how
that pulled feature map comes down and
we're just looking for the max value in
each one of those Matrix
pooling layer uses different filters to
identify different parts of the image
like edges corners body feathers eyes
beak Etc um I know I focus mainly on the
beak but obviously uh each feature could
be each a different part of the bird
coming in so let's take a look at what
that looks like structure of a
convolution neural network so far this
is where we're at right now we have our
input image coming in and then we use
our filters and there's multiple filters
on there that are being developed to
kind of twist and change that data and
so we multiply the matrixes we take that
little filter maybe it's a 2 by two we
multiply it by each piece of the image
and if we step two then it's every other
piece of the image that generates
multiple convolution layers so we have a
number of convolution layers we have um
set up in there just looking at that
data we then take those convolution
layers we run them through the reu setup
and then once we've done through the reu
setup and we have multiple reu going on
multiple layers that are Ru then we're
going to take those multiple layers and
we're going to be pooling them so now we
have the pooling layers or multiple
poolings going on up until this point
we're dealing with u sometimes it's
multiple Dimensions you can have three
dimensions some strange data setups that
aren't doing images but looking at other
things they can have four five six seven
dimensions uh so right now we're looking
at 2D image Dimensions coming in into
the pooling layer so the next step is we
want to reduce those Dimensions or
flatten them so flattening flattening is
a process of converting all of the re
resultant two-dimensional arrays from
pulled feature map into a single long
continuous linear Vector so over here
you see where we have a pulled feature
map maybe that's the Birdwing and it has
values 6847 and we want to just flatten
this out and turn it into 6847 or a
single linear vector and we find out
that not only do we do each of the
pulled feature Maps we do all of them
into one long linear Vector so now we've
gone through our convolutional neural
network part and we have the input layer
into the next setup all we've done is
taken all those different pooling layers
and we flattened them out and combined
them into a single linear Vector going
in so after we've done the flattening we
have H just a quick recap because we've
covered so much so it's important to go
back and take a look at each of the
steps we've gone through the structure
of the network so far is we have our
convolution where we twist it and we
filter it and multiply the matrixes we
end up with our convolutional layer
which uses the reu to figure out the
values going out out into the pooling
and you have numerous convolution layers
that then create numerous pooling layers
pulling that data together which is the
max value which one we want to send
forward we want to send the best value
and then we're going to take all of that
from each of the pooling layers and
we're going to flatten it and we're
going to combine them into a single
input going into the final layer once
you get to that step you might be
looking at that going boy that looks
like the normal input to most neural
network and you're correct it is so once
we have the flattened Matrix from the
pooling layer that becomes our input so
the pooling layer is fed as an input to
the fully connected layer to classify
the image and so you can see as our
flatten Matrix comes in in this case we
have the pixels from the flatten Matrix
fed as an input back to our twocan or
whatever that kind of bird that is um I
need one of these to identify what kind
of bird that is it comes into our Ford
propagation Network um and that will
then have the different weights coming
down across and then finally it selects
that that's a bird and that it's not a
dog or a cat in this case even though
it's not labeled the final layer there
in red is our output layer our final
output layer that says bird cat or dog
so quick recap of everything we've
covered so far we have our input image
which is twisted and multiply the
filters are multiplied times the uh
matri the two matrixes multiplied all
the filters to create our convolution
layer our convolution layers there's
multiple layers in there because it's
all building multiple layers off the
different filters then goes through the
reu as say activation and that creates
our pooling and so once we get into the
pooling layer we then and the pooling
look for who's the best what's the max
value coming in from our convolution and
then we take that layer and we flatten
it and then it goes into a fully
connected layer our fully connected
neural network and then to the output
and here we can see the entire process
how the CNN recognizes a bird this is
kind of nice cuz it's showing the little
pixels and where they're going you can
see the filter is generating this convol
olution Network and that filter shows up
in the bottom part of the convolution
network and then based on that it uses
the relo for the pooling the pulling
then find out which one's the best and
so on all the way to the fully connected
layer at the end or the classification
in the output layer so that'd be a
classification neural network at the end
so we covered a lot of theory up till
now and you can imagine each one of
these steps has to be broken down in
code so putting that together can be a
little complicated not that each step of
the process is over really complicated
but because we have so many steps uh we
have 1 2 3 four five different steps
going on here with substeps in there
we're going to break that down and walk
through that in code so in our use case
implementation using the CNN we'll be
using the CFR 10 data set from Canadian
Institute for advanced research for
classifying images across 10 categories
Unfortunately they don't let me know
whether it's going to be a two can or
some other kind of bird but we do get to
find out whether it can categorize
between a ship a frog deer bird airplane
automobile cat dog horse truck so that's
a lot of fun and if you're looking
anything in the news at all of our
automated cars and everything else you
can see where this kind of processing is
so important in today's world and very
Cutting Edge as far as what's coming out
in the commercial deployment I mean this
is really cool stuff we're starting to
see this just about everywhere in
Industry uh so great time to be playing
with this and figuring it all out let's
go ah head and dive into the code and
see what that looks like when we're
actually writing our script before we go
on let's do uh one more quick look at
what we have here let's just take a look
at data batch one keys and remember in
Jupiter notebook I can get by with not
doing the print statement if I put a
variable down there it'll just display
the variable and you can see under data
batch one for the keys since this is a
dictionary we have the batch one label
data and file names uh so you can
actually see how it's broken up in our
data set so for the next step or step
four as we're calling it uh we want to
display the image using Matt plot
Library there's many ways to display the
images you could even uh well there's
other ways to drill into it but map plot
library is really good for this and
we'll also look at our first reshape uh
setup or shaping the data so you can
have a little glimpse into what that
means uh so we're going to start by
importing our map plot and of course
since I am doing jupyter notebook I need
to do the map plot inline command so it
shows up on my page so so here we go
we're going to import matplot library.
pyplot is PLT and if you remember
matplot Library the PIP plot is like a
canvas that we paint stuff onto and
there's my percentage sign map plot
library in line so it's going to show up
in my notebook and then of course we're
going to import numpy as NP for our
numbers python array setup and let's go
ahead and set u x equals to data batch
one so this will pull in all the data
going into the x value and then because
this is just a long stream of binary
data uh we need to go a little bit of
reshaping so in here we have to go ahead
and reshape the data we have 10,000
images okay that looks correct and this
is kind of an interesting thing it took
me a little bit to I had to go research
this myself to figure out what's going
on with this data and what it is is it's
a 32x 32 picture and let me do this let
me go ahead and do a drawing pad on here
uh so we have 32 bits by 32 bits and
it's in color so there's three bits of
color now I don't know why the data is
particularly like this it had probably
has to do with how they originally
encoded it but most pictures put the
three afterward so what we're doing here
is we're going to take uh the shape
we're going to take the data which is
just a long stream of information and
we're going to break it up into 10,000
pieces and those 10,000 pieces then are
broken into three pieces each and those
three pieces then are 32x 32 you could
look at this like an oldfashioned
projector where they have the red screen
or the red projector the blue projector
and the green projector and they add
them all together and each one of those
is a 32x 32 bit so that's probably how
this was originally formatted with in
that kind of Ideal things have changed
so we're going to transpose it and we're
going to take the three which was here
and we're going to put it at the end so
the first part is reshaping the data
from a single line of bit data or
whatever format it is into 10,000x 3x
32x 32 two and then we're going to
transpose the color factor to the last
place so it's the image then the 32 by
32 in the middle that's this part right
here and then finally we're going to
take this uh which is three bits of data
and put it at the end so it's more like
we do we process images now and then as
type this is really important that we're
going to use an integer 8 you can come
in here and you'll see a lot of these
they'll try to do this with a float or
float 65 four what you got to remember
though is a float uses a lot of memory
so once you switch this into uh
something that's not integer 8 which is
goes up to 128 you are just going to the
the amount of ram let me just put that
in here is going to go way up the amount
of ram that it loads uh so you want to
go ahead and use this you can try the
other ones and see what happens if you
have a lot of RAM on your computer but
for this exercise this will work just
fine and let's go ahead and take that
and run this so now our X variable is
all loaded and it has all the images in
it from the batch one data batch one and
just to show we are talking about with
the as type on there if we go ahead and
take x0 and just look for its max value
let me go ahead and run that uh you'll
see it doesn't oops I said 128 it's 255
uh you'll see it doesn't go over 255
because it's an basically an asky
character is what we're keeping that
down to we're keeping those values down
so they're only 255 0 to 255 versus
versus a float value which would bring
this up um exponentially in size and
since we're using the map plot Library
we can do um oops that's not what I
wanted since we're using the map plot
Library we can take our canvas and just
do a PLT do I IM for image show and
let's just take a look at what x0 looks
like and it comes in I'm not sure what
that is but you can see it's a very low
grade image uh broken down to the
minimal pixels on there and if we did
the same thing oh let's do uh let's see
what one looks like hopefully it's a
little easier to see run on there not
enter let's hit the run on that uh and
we can see this is probably a semi
that's a good guess on there and I can
just go back up here instead of typing
the same line in over and over and we'll
look at three uh that looks like a dump
truck unloading uh and so on you can do
any of the 10,000 images we can just
jump to 55 uh looks like some kind of
animal looking at us there probably a
dog and just for fun let's do just one
more uh uh run on there and we we can
see a nice car for our image number four
uh so you can see we past through all
the different images and it's very easy
to look at them and they've been
reshaped to fit our view and what the uh
map plot Library uses for its format so
the next step is we're going to start
creating some helper functions we'll
start by a one hot encoder to help us
we're processing the data remember that
your labels they can't just be words
they have to switch it and we use the
one hot encoder to do that and then
we'll also create a a class uh CFR
helper so it's going to have a knit and
a setup for the images and then finally
we'll go ahead and run that code so you
can see what that looks like and then we
get into the fun part where we're
actually going to start creating our
model our actual neural network model so
let's start by creating our one hot
encoder we're going to create our own
here uh and it's going to return an out
we'll have our Vector coming in and our
values equal 10 what this means is that
we have the 10 values the 10 possible
labels and remember we don't look at the
labels as a number because a car isn't
one more than a horse and that'd be just
kind of bizarre to have horse equals 0
car equal 1 plane equal 2 cat equal 3 so
a cat plus a car equals what uh so
instead we create a numpy array of zeros
and there's going to be 10 values so we
have 10 different values in there so you
have uh zero or one one means it's a cat
zero means it's not a cat um in the next
line it might be that uh one means it's
a car zero means it's not a car so
instead of having one output with a
value of 0o to 10 you have 10 outputs
with the values of 0 to one that's what
the one hot encoder is doing here and
we're going to utilize this in code in
just a minute so let's go ahead and take
a look at the next helpers we have a few
of these helper functions we're going to
build and when you're working with a
very complicated python project dividing
it up into separate definitions and
classes is very important otherwise it
just becomes really un gainly to work
with so let's go ahead and put in our
next helper uh which is a class and this
is a lot in this class so we we'll break
it down here let's just start uh oops we
put a space right in there there we go
now this a little bit more readable add
a second space so we're going to create
our class the cipher Helper and we'll
start by initializing it now there's a
lot going on in here so let's start with
the uh nit part uh self. I equals z
that'll come in in a little bit we'll
come back to that in the lower part we
want to initialize ize our training
batches so when we went through this
there was like a meta batch we don't
need the meta batch but we do need the
data batch one 2 three four five and we
do not want the testing batch in here
this is just the self all train batches
so we're going to come make an array of
of all those different images and then
of course we left the test batch out so
we have our self. test batch uh we're
going to initialize the training images
and the training labels and also the
test images and the test labels so these
are just this is just to initialize
these variables in here then we create
another definition down here and this is
going to set up the images let's just
take a look and see what's going on in
there now we could have all just put
this as part of the uh innit part uh
since this is all just helper stuff but
breaking it up again makes it easier to
read it also makes it easier when we
start executing the different pieces to
see what's going on so that way we have
a nice print statement to say hey we're
now running this and this is what's
going on in here we're going to set up
these self trining images at this point
and that's going to go to a numpy array
vstack and in there we're going to load
up uh in this case the data for D and S
all train batches again that points
right up to here so we're going to go
through each one of these uh files or
each one of these data sets because
they're not a file anymore we've brought
them in data batch one points to the
actual data and so our self-training
images is going to stack them all into
our into a numpy array and then it's
always nice to uh get the training
length and that's just a total number of
uh self-training images in there and
then we're going to take the selft
trining images and let me switch marker
colors because I am getting a little too
much on the markers up here oops there
we go bring down our marker change so we
can see it a little better and at this
point this should look familiar where
did we see this well when we wanted to
uh uh look at this above and we want to
look at the images in the matap plot
Library we had to reshape it so we're
doing this same thing here we're taking
our self-training images and uh based on
the training length total number of
images because we stacked them all
together so now it's just one large file
of images we're going to take and look
at it as our our three video cameras
that are each displaying uh 32x 32 we're
going to switch that around so that now
we have um each of our images that stays
the same place and then we have our 32
by 32 and then by our three our last our
three different different values for the
color and of course we want to go ahead
and uh they run this where we say divide
by 255 that was from earlier it just
brings all the data into 0 to one that's
what this is doing so we're turning this
into a 0: one array which is uh all the
pictures 32x 32 by 3 and then we're
going to take the self-training labels
and we're going to pump those through
our one hot encoder we just made and
we're going to stack them together and
uh again we're converting this into an
array that goes from uh instead of
having horse equals 1 dog equals 2 and
then horse plus dog would equal three
which would be cat no it's going to be
uh you know an array of 10 where each
one is zero to one then we want to go
ahead and set up our test images and
labels and uh when we're doing this
you're going to see it's the same thing
we just did with the rest of them let me
just change colors right here this is no
different than what we were doing up
here with our training Set uh we're
going to stack the different uh images
uh we're going to get the length of them
so we know how many images are in there
uh you certainly could add them by hand
but it's nice to let the computer do it
especially if it ever changes on the
other end and you're using other data
and again we reshape them and transpose
them and we also do the one hot encoder
same thing we just did on our training
images so now our test images are in the
same format so now we have a definition
which sets up all our images in there
and then the next step is to go ahead
and batch them or next batch and let's
do another breakout here for batches cuz
this is really important to understand
tends to throw me for a little Loop when
I'm working with tensor flow or carass
or a lot of these we have our data
coming in if you remember we had like
10,000 photos let me just put 10,000
down here we don't want to run all
10,000 at once so we want to break this
up into batch sizes and you also
remember that we had the number of
photos in this case uh length of test or
whatever number is in there uh we also
have 32 by 32 by 3 so when we're looking
at the batch size we want to change this
from 10,000 to um a batch of in this
case I think we're going to do batches
of a 100 so we want to look at just 100
the first 100 of the photos and if you
remember we set selfi equal to zero uh
so what we're looking at here is we're
going to create X we're going to get the
next batch from the very initialized
we've already initialized it for zero so
we're going to look at X from zero to
batch size which we set to 100 so just
the first 100 images and then we're
going to reshape that into uh and this
is important to let the data know that
we're looking at 100x 32x 32x 3 now
we've already formatted it to the 32 by
32 by3 this just sets everything up
correctly so that X has the data in
there in the correct order and the
correct shape and then the Y just like
the X uh is our labels so our training
labels again they go from zero to batch
size in this case they do selfi plus
batch size because the selfi is going to
keep changing and then finally we
increment the selfi CU we have zero so
we so the next time we call it we're
going to get the next batch size and so
basically we have X and Y X being the
photograph data coming in and Y being
the label and that of course is labeled
through one hot encoder so if you
remember correctly if it was say horse
is equal to zero it would be um one for
the zero position since this is the
horse and then everything else would be
zero in here let me just put lines
through there there we go there's our
array hard to see that array so let's go
ahead and take that and uh we're going
to finish loading it since this is our
class and now we're armed with all this
um uh our setup over here let's go ahead
and load that up and so we're going to
create a variable CH with the CFR helper
in it and then we're going to do ch.
setup images uh now we could have just
put all the setup images under the init
but by breaking this this up into two
parts it makes it much more readable and
um also if you're doing other work
there's reasons to do that as far as the
setup let's go ahead and run that and
you can see where it says uh setting up
training images and labels setting up
test images and that's one of the
reasons we broke it up is so that if
you're testing this out you can actually
have print statements in there telling
you what's going on which is really nice
uh they did a good job with this setup I
like the way that it was broken up in
the back and then one quick note you
want to remember that batch to set up
the next batch as we have to run uh
batch equals CH next batch of 100 cuz
we're going to use the 100 size uh but
we'll come back to that we're going to
use that just remember that that's part
of our code we're going to be using in a
minute from the definition we just made
so now we're ready to create our model
first thing we want to do is we want to
import our tensor flow as TF I'll just
go ahead and run that so it's loaded up
and you can see we got a a warning here
uh that's because they're making some
changes it's always growing and they're
going to be depreciating one of the uh
values from float 64 to float typee or
is treated as an NP float 64 uh nothing
to really worry about this doesn't even
affect what we're working on because
we've set all of our stuff to a 255
value or 0 to one and do keep in mind
that 0 to one value that we converted to
255 is still a float value uh but it'll
easily work with either the uh numpy
float 64 or the numpy dtype float it
doesn't matter which one it goes through
so the depreciation would not affect our
code as we have it and in our tensor
flow
uh we'll go ahead let me just increase
the size in there just a moment so you
can get better view of the um what we're
typing in uh we're going to set a couple
placeholders here and so we have we're
going to set x equals TF placeholder TF
float 32 we just talked about the float
64 versus the numpy float we're actually
just going to keep this at float 32 more
than a significant number of decimals
for what we're working with and since
it's a placeholder we're going to set
the shape equal to and we've set it
equal to none cuz at this point we're
just hold holding the place on there
we'll be setting up as we run the
batches that's what the first value is
and then 32x 32x 3 that's what we
reshaped our data to fit in and then we
have our y true equals placeholder TF
float 32 and the shape equals none comma
10 10 is the 10 different labels we have
so it's an array of 10 and then let's
create one more placeholder we'll call
this a hold prob or hold probability and
we're going to use this we don't have to
have a shape or anything for this this
placeholder is for what we call Dropout
if you remember from our Theory before
we drop out so many nodes is looking at
or the different values going through
which helps decrease bias so we need to
go ahead and put a a placeholder for
that also and we'll run this so it's all
loaded up in there so we have our three
different placeholders and since we're
in tensor flow when you use carass it
does some of this automatically but
we're in tensor flow direct sits on
tensor flow we're going to go ahead and
create some more helper functions we're
going to create something to help us
initialize the weights initialize our
bias if you remember that each uh layer
has to have a bias going in we're going
to go ahead and work on our our
conversional 2D our Max pool so we have
our pooling layer our convolutional
layer and then our normal full layer so
we're going to go ahead and put those
all into definitions and let's see what
that looks like in code and you can also
grab some of these helper functions from
the MN the uh nist setup let me just put
that in there if you're under the tensor
flow so a lot of these are already in
there but we're going to go ahead and do
our own and we're going to create our uh
knit weights and one of the reasons
we're doing this is so that you can
actually start thinking about what's
going on in the back end so even though
there's ways to do this with an
automation sometimes these have to be
tweaked and you have to put in your own
setup in here uh now we're not going to
be doing that we're just going to
recreate them for our code and let's
take a look at this we have our weights
and so what comes in is going to be the
shape and what comes out is going to be
uh random numbers so we're going to go
ahead and just knit some random numbers
numbers based on the shape with a
standard deviation of 0.1 kind of a fun
way to do that and then the TF variable
uh in nit random distribution so we're
just creating a random distribution on
there that's all that is for the weights
now you might change that you might have
a a higher standard deviation in some
cases you actually load preset weights
that's pretty rare usually you're
testing that against another model or
something like that and you want to see
how those weights configure with each
other uh now remember we have our bias
so we need to go ahead and initialize
the bias with a constant in this case
we're using 0.1 a lot of times the bias
is just put in as one and then you have
your weights to add on to that uh but
we're going to set this as 0.1 uh so we
want to return a convolutional 2d in
this case a neural network this is uh
would be a layer on here what's going on
with the con 2D is we're taking our data
coming in uh we're going to filter it
strides if you remember correctly
strides came from here's our image and
then we only look at this picture here
and then maybe we have a stride of one
so we look at this picture here and we
continue to look at the different
filters going on there the other thing
this does is that we have our data
coming in as
32 by
32 by three and we want to change this
so that it's just this is three
dimensions and it's going to reformat
this as just two Dimensions so it's
going to take this number here and
combine it with the 32x 32 so this is a
very important layer here CU it's
reducing our data down using different
means and it connects down I'm just
going to jump down one here uh it goes
with the convolutional layer so you have
your your kind of your pre- formatting
and the setup and then you have your
actual convolution layer that goes
through on there and you can see here we
have a knit weights by the shape a knit
bias shape of three because we have the
three different uh here's our three
again and then we return the tfnn relu
with the convention 2D so this
convolutional uh has this feeding into
it right there it's using that as part
of it and of course the input is the XY
plus b the bias so that's quite a
mouthful but these two are the are the
keys here to creating the convolutional
layers there the convolutional 2D coming
in and then the convolutional layer
which then steps through and creates all
those filters we saw then of course we
have our pooling uh so after each time
we run it through the convectional layer
we want to pull the data uh if you
remember correctly on the on the pool
side and let me just get rid of all my
marks it's getting a little crazy there
and in fact let's go ahead and jump back
to that slide let's just take a look at
that slide over here uh so we have our
image coming in we create our
convolutional layer with all the filters
remember the filters go um you know the
filters coming in here and it looks at
these four boxes and then if it's a step
let's say step two and then goes to
these four boxes and then the next step
and so on uh so we have our
convolutional layer that we generate or
convolutional layers they use the uh reu
function um there's other functions out
there for this though the Ru is the uh
most the one that works the best at
least so far I'm sure that will change
then we have our pooling now if you
remember correctly the pooling was Max
uh so if we had the filter coming in and
they did the multiplication on there and
we have a one and maybe a two here and
another one here and a three here three
is the max and so out of all of these
you then create an array that would be
three and if the max is over here two or
whatever it is that's what goes into the
pooling of what's going on in our
pooling uh so again we're reducing that
data down we're reducing it down as
small as we can and then finally we're
going to flatten it out into a single
array and that goes into our fully
connected layer and you can see that
here in the code right here we're going
to create our normal full layer um so at
some point we're going to take from our
pooling layer this will go into some
kind of flattening process and then that
will be fed into the full the different
layers going in down here um and so we
have our inputs size you'll see our
input layer get shape which is just
going to get the shape for whatever is
coming in uh and then input size initial
weights is also based on uh the input
layer coming in and the input size down
here is based on the input layer shape
so we're just going to already use the
shape and already have our size coming
in and of course uh you have to make
sure you init the bias always put your
bias on there and we'll do that based on
the size so this will return tf. matmo
input layer w plus b this is just a
normal full layer that's what this means
right down here that's what we're going
to return so that was a lot of steps we
went through let's go ahead and run that
so those are all loaded in there and
let's go ahead and uh create the layers
let's see what that looks like now that
we've done all the heavy lifting and
everything uh we get to do all the easy
part let's go ahead and create our
layers we'll create a convolution layer
one and two two different convolutional
layers and then we'll take that and
we'll flatten that out create a a
reshape pool in in there for our reshape
and then we'll have our full uh layer at
the end so let's start by creating our
first uh convolutional layer then we
come in here and let me just run that
real quick and I want you to notice on
here the three and the 32 this is
important because coming into this
convolutional layer we have three
different channels and 32 pixels each uh
so that has to be in there the four and
four you can play with this is your
filter size so if you're remember you
have a filter and you have your image
and the filter slowly steps over and
filters out this image depending on what
your step is for this particular setup
44 is just fine that should work pretty
good for what we're doing and for the
size of the image and then of course at
the end once you have your convolutional
layer set up you also need to pull it
and you'll see that the pooling is
automatically set up so that it would
see the different shape based on what's
coming in so here we have Max two 2 by
two and we put in the convolutional one
that we just created the convolutional
layer we just created goes right back
into it and that right up here as you
can see is the X it's coming in from
here so it knows to look at the first
model and set the the data accordingly
set that up so matches and we went ahead
and ran this already I think I ran let
me go and run it again and if we're
going to do one layer let's go ahead and
do a second layer down here and it's
we'll call it convo 2 it's also a
convolutional layer on this and you'll
see that we're feing convolutional one
in the pooling so it goes from
convolutional one into convolutional one
pooling from convolutional one pooling
into convolutional two and then from
convolutional two into convolutional two
pooling and we'll go ahead and take this
and run this so these variables are all
loaded into memory and for our flatten
layer uh let's go ahead and we'll do uh
since we have 64 coming out of here and
we have a 4x4 going in let's do 8X 8X 6
4 so let's do
4,096 this is going to be the flat layer
so that's how many bits are coming
through on the flat layer and we'll
reshape this so we'll reshape our convo
2 pooling and that will feed into here
the convo 2 pooling and then we're going
to set it up as a single layer that's
4,096 in size that's what that means
there we'll go ahead and run this so
we've now created this variable the
convo 2 flat and then we have our first
full layer this is the final uh neural
netor networ where we have the flat
layer going in and we're going to again
use the uh reu for our uh setup on there
on a neural network for evaluation and
you'll notice that we're going to create
our first full layer our normal full
layer that's our definition so we
created that that's creating the normal
full layer and our input for the data
comes right here from the this goes
right into it uh the convo to flat so
this tells it how big the data is and
we're going to have it come out it's
going to have uh 1024 that's how big the
layer is is coming out we'll go ahead
and run this so now we have our full
layer one and with the full layer one we
want to also Define the full one Dropout
to go with that so our full layer one
comes in uh keep probability equals hold
probability remember we created that
earlier and the full layer one is what's
coming into it and this is going
backwards and training the data we're
not training every weight we're only
training a percentage of them each time
which helps get rid of the bias so let
me go ahead and run that and uh finally
we'll go ahead and create a y predict
which is going to equal the normal full
one Dropout and 10 because we have 10
labels in there now in this neural
network we could have added additional
layers that would be another option to
play with you can also play with instead
of 1024 you can use other numbers for
the way that sets up and what's coming
out going into the next one we're only
going to do just the one layer and the
one layer Dropout and you can see if we
did another layer it'd be really easy
just to feed in the full one Dropout
into full layer two and then then full
Layer Two Dropout would have full Layer
Two feed into it and then you'd switch
that here for the Y prediction for right
now this is great this particular data
set is tried and true and we know that
this will work on it and if we just type
in y predict and we run that uh we'll
see that this is a tensor object uh
shape question mark 10 dtype 32 uh quick
way to double check what we're working
on so now we've got all of our uh we've
done a setup all the way to the Y
predict which we just did uh we want to
go ahead and apply the loss function and
make sure that's set up in there uh
create the optimizer and then uh train
our Optimizer and create a variable to
initialize all the global TF variables
so before we dive into to the um loss
function let me point out one quick
thing or just kind of a rehap over a
couple things and that is when we're
playing with this these setups um we
pointed out up here we can change the 44
and use different numbers there they
change your outcome so depending on what
numbers you use here will have a huge
impact on how well your model fits and
that's the same here of the 1024 also
this is also another number that if you
continue to raise that number you'll get
um possibly a better fit you might over
fit and if you lower that number you'll
use less resources and generally you
want to use this in um the exponential
growth an exponential being 2 4 8 16 and
in this case the next one down would be
512 you can use any number there but
those would be the ideal numbers uh when
you look at this data so the next step
in all this is we need to also create uh
a way of tracking how good our model is
and we're going to call this a loss
function and so we're going to create a
cross entropy loss function and so
before we discuss exactly what that is
let's take a look and see what we're
feeding it uh we're going to feed it our
labels and we have our true labels and
our prediction labels uh so coming in
here as we're the two different
variables we're sending in or the two
different probability distributions is
one that we know is true and what we
think it's going to be now this function
right here when they talk about cross
entropy uh in information Theory the
cross entropy between two probability
distributions over the same underlying
set of events measures the average
number of bits needed to identify an
event drawn from the set that's a
mouthful uh really we're just looking at
the amount of error in here how many of
these are correct and how many of these
um are incorrect so how much of it
matches and we're going to look at that
we're just going to look at the average
that's what the mean the reduced to the
mean means here so we're looking at the
average error on this and so the next
step is we're going to take the error we
want to know uh our cross entropy or our
loss function how much loss we have
that's going to be part of how we train
the model so when you know what the loss
is and we're training it you feed that
back into the back propagation setup and
so we want to go ahead and optimize that
here's our Optimizer we're going to
create the optimizer using an atom
Optimizer remember there's a lot of
different ways of optimizing the data
atoms the most popular used uh so our
Optimizer is going to equal the TF train
atom Optimizer if you don't remember
what the learning rate is let me just
pop this back into here here's our
learning rate when you have your weights
you have all your weights and your
different nodes that are coming out
here's our node coming out um and it has
all its weights and then the error is
being prop sent back through in reverse
on our neural network so we take this
error and we adjust these weights based
on the different formulas in this case
the atom formula is what we're using we
don't want to just adjust them
completely we don't want to change this
weight so it exactly fits the data
coming through because if we made that
kind of adjustment it's going to be
biased to whatever the last data we sent
through is instead we're going to
multiply that by 0.001 and make a very
small shift in this weight so our Delta
W is only 0.001 of the actual Delta w of
the full change we're going to compute
from the atom and then we want to go
ahead and train it so our training or
set up a training uh uh variable or
function and this is going to equal our
Optimizer minimize cross entropy and we
make sure we go ahead and run this so
it's loaded in there and then we're
almost ready to train our model but
before we do that we need to create one
more um variable in here and we're going
to create a variable to initialize all
the global TF variables and when we look
at this um the TF global variable
initializer this is a tensor flow um
object it goes through there and it
looks at all our different setup that we
have going under our tensor flow and
then initializes those variables uh so
it's kind of like a magic W because it's
all hidden in the back end of tensorflow
all you need to know about this is that
you have to have the initialization on
there which is an operation um and you
have to run that once you have your
setup going so we'll go ahead and run
this piece of code and then we're going
to go ahead and train our data so let me
run this so it's loaded up there and so
now we're going to go ahead and run the
model by creating a graph session graph
session is a tensor flow term so you'll
see that coming up it's one of the
things that throws me because I always
think of graphic and Spark and graph as
just general graphing uh but they talk
about a graph session so we're going to
go ahead and run the model and let's go
ahead and walk through this uh what's
going on here and let's paste this data
in here and here we go so we're going to
start off with the with the TF session
as
so that's our actual TF session we've
created uh so we're right here with the
TF uh session our session we're creating
we're going to run TF Global variable
initializer so right off the bat we're
initializing our variables here uh and
then we have for I in range 500 so
what's going on here remember 500 we're
going to break the data up and we're
going to batch it in at 500 points each
we've created our session run so we're
going to do with TF session as set
session right here we've created our
variable session uh and then we're going
to run and we're going to go ahead and
initialize it so we have our TF Global
variables initializer that we created um
that initializes our our session in here
the next thing we're going to do is
we're going to go for I in range of 500
batch equals ch. next batch so if you
remember correctly this is loading up um
100 pictures at a time and uh this is
going to Loop through that 500 times so
we are literally doing uh what is that
uh 500 time 100 is uh 50,000 so that's
50,000 pictures we're going to process
right there in the first process is
we're going to do a session run we're
going to take our train we created our
train variable or Optimizer in there
we're going to feed it the dictionary uh
we had our feed dictionary that created
and we have x equals batch zero coming
in y true batch one hold the probability
0.5 and then just so that we can keep
track of what's going on we're going to
every 100 steps we're going to run a
print So currently on step format C
accuracy is um and we're going to look
at matches equals tf. equal TF argument
y prediction one tf. AR Max y true comma
one so we're going to look at this is
how many matches it has and here our ACC
uh all we're doing here is we're going
to take the matches how many matches
they have it creates it generates a
chart we're going to convert that to
float that's what the TF cast does and
then we just want to know the average we
just want to know the average of the um
accuracy and then we'll go ahead and
print that out uh print session run
accuracy feed dictionary so it takes all
this and it prints out our accuracy on
there so let's go ahead and take this
oops FP screens there let's go ahead and
take this and let's run it and this is
going to take a little bit to run uh so
let's see what happens on my old laptop
and we'll see here that we have our
current uh we're currently on Step Zero
it takes a little bit to get through the
accuracy and this this will take just a
moment to run we can see that on our
Step Zero it has an accuracy of 0.1 or
0128 um and as it's running we'll go
ahead you don't need to watch it run all
the way but uh this accuracy is going to
change a little bit up and down so we've
actually lost some accuracy during our
step
two um but we'll see how that comes out
let's come back after we run it all the
way through and see how the different
steps come out I was actually reading
that backwards uh the way this works is
the closer we get to one the more
accuracy we have uh so you can see here
we've gone from a 0.1 to a 39 um and
we'll go ahead and pause this and come
back and see what happens when we're
done with the full run all right now
that we've uh prepared the meal got it
in the oven and pulled out my finished
dish here if you've ever watched uh any
of the old cooking shows let's discuss a
little bit about this accuracy going on
here and how do you interpret that we've
done a couple things first we've defined
accuracy um the reason I got it
backwards before is you have uh loss or
accuracy and with loss you'll get a
graph that looks like this it goes oops
that's an S by the way there we go you
get a graph that curves down like this
and with accuracy you get a graph that
curves up this is how good it's doing
now in this case uh one is supposed to
be really good accuracy that mean it
gets close to one but it never crosses
one so if you have an accuracy of one
that is phenominal um in fact that's
pretty much un you know unheard of and
the same thing with loss if you have a
loss of zero that's also unheard of the
zero is actually on this this axis right
here as we go in there so how do we
interpret that because you know if I was
looking at this and I go oh 0. 51 that's
uh 51% you're doing 50/50 no this is not
percentage let me just put that in there
it is not percentage uh this is
logarithmic what that means is that 0. 2
is twice as good as 0.1 and uh when we
see 0. 4 that's twice as good as .2 real
way to convert this into a percentage
you really can't say this is is a direct
percentage conversion what you can do
though is in your head if we were to
give this a percentage uh we might look
at this as uh 50% we're just guessing
equals 0.1 and if 50% roughly equals 0.1
that's where we started up here at the
top remember at the top here here's our
0128 the accuracy of 50% then 75% is
about 0.2 and so on and so on don't
quote those numbers because that doesn't
work that way they say that if you have
95 that's pretty much saying 100% And if
you have uh anywhere between you'd have
to go look this up let me go and remove
all my drawings there uh so the magic
number is 05 we really want to be over a
0. five in this whole thing and we have
uh both 0504 remember this is accuracy
if we were looking at loss then we'd be
looking the other way but 0.0 you know
instead of how high it is we want how
low it is uh but with accuracy being
over a 0 five is pretty valid that means
this is pretty solid and if you get to a
0.95 then it's a direct correlation
that's what we're looking for here in
these numbers you can see we finished
with this model at 0 5135 so still good
um and if we look at uh when they ran
this in the other end remember there's a
lot of Randomness that goes into it when
we see the weights uh they got. 5251 so
a little better than ours but that's
fine you'll find your own uh comes up a
little bit better or worse depending on
uh just that Randomness and so we've
gone through the whole model we've
created we trained the model and we've
also gone through on every uh 100th run
to test the model to see how accurate it
is we will start with of course the
fundamentals what is a neural network
and popular neural networks it's
important to know the framework we're in
and what we're going to be looking at
specifically then we'll touch on why a
recurrent neural network net work what
is a recurrent neural network and how
does an RNN work uh one of the big
things about rnns is what they call the
vanishing and exploding gradient problem
so we'll look at that and then we're
going to be using a use case uh study
it's going to be in carass on tensor
flow carass is a python module for doing
neural networks in deep learning and uh
in there there's the what they call long
shortterm memory lstm and then we'll use
the use case to implement our LST TM on
the carass so when you see that lstm
that is basically the RNN Network and
we'll get into that the use case is
always my favorite part before we dive
into any of this we're going to take a
look at what is an RNN or an
introduction to the RNN do you know how
Google's autocomplete feature predicts
the rest of the words a user is typing I
love that autocomplete feature as I'm
typing away saves me a lot of time I can
just kind of Hit the enter key and it
autofills everything and I don't have to
typee as much well first first is a
collection of large volumes of most
frequently occurring consecutive words
uh this is fed into a recurrent neural
network analyses the data by finding the
sequence of words occurring frequently
and builds a model to predict the next
word in the sentence and then Google
what is the best food to eat in Las I'm
guessing you're going to say Las Mexico
no it's going to be Las Vegas uh so the
Google search will take a look at that
and say hey the most common auto
complete is going to be Vegas in there
and usually gives three or four
different choices so it's a very
powerful tool it saves us a lot of time
especially when we're doing a Google
search or even in Microsoft Words has a
some people get very mad at it it
autofills with the wrong stuff uh but
you know you're typing away and it helps
you autofill I have that in a lot of my
different packages is just a standard
feature that we are all used to now so
before we dive into the RNN and getting
Into the Depths let's go ahead and talk
about what is a neural network neural
networks used in deep learning consist
of different layers connected to each
other and work on the structure and
functions of a human brain you're going
to see that thread human in human brain
and human thinking throughout deep
learning the only way we can evaluate an
artificial intelligence or anything like
that is to compare it to human function
very important note on there and it
learns from a huge volumes of data and
it uses complex algorithm to train a
neural net so in here we have image
pixels of two different breeds of dog uh
one looks like a nice floppy eared lb
and one a German Shepherd you know both
wonderful breeds of animals that image
then goes into an input layer uh that
input layer might be formatted at some
point because you have to let it know
like you know different pictures are
going to be different sizes and
different color content then it'll feed
into hidden layers so each of those
pixels or each point of data goes in and
then um splits into the hidden layer
which then goes into another hidden
layer which then goes to an output layer
RNN there's some changes in there which
we're going to get into so it's not just
a straightforward propagation of data
like we've covered in many other
tutorials and finally you have an output
layer and the output layer has two
outputs it has one that lights up if
it's a German shepherd and another that
lights up as if it's a labador so
identifies a dog's breed such networks
do not require memorizing the past
output so our forward propagation is
just that it goes forward and it doesn't
have to rememorize stuff and uh you can
see there that's not actually me in the
picture uh dressed up in my
suit I haven't worn a suit in years
so as we're looking at this we're going
to change it up a little bit before we
cover that let's talk about popular
neural networks first there's the feed
forward neural network used in general
regression and classification problems
and we have the convolution neural
network used for image recognition deep
neural network used for acoustic
modeling deep belief Network used for
cancer detection and recurrent neural
network used for speech recognition now
taken a lot of these and mixed them
around a little bit so so just because
it's used for one thing doesn't mean it
can't be used for other modeling but
generally this is where the field is and
this is how those models are generally
being used right now so we talk about a
feed forward neural network in a feed
forward neural network information flows
only in the forward direction from the
input nodes through the hidden layers if
any and to the output nodes there are no
Cycles or Loops in the network and so
you can see here we have our input layer
I was talking about how it just goes
straight forward into the hidden layers
so each one of those connects and then
connects to the next hidden layer
connects to the output layer and of
course we have a nice simplified version
where it has a predicted output and they
refer to the input as x a lot of times
and the output as why decisions are
based on current input no memory about
the past no future scope why recurrent
neural network issues in feed forward
neural network so one of the biggest
issues is because it doesn't have a
scope of memory or time a feed forward
neural network doesn't know how to
handle sequential data uh it only
considers only the current input so if
you have a series of things and because
three points back affects what's
happening now and what your output
affects what's happening that's very
important so whatever I put as an output
is going to affect the next one um a
feed forward doesn't look at any of that
it just looks at this is what's coming
in and it cannot memorize previous
inputs so it doesn't have that list of
inputs coming in solution to feed
forward neural network you'll see here
where it says recurrent neural network
and we have our X on the bottom going to
H going to Y that's your feed forward uh
but right in the middle it has a value
you see so it's a whole another process
was memorizing what's going on in the
hidden layers and the hidden layers as
they produce data feed into the next one
so your hidden layer might have an
output that goes off to Y uh but that
output goes back into the next
prediction coming in what this does is
this allows it to handle sequential data
it considers the current input and also
the previously received inputs and if
we're going to look at General drawings
and um Solutions we should also look at
applications of the RNN image captioning
RNN is used to caption an image by
analyzing the activities present in it a
dog catching a ball in midair uh that's
very tough I mean you know we have a lot
of stuff that analyzes images of a dog
and the image of a ball but it's able to
add one more feature in there that's
actually catching the ball in midair
time series prediction any time series
problem like predicting the prices of
stocks in a particular month can be
solved using RNN and we'll dive into
that in our use case and actually take a
look at some stock one of the things you
should know about analyzing stock today
is that it is very difficult and if
you're analyzing the whole stock the
stock market at the New York Stock
Exchange in the US produces somewhere in
the neighborhood if you count all the
individual trades and fluctuations by
the second um it's like three terabytes
a day of data so we're only going to
look at one stock just analyzing One
stock is really tricky in here we'll
give you a little jump on that so that's
exciting but don't expect to get rich
off of it immediately another appc
application of the RNN is natural
language processing text Mining and
sentiment analysis can be carried out
using RNN for natural language
processing and you can see right here
the term natural language processing
when you stream those three words
together is very different than I if I
said processing language natural leave
so the time series is very important
when we're analyzing sentiments it can
change the whole value of a sentence
just by switching the words around or if
you're just counting the words you might
get one sentiment where if you actually
look at the order they're in you get a
completely different sentiment when it
rains look for rainbows when it's dark
look for stars both of these are
positive sentiments and they're based
upon the order of which the sentence is
going in machine translation given an
input in one language RNN can be used to
translate the input into a different
languages as output I myself very
linguistically challenged but if you
study languages and you're good with
languages you know right away that if
you're speaking English you would say
big cat and if you're speaking Spanish
she would say cat big so that
translation is really important to get
the right order to get there's all kinds
of parts of speech that are important to
know by the order of the words here this
person is speaking in English and
getting translated and you can see here
a person is speaking in English in this
little diagram I guess that's denoted by
the flags I have a flag I own it no um
but they're speaking in English and it's
getting translated into Chinese Italian
French German and Spanish languages some
of the tools coming out are just so cool
so somebody like myself who's very
linguistically challenged I can now
travel into Worlds I would never think
of because I can have something
translate my English back and forth
readily and I'm not stuck with a
communication gap so let's dive in what
is a recurrent neural network recurrent
neural network works on the principle of
saving the output of a layer and feeding
this back to the input in order to
predict the output of the layer sounds a
little confusing when we start breaking
it down it'll make more % and usually we
have a propagation forward neural
network with the input layers the hidden
layers the output layer with the
recurrent neural network we turn that on
its side so here it is and now our X
comes up from the bottom into the hidden
layers into Y and they usually draw very
simplified X to H with c as a loop a to
Y where a B and C are the perimeters a
lot of times you'll see this kind of
drawing in here digging closer and
closer into the H and how it works going
from left to right you'll see that the C
goes in and then the X goes in so the x
is going Upward Bound and C is going to
the right a is going out and C is also
going out that's where it gets a little
confusing so here we have xn uh CN and
then we have y out and C out and C is
based on HT minus one so our value is
based on the Y and the H value are
connected to each other they're not
necessarily the same value because H can
be its own thing and usually we draw
this or we represent it as a function h
of t equals a function of C where H of T
minus one that's the last H output and X
of T going in so it's the last output of
H combined with the new input of x uh
where HT is the new state FC is a
function with the parameter C that's a
common way of denoting it uh HT minus
one is the Old State coming out and then
X of T is an input Vector at time of
Step T well we need to cover types of
recurrent neural networks and so the
first one is the most common one which
is a one toone single output one: one
neural network is usually known as a
vanilla neural network used for regular
machine learning problems why because
vanilla is usually considered kind of a
just a real basic flavor but because
it's a very basic a lot of times they'll
call it the vanilla neural network uh
which is not the common term but it is
you know kind of a slang term people
will know what you're talking about
usually if you say that then we run one
to mini so you have a single input and
you might have a multiple outputs and
this this case uh image captioning as we
looked at earlier where we have not just
looking at it as a dog but a dog
catching a ball in the air and then you
have many to1 Network takes in a
sequence of inputs examples sentiment
analysis where a given sentence can be
classified as expressing positive or
negative sentiments and we looked at
that as we were discussing if it rains
look for a rainbow so positive sentiment
where rain might be a negative sentiment
if you were just adding up the words in
there and then of course and just a
quick INF for for you if you want to
upskill yourself master artificial
intelligence and machine learning skills
and land your dream job or grow in your
career then you must explore simply
learns cohort of various AI ml programs
simply learn offers various
certifications and postgraduate programs
in collaboration with some of the
world's leading universities like Bon
Purdue Caltech it kpur and many more
through our courses we will gain
knowledge and work ready expertise in
skills like generative AI prompto
engineering explainable a I machine
learning algorithms and over a dozen
others and that's not all you also get
the opportunity to work on multiple
projects and learn from industry experts
working in top tier product companies
and academicians from top universities
after completing these courses thousands
of Learners have transitioned into an AI
or ml role as a fresher or moved on to
higher paying job and profile if you're
passionate about making your career in
this field then make sure to check out
the link in the pin comment and
description box to find an AI M ml
program that fits your experience and
areas of Interest cross is a highlevel
python deep learning
API which is used for easy
implementation of neural networks it has
multiple low-level backends like tensor
flow uh thano py torch Etc which are
used for fast
computation so you can think of this as
carass being almost its own little
programming language and then it sits on
neural networks in this case uh the ones
listed where tensorflow thano and
pytorch which can all integrate with the
carass model this makes it very diverse
and also makes it very easy to use and
switch around with different things uh
cross is very uh user friendly as far as
neural network software goes as a high
level
API computational graphs so
computational graphs are really the
heart and soul of neural networks uh we
talk about a computational graph they
are visual representation of expressing
and evaluating mathematical equations
the nodes and data flow in a graph
correspond to mathematical operations
and variables you'll hear a lot uh some
of the terms you might hear are node and
Edge The Edge being the data flow in
this case um it could also represent an
actual value they have um oh I think in
spark they have a graph x which works
just on Computing edges there's all
kinds of stuff that has evolved from
computational graphs we're focusing just
on carass and on neural networks so
we're not going to go into great detail
on everything a computational graph does
it is a core component of a neural
network is what's important to know on
this so carass offers a python
userfriendly front end while maintaining
a strong computation Power by using a
low-level API like tensor flow pie torch
Etc which use computational graphs as a
back end so one this allows for
abstraction of complex problems while
specifying control flow if you've ever
looked at some of the backend or the
original versions of tensorflow uh it's
really a nightmare you have all these
different settings you have to put in
there and create uh it's a lot of a lot
of back in programming this is like the
old computers when you had to uh tell it
how to dispose of a variable and how to
properly re allocate the memory for use
all that is covered nowadays in our
higher level programming well this is
the same thing with carass is it covers
a lot of this stuff and does things for
you that you would could spend hours on
just trying to figure
out it's useful for calculating
derivatives by using back propagation
we're definitely not going to teach a
class on derivatives uh in this little
video but understanding uh a derivative
is the rate of change so if you have a
particular function you're using in your
neural network a lot of them is just
simple uh uh y equals MX plus b um your
ukian geometry where you just have a
simple slope times the intercept and
they get very complicated they have the
inverse tangent function for Activation
as opposed to just a linear ukian model
and you can think about this as you have
your data coming in and you have to
alter it somehow well you alter it going
down to get an answer you end up with an
error and that error goes back up and
you have to have that back propagation
with the derivative you want to know how
it changed so that you can figure out
how to adjust it for the
error a lot of that's hidden so you
don't even have to worry about it with
carass and in today's carass it'll even
if you create your own um uh formula for
computing an answer it will
automatically compute the back prop the
the derivative for you in a lot of
cases it's easier to implement
distributed computation uh so cross is
really nice way to package it and get it
off on different computers and share it
and it allows parallelism which means
that two operations can run
simultaneously so as we start developing
these backends it can do all kinds of
cool things and utilize multiple cores
gpus on a computer uh to get that
parallel processing
up what are neural networks well like I
said there already uh we talked about in
computational edges you have a node and
you have a connection or your Edge so
neural networks are algorithms fashioned
after the human brain which contain
multiple layers each layer contains a
node called a neuron which performs a
mathematical operation they break down
complex problems into simple
operations so one an input layer takes
in our data and pre-processes it when we
talk about pre-processing you're dealing
with neural networks uh you usually have
to pre-process your data so that it's
between minus one and one or zero and
one um into some kind of value that's
usable that occurs before it gets to the
neural network um in fact 80% of data
science is usually impr prepping that
data and getting it ready for your
different
models two you have hidden layer
performs a nonlinear transformation of
input now it can do a hidden a linear
transformation it can use just a basic
um ukian geometry and you could think of
a node adding all the different
connections coming in uh so each
connection would have a weight and then
it would add to that weight plus an
intercept um in the node itself so you
can actually use Idan geometry but a lot
of these get really complicated they
have all these different formulas and
they're really cool to look at but when
you start looking at them look at how
they work uh you really don't need to
know the high math behind it um to
figure them out and figure out what
they're doing which is really cool that
means a lot of people can use this
without having to go get a PhD in
mathematics number three the output
layer takes the results from hidden
layer transform them and gives a final
output
so sequential models uh so what makes
this a sequential model sequential
models are linear stacks of layers where
one layer leads to the next it is simple
and easy to implement and you just have
to make sure that the previous layer is
the input to the next layer so uh you
have used for plain stack of layers
where each layer has one input and one
output tensor and this is what tensor
flow is named after is um each one of
these layers is like a tensor each each
node is a tensor and then the layer is
also considered a tensor of
values and it's used for simple
classifier de classifier models you can
it's also used for regression models too
so it's not just about uh this is
something this is a teapot this is a cat
this is a dog um it's also used for
generating um uh regret the actual
values you know this is worth $10 that's
worth $30 uh the weather's going to be
90 out or whatever it is so you can use
it for both class class ifier and
declassify
models and one more note when we talk
about sequential models the term
sequential is used a lot and it's used
in different areas and different
notations when you're in data science so
when we talk about time series we'll
talk about sequential that is something
very different uh sequential in this
case means it goes from the input to
layer one to Layer Two to the output so
it's very directional it's important to
note this because if you have a a
sequential model can you have a
nonsequential model and the answer is
yes uh if you master the basics of a
sequential model you can just as easily
have another model that shares layers um
you can have another model where they
you have an input coming in and it
splits and then you have one set that's
doing one set of uh nodes maybe they're
doing a yes no kind of node where it's
either putting out a zero or a one a
classifier and the other one might be
regression it's just processing numbers
and then you recombine them for the
output um that's what they call a cross
the cross
API so there's a lot of different
availabilities in here and all kinds of
cool things you can do as far as
encoding and decoding and all kinds of
things and you can share layers and
things like that we're just focusing on
the basic cross model with the
sequential
model so let's dive into the meat of the
matter let's do a and do a demo on here
uh today's demo in this demo we we will
be performing flower classification
using sequential model and carass and
we'll use our model to classify between
five different types of
flowers now for this demo and you can do
this demo on whatever platform you want
or whatever um user interface for
developing python um I'm actually using
anaconda and then I'm using Jupiter
notebooks to develop in and if you're
not familiar with this um you can go
under environment once you've created
environment you can come in here to open
a terminal window and if you don't have
the different modules in here you can do
youra install or whatever module it is
um just happened that this particular
setup didn't have a Seaborn in it which
I already installed uh so here's our
anaconda and then I'm going to go
back and start up my jupyter
notebook where I already created a uh
new uh python project Python 3 I'm in
Python 3.8 on this particular one um
sequential model for flowers so lots of
fun there uh so we're going to jump
right into this the first thing is to
make sure you have all your modules
installed so if you don't have uh numpy
pandas matplot library and Seaborn in
the carass um an sklearn or S kit it's
not actually sklearn you'll need to go
ahead and install all of those now
having done this for years and having
switched environments and doing
different things um I get all my imports
done and then we just run it and if we
get an error we know we have to go back
and install something um right off the
bat though we have numpy pandas matplot
Library Seaborn these are built on top
of each other pandas the data frame and
built on top of numpy the uh um data
array and then we bring in our SK learn
or S kit this is the pyit setup SCI uh
kit even though you use sklearn to bring
it in it's a s kit and then our carass
we have our pre-processing the images
image data generator um our model this
is our basic model or sequential
model uh and then we bring in from caros
layers uh import dents um
optimizers these optimizers a lot of
them already come in these are your
different optimizers and it's almost lot
of this is so automatic now um atom is
the a lot of times the default because
you're dealing with a large data uh and
then we get our SGD which is uh smaller
data does better on smaller pieces of
data and I'm not going to go into all of
these uh different optimizers we didn't
even use these in the actual demo you
just have to be aware that they are
different optimizers and the Digger the
more you dig into these models um you'll
hit a point where you do need to play
with these a little bit but for the most
part leave it at the default when you're
first starting
out and we're doing just the sequential
you'll see here layers
dense and then if we come down a little
bit more uh when they put this together
and they're running the dense layers
you'll also see they have Dropout they
have flatten they have activation uh
they have the uh convolutional layer 2D
Max pooling 2D batch
normalization what are all these layers
uh and when we get to the model we're
going to talk about them uh a lot of
times when you're just starting you can
just uh uh import cross. layers and then
you have your Dropout your flatten uh
your convolutional uh neural network 2D
and we'll we'll cover what these do in
the actual example when we get down
there uh what I want you to take from
here though is you need to run your
Imports um and load your different
aspects of this and of course your
tensor flow TF cuz this is all built on
tensor flow and then finally uh import
random as RN just for random
generation and then we get down here we
have our uh
CV2 that is your um open image or your
open CV they call it for processing
images that's what the CV2
is uh we have our
tqdm the tqdm is for um is a progress
bar just a fancy way um of adding when
you're running a process you can view
the bar going across in the Jupiter uh
setup not really necessary but it's kind
of fun to have um we want to be able to
shuffle some files uh again these are
all different things pill is another um
image processor it goes with the CV2 a
lot of times you'll see both of those
and so we run those we got to bring them
all
in and the next thing is to set up our
directories and so we come in to the
directories there's an important thing
to note on here other than we're looking
at a lot of flowers which is
fun uh is we get down here we have our
directory archive flowers that just
happens to be where the different uh
files for different flowers are put in
we're denoting an X and a z and the x is
the data of the image and the Z is the
tag for it what kind of flower is this
uh and the image size is really
important because we have to re size
everything if you have a neural network
and if you remember from our neural
networks uh let me flip back to that
slide we look at this slide we have two
input nodes here uh with an image you
have an input node depending on how you
set it up for each pixel and that pixel
has three different color schemes
usually in it sometimes four so if you
have a picture that's 150 by
150 uh you multiply 150 * 150 * 3 that's
how many nodes input layers coming in I
mean so this is a massive input a lot of
times you think oh yeah it's just a a
small amount of data or something like
that uh no it's a full image coming in
then you have your hidden layers A lot
of times they match what the image size
is coming in so each one of those is
also just as big and then we get down to
just a single output so that's kind of a
a thing to note in here what's going on
behind the scenes and of course each one
of these layers has a lot of processes
and stuff going on
and then we have our our different uh
directories on here let me go and run
that so I'm just setting the directories
that's all this is um archive flowers
Daisy sunflower tulip dandelion Rose uh
just our different directories that
we're going to be looking
at uh and then we want to go ahead and
we're need to assign labels remember we
defined x and
z so we're just going to create a uh uh
definition here um and the first thing
is a return flower type
okay just returns it what kind of flower
it is I guess assign the label to it uh
but we're going to go ahead and make our
train data and when you look at this
there's a couple things to take away
from here uh the first one is we're just
appending right onto our numpy array the
image we're going to let numpy handle
all that different aspects of as far as
150 by 150 by 3 uh we just dump it right
into the numpy which makes it really
easy we don't have to do anything funky
on the processing and we want to leave
it like that and I'm going to talk about
that in a minute uh and then of course
we have to have the string upin the
label on there and I want you to notice
right here uh we're going to read the
image
in and then we're going to size it and
this is important because we're just
changing this to 150 by 150 we're
resizing the image so it's uniform every
image comes in identical to the other
ones uh this is something that's so
important is um when you're resizing or
reformatting your data you really have
to be aware of what's going on with
images it's not a big deal because with
an image you just resize it so it looks
squishy or spread out or stretched um
the neural network picks up on that and
it doesn't really change how it
processes
it so let's go ahead and run that uh and
now we've got our definition set up on
there and then we want to go ahead and
make our
uh training data uh so make the train
data uh daisy flower daisy directory uh
print length of X so here we go let's go
and run that and we're just loading up
the flower daisy uh so this is going all
in there and it's setting um it's adding
it in to the our setup on there to our x
and z setup
and we see we have
769 um and then of course you can see
this nice bar here this is the bar going
across is that little added uh code in
there that just makes it really cool for
doing demos uh not necessarily when
you're building your own model or
something like that but if you're going
to display this to other people adding
that little what was it called
um tqdm I can never remember that uh but
the tqdm module in there is really nice
and we'll go ahead and do sunflowers and
of course you could have just uh created
an array of these um but this has an
interesting problem that's going to come
up and I want to show you something it
doesn't matter how good the people in
the back are or how good you are at
programming errors are going to come up
and you got to figure out how to handle
them uh and so when we get all the way
down
to the um where is it dandelion here's
our dandelion directory we're going to
build
um Jupiter has some cool things it does
which makes this really easy to deal
with but at the same time you would want
to go back in there depending on how
many times you rerun this how many times
you pull this so when you're finding
errors uh going in here there's a couple
things you can do and we're just going
to um oh it wasn't there it is there's
our error I knew there was an error this
processed
1,62 out of
1065 now I can do a couple things one I
can go back into our definition and I
can just put in here try and so if it
has a bad conversion because this is
where the errors is coming from uh just
skip it that's one way to do it um when
you're doing a lot of work in data
science and you look at something like
this where you're losing three points of
uh data at the end you just say okay I
lost three points who cares um or you
can go in there and try to delete it um
it really doesn't matter for this
particular demo and so we're just going
to leave that error right alone and skip
over because it's already added all the
other files in there and this is
wonderful thing about Jupiter notebook
is that I can just continue on there and
the x and z which we're creating is
still uh running and we'll just go right
into the next flower row so all these
flowers are in there um that's just a
cool thing about Jupiter
notebook uh and then we can go ahead and
just take a quick look and
see what we're dealing with and this is
of course really when you're dealing
with other people and showing them stuff
this is just kind of fun where we can
display it on the plot Library here and
we're just going to go through and um
let's see what we got here uh looks like
we're going to do like five of each of
them I think is that how they set this
up um plot Library 5 by two okay oh I
see how they did it okay so two each so
we have 5x two set up on our axes and
we're just going to go in and look at a
couple of these
flowers it's always a good thing to look
at some of your data uh no matter what
you're doing we've reformatted this to
150 by 150 you can see how it really
blurs this one up here on the Tulip that
is that resize to 150 by 150 um and
these are what's actually going in these
are all 150 by 150 images you can check
the dimensions on the side and you can
see uh just a quick sampling of the
flowers we're actually going to process
on here and again like I said at the
beginning most of your work in data
science is
reprocessing this different uh
information so we need to go ahead and
take our
labels uh and run a label encoder on
there and then we're just going to Le is
a label encoder one of the things we
imported and then we always use the
fit um to categorical y comma 5 uh X
here's our array um X so if you look at
this here's our fit we're going to
transform
Z that's our Z array we
created um and then we have Y which
equals that and then we go ahead and do
uh to categorical we want five different
categories and then we create our x uh
npay of x xal x over
255 so what's going on here there's two
different Transformations one we've
turned our categories into 0 1 2 3 4 5
as the output and we have taken our X
array
and remember the X array is three values
of your different
colors this is so important to
understand when we do this across a
numpy array this takes every one of
those three colors so we have 150 by 150
pixels out of those 150 by 150 pixels
they each have three um color arrays and
those color arrays ra range from 0 to
250 so when we take the xal X over
255 I'm sorry range from 0 to 2 55 this
converts all those pixels to a number
between 0 and one and you really want to
do that when you're working with neural
networks uh now if you do a linear
regression model um it doesn't affect it
as much and so you don't have to do that
conversion if you're doing straight
numbers but when you're running neural
networks if you don't do this you're
going to create a huge bias and that
means they'll do really good on
predicting one or two things and they'll
just totally die on a lot of other
predictions so now we have have our um X
and Y values uh X being the data in y
being our no one
output and with any good setup we want
to divide this data into our training so
we have X train uh we have our X test
this is the data we're not going to
program the model with and of course
your y train corresponds to your X train
and your y test corresponds to your X
test the outputs and this is uh when we
do the train test split this was from
the S kit sklearn we imported train test
split and we're just going to go ahead
and do the test size at about a quarter
of the data 0.25 and of course random is
always good this is such a good tool I
mean certainly you can do your own
division um you know you could just take
the first you know 0.25 of the data or
whatever do the length of the data not
real hard to do but this is randomized
so that if you're running this test a
few times you can kind of get an idea
whether it's going to work or not some
times what I will do is um I'll just
split the data into three parts and then
I'll test it on two with one being the U
or train it on two of those parts with
one being the test and I rotate it so I
come up with three different answers
which is a good way of finding out just
how good your model is uh but for
setting up let's stick with the X train
X test and the SK learn
package and then we're going to go ahead
and uh do a random
seed uh now a lot of times the cross
actually does this automatic IC Ally but
we're going to go ahead and set it up on
here and you can see we did an NP random
seed um from 42 and we get a nice RN
number um and then we do TF random we
set the seed so you can set your
Randomness at the beginning of your
tensor flow and that's what the tf.
random. set
is so that's a lot of prep um all this
prep and then we finally get to the
exciting part um this is where you
probably spend once you have the data
prepped and you have your pipeline going
and you have everything set up on there
this is the part that's exciting is
building these
models and so we look at this model one
we're going to designate it sequential
um they have the API which is a cross
the cross tensorflow API versus
sequential sequential means we're going
one layer to the next so we're not going
to split the layer and bring it back
together it looks almost the same with
the exception of um bringing bring it
back together so it's not a huge step to
go from this to an
API and the first thing we're going to
look at is um our convolutional neural
network in 2D uh so what's going on here
there's a lot of stuff that's going on
here um the default for well let's start
with the beginning what is a
convolutional 2d
Network well convolutional 2D Network
creates a number of small windows and
those small Windows float over the
picture and each one of them is their
own neural network and it's basically U
becomes like a um a categorization and
then it looks at that and it says oh if
we add these numbers up a certain way uh
we can find out whether this is the
right flower based on this this little
window floating around which looks at
different things and we have filters 32
so this is actually creating 32 Windows
is what that's
doing and the kernel size is 5 by by 5
so we're looking at a 5x5 Square
remember it's 150 by 150 so this narrows
it down to a 5x5 it's a 2d so it has
your XY coordinates um and when we look
at this 5x5 remember each one of these
is is actually looking at 5x5
by3 uh so we're actually looking at 15
by 15 different um
pixels and padding is just um uh usually
I just ignore that activation by default
is ru we went ahead and put the rilu in
there there's a lot of different
activations Rilo is for your smaller uh
when you remember I mentioned atom when
you have a lot of data data use an atom
kind of activation or use an atom
processing we're using the ru here uh it
kind of gives you a yes or no but it it
doesn't give you a full yes or no it has
a um a zero and then it kind of shoots
off at an angle very common it's the
most common wand and then of course
here's our input shape 150 by 150 by 3
pixels and then we have to pull it so
whenever you have a two convolutional 2D
um uh layer we have to bring this back
together and pull this into uh neural
network and then we're going to go ahead
and repeat
this uh so we're going to add another
Network here one of the cool things if
you look at this is that it as it comes
in it just kind of it automatically
assumes you're going down to the next
layer and so we have another
convolutional null Network 2D here's our
Max pooling again we're going to do that
again Max pooling uh and we're just
going to filter on down now one of the
things they did on this one is they
change the kernel size they change the
number of filters and so each one of
these steps kind of looks at the data a
little bit differently and that's kind
of cool because then you get a little
added filtering on there this this is
where you start playing with the model
you might be looking at a convolutional
no network which is great for image
classifications um we get down to here
one of the things we see is flatten so
we had a we just flatten it remember
this is 150 by 150 by 3 well and
actually the pool size changes so it's
actually smaller than that flatten just
puts that into a 1D array uh so instead
of being you know a tensor of this
really complexity with the the pixels
and everything it's just flat and and
then the D is just another activation on
there um by default it is probably railu
as far as it's
activation and then oh yeah here we go
in sequential they actually added the
activation as railu so this just because
this is sequential this activation is
attached to the dents uh and there's a
lot of different activations but Ru is
the most common one and then we also see
a soft Max uh soft Max is similar but it
has its own kind of variation
and one of the cool things you know what
let me bring this up because if we if
you don't know about these activations
this doesn't make
sense and I just did a quick Google
search on images of tensorflow
activations um I should probably look at
which website this is but this is the
output of the values uh so as your X as
it adds in all those uh weighted X
values going into the node it's going to
activate it a certain way and that's a
sigmoid activation and you can see it
goes between zero and one and has a nice
curve there this also shows the
derivatives um and if we come down the
seven popular activation functions
nonlinear activations there's a lot of
different options on this let me see if
I can find
[Music]
the let me see we can find this specific
to
Rayo so this is a leaky
raayo and you can see instead of it just
being zero and then a value between uh
going up it has a little leaky there
otherwise your railo loses some noes
they just become inactive um but you can
see there's a lot of different options
here here's a good one right here with
the railu you can see the railo function
on the upper on the upper left here and
then the Leaky raayo over here on the
right which is very commonly used
also one of the things I use with
processing um language is the S is the
exponential one or the tangent H the
hyperbolic tangent because they have
that nice uh funky curve that comes in
that um has a whole different meaning
and captures word use better again these
are very specific to domain and you can
spend a lot of time playing with
different models for our basic model uh
we'll stick to the ru and the softmax on
here and we'll go a and run and build
this
model so now that we've had fun playing
with all these different models that we
can add in there uh we need to go ahead
and have a batch size on here uh
128 epics
10 this means that we're going to send
128 uh rows of data or flowers at a time
to be processed and the Epic 10 that's
how many times we're going to Loop
through all the
data um and then there's all kinds of
stuff you can do again this is now built
into a lot of carass models already by
default
um so there's different ways to reduce
um the values and and verbose verbose
equals one means that we're going to
show what's going on um value monitor
what we're monitoring we'll see that as
we actually train the model this is
what's what's going to come out of there
if you set the verbos equal to zero um
you don't have to watch it train the
model although it is kind of nice to
actually know what's going on
sometimes and since we're still working
on uh bringing the data in here's our
batch side here's our epics we need to
go ahead and create a data generator uh
this is our image data
generator and it has all the different
settings in here almost all of these are
defaults uh so if you're looking at this
going oh my gosh this is confusing most
of the time you can actually just ignore
most of this um vertical flip so you can
randomly flip pictures you can randomly
horizontally flip them um you can shift
the picture around this kind of helps
gives you multiple data off of them uh
zooming rotation there's all kinds of
different things you can do with images
most of these we're just going to leave
as false we don't really need to do all
that um um setup because we already have
a huge amount of data if you're short
data you can start flipping like a
horizontal picture and it will generate
it's like doubling your data almost um
so the upside is you double your data
the downside is that if you already have
a bias in your data you already have um
5,000 sunflowers and only two roses
that's a huge bias it's also going to
double that bias uh that is the downside
of
that and so we have our model compile
and this you're going to see in all the
carass we're going to take this model
here we're going to take all this
information as far as how we want it to
go and we're going to compile it this
actually builds the model and so we're
going to run that and I want you to
notice uh learning
rate very important this is the default
001 um there's there you really don't
this is how slowly it adjusts to find
the right answer and the more data you
have you might actually make this a
smaller number um with larger with you
have a very small sample of data you
might go even larger than that and then
we're going to look at the loss
categorically categorical cross entropy
most commonly used and this is uh how
how much it improves the model is
improving is what this number means or
yeah that's that's important on there
and then the accur accuracy we want to
know just how good our model is on the
accuracy and then uh one of the cool
things to do is if you're in a group of
people who are studying the model if
you're in shareholders you don't want to
do this is you can run the model summary
I do this by default and you can see the
different layers that you built into
this model just a quick summary on there
so we went ahead and we're going to go
ahead and create a
um we'll call it history but we want to
do a model fit
generator and so what this history is
doing is this is tracking what's going
on as while it fits the
model now there's a lot of new setups in
here where they just use fit and then
you put the generator in here um we're
going to leave it like this even though
the new default um is a little different
on that doesn't really matter it does
the same thing and we'll go ahead and
just run
that and you you can see while it's
running right here uh we're going
through the epics we have one of 10 now
we're going through 6 of 25 here's our
loss we're printing that out so you can
see how it's improving and our accuracy
the accuracy gets better and better and
this is 6 out of 25 this is going to
take a couple minutes to process uh
because we are training 150 by 150 by 3
pixels across uh six layers or eight
layers whatever it was that is a huge
amount of processing so this will take a
few minutes to process this is when we
talk about the hardware and the problems
that come up in data science and why
it's only now just exploding being able
to do neural networks this is why this
process takes a long
time now you should have seen a jump on
the screen here because I did uh uh
pause the recorder to let this go ahead
and run all the way through its epics
let's go ahead and take a look and see
what these epics are and um if you set
the verbos to uh zero instead of one it
won't show what's going on in the behind
the scenes as it's training it so when
we look at this epic 10 epic so we went
through all the data 10 times uh if I
remember correctly there's roughly a gig
of data there so that's a lot of data
the first thing you're going to notice
is the 270 seconds um that's how much
each of those epics took to run and so
if you divide 60 in there you roughly
get about 5 minutes worth of each epic
so if I have 10 Epic that's 50 minutes
almost an hour of
runtime that's a big deal when we talk
about processing uh in on this
particular computer um I actually have
what is it uh uh eight cores with 16
dedicated threads so it runs like a 16
core computer it alternates the threads
going in and it still takes it five
minutes for each one of these epics so
you start to see that if you have a lot
of data this is going to be a problem if
you have a number of models you want to
Fe find out how good the models are
doing and what model to use and so each
of those models could take all night to
run in fact I have a model I'm running
now that takes over uh takes about a day
and a half to test each model um it
takes four days to do the whole data uh
so what I do is I actually take a small
piece of the
data test it out to find out uh get an
idea of of how the different setups are
going to do and then I increase that
size of the data and then increase it
again and I can just take that that
curve and kind of say okay if U the data
is doing this then I need to add in more
dense layers or whatever uh so you can
do a small chunks of data then figure
out what it costs to do a large set of
data and what kind of model you
want the loss as we see here continues
to go down uh this is the error this is
how much errors is in there it really
isn't a um userfriendly number other
than the more it Trends down the better
and so if you continue to to see the
loss going down eventually it'll get to
the point where it stops going down and
it goes up and down and kind of waivers
a little bit that point you know you've
run too many epics you're you're
starting to get a bias in there and it's
not going to give you a good model fit
the accuracy just turns this into
something that uh we can use and so the
accuracy is what percentage of guesses
in this case is categorical so this is a
percentage of guesses are correct um
value loss is similar you know it's a
minus a value loss and and then you have
the value accuracy and you'll see the
value accuracy is pretty similar to the
accuracy um just rounds it off basically
and so a lot of times you come down here
and you go okay we're doing 0.5
6 7 and that is 70% accuracy or in this
case 68 uh 59% accuracy that's a very
usable number and it's very important to
have if you're identifying uh flowers
that's probably good enough if you can
get within a close distance and knowing
what flower you're you're identifying
uh if you're trying to figure out
whether someone's going to die from a
heart attack or not might want to
rethink it a little bit or rekey how
you're building your model so if I'm
working with a uh uh a group of um
clients um shareholders in a company or
something like that you don't really
want to show them this um you don't want
to show them hey you know this is what's
going on with the accuracy these are
just numbers and so we want to go and
put the finishing touches just like when
you are building a house and you put in
the frame and the trim on the house it's
nice to have something a nice view of
what's going on and so we'll go ahead
and do a pip plot and we'll just plot
the history of the loss uh the history
of the value
loss over here um epics train and test
and so we're just going to compute these
this is really important uh and what I
want you to notice right here is when we
get to about oh five epics a little more
than five six epics you see a cross over
here and it starts Crossing as far as
the um uh value loss and what's going on
here is you have the loss in your actual
model and your actual data and you have
the value loss where it's testing it
against the the test data the the data
wasn't used to program your model wasn't
used to train your model on and so when
we see this crossing over this is where
the bias is coming in this is becoming
overfitted and so when you put these two
together uh right around five and six
you start to see how it does this this
switch over here and that's really where
you need to stop right around five yeah
six um it's always hard to guess because
at this point the model is kind of a
black box uh see but you know that right
around here if you're saving your model
after each run you want to use the one
that's right around five epics because
that's the one that's going to have the
least amount of bias so this is really
important as far as guessing what's
going on with your model and its
accuracy and when to stop uh it also is
you know I don't show people this mess
up here um I show somebody this kind of
model and I say this is where the
training and the testing comes in on
this model uh it just makes it easier to
see and people can understand what's
going
on so that completes our demo and you
can see we did what we were set out to
do we took our flowers and we're able to
classify them uh within about you 68 70%
accuracy whether it's going to be a
dollia sunflower cherry blossom Rose um
a lot of other things you can do with
your output as far as a different tables
to see where the errors are coming from
and what problems are coming up image
classification using
carass and we're going to take a look at
image classification using carass and
the basic setup we'll actually look at
two different demos on
here uh what's in it for you today what
is image
classification Intel image
classification data creating neural
networks with carass and the vgg16
model what is image
classification the process of image
classification refers to assigning
classes to an entire image images can be
classified based on different categories
like whether it is a nighttime or
daytime shot what the image represents
Etc and you see here we have mountains
looking for mountains we'll actually be
doing some uh uh pictures of scenery and
stuff like that in deep learning we
perform image classification by using
neural networks to extract features from
images and classifies them based on
these
features and you can see here where it
says like what computer sees and this
says oh yeah we see mostly Forest maybe
a little bit of mountains because the
way the image is um and this is really
where one of the areas that neural
networks really shines um if you try to
run this stuff through uh more like a
linear regression model you'll still get
results uh but the results kind of miss
a lot of things as they as the neural
networks get better and better at what
they do with different tools we have out
there uh so Intel image classification
data the data being used is the Intel
image classification data set which
consists of images of six types of land
areas and so we have Forest building
glaciers and mountains sea and Street uh
and you can see here there's a couple of
the images out of there as a setup in in
the um uh Intel image classification
data that they
use and then we're going to go into
creating a neural networks with
carass the convolutional neural network
that we are creating from scratch looks
uh as showing
below you see here we have our input
layer
um they have have a listed Max pooling
uh so you have as you're coming in with
the input layer and this the input layer
is actually um before this but the first
layer that it's going to go into is
going to be a convolutional neural
network uh then you have a Max pooling
that pulls those the the convolutional
neural networks returns uh in this case
they have two of those that is very
standard with convolutional neural
networks uh one of the ones that I was
looking at earlier that was a standard
being used by um I want one of the
larger companies I can't remember which
one for doing a large amount of
identification had two convolutional
neural networks each with their Max
pooling and then about 17 dense layers
after it we're not going to do that
heavy duty of a of a code but we'll get
you head in the right direction and that
gives you an idea of what you're
actually going to be looking at when you
look at the flattened part and then the
dense we're talking like 17 dense layers
afterwards uh I find that a lot of the
stuff I've been working on I end up
maxing it out right around nine dense
layers it really depends on what you
have going in and what you're working
with and the vgg16
model uh vgg16 is a pre-trained CNN
model which is used for image
classification it is trained on a large
varied data set and fine-tuned to fit
image classification data sets with
ease and you can see down here we have
the input coming in uh the convolutional
neural network one 1 to one 1:2 and then
pooling and then we do 2: one 2:2
convolutional Network then pooling 3:2
and you can see there's just this huge
layering of convolutional neural
networks and in this case they have five
such layers going in and then in three
dents going out or uh more now when they
took this setup this actually won an
award uh back in 2019 for this
particular
setup uh and it does it does really good
except ccept that again um we only show
the three dense layers here and as you
find
out depending on your data going in what
you have set up uh that really isn't
enough on one of these setups and I'm
going to show you why we restricted it
because it does take up a lot of
processing power in some of these things
so let's go ahead and roll up our
sleeves and we're going to look at both
the setups we're going to start with the
um the first
classification um and then we'll go into
the vgg16 and show you how that's set up
now I'm going to be using anaconda and
let me flip over to my anaconda so you
can see what that looks like now I'm
running in the Anaconda here uh you'll
see that I've set up a main python uh 38
I always put that in there this is where
I'm doing like most of my kind of
playing around uh this is done in Python
version 3.8 we're not going to dig too
much into versions uh at this point you
should already have carass installed on
there usually carass takes a number of
extra steps
and then our usual um uh setup is the
numpy the pandas uh your SK your s kit
which is going to be the sklearn your
caborn and I'll I'll show you those in
just a minute um and then I'm just going
to be in the Jupiter lab where I've
created a new um notebook in here and
let's flip on over there to my blank
notebook now I'm there's a couple cool
things to note in here is is that um one
I used the the um Anaconda Jupiter
notebook setup because it keeps
everything separate uh except for carass
uh carass is actually running separately
in the back I believe it's a a c program
uh what's nice about that is that it
utilizes the multiprocessors on the
computer and I'll mention that just in a
little bit when we actually get down to
running the
code and when we look in here uh a
couple things to note is here's our uh
um oops I thought I grabbed the other
drawing thing uh but here's our numpy
and our pandas right here and our
operating system this is our SII kit you
always import it as sklearn for the
classification report uh we're going to
be using well usually import like
Seaborn brings in all of your pip plot
Library
also kind of nice to throw that in there
I can't remember if we're actually using
caborn if they just the people in the
back just threw that together um and
then we have the sklearn shuffle for
shuffling data here's our map plot
library that the caborn is pretty much
built on um CV2 if you're not familiar
with that that is our image um module
for importing the image and then of
course we have our tensor flow down here
which is what we're really working
with and then the last thing is just for
visual effect while we're running this
um if you're doing a demo and you're
working with uh the partners or the
shareholders uh this tqdm is really kind
of cool it's an extensible progress bar
for Python and I I'll show you that too
remember data science is not I mean you
know most this code when I'm looking
through this code I'm not going to show
half of this stuff to the shareholders
or anybody I'm working with they don't
really care about pandas and all that we
do because we want to understand how it
works uh so we need to go ahead and
import those different um uh setup on
there there and then the next thing is
we're going to go ahead and set up our
classes uh now we remember if we had
Mountain streak Glacier building sea and
Forest those are the different images
that we have coming
in and we're going to go ahead and just
do class name labels and we're going to
kind of match that class name of I for I
class name uh equals the class names so
our labels are going to match the names
up
here uh and then we have the number of
classes and print the class names and
the labels and we'll go ahead and set
the image size this is important that we
resize everything because if you're
remember with neural
networks they take one size data coming
in and so when you're working with
images you really want to make sure
they're all resized to the same uh setup
it might squish them it might stretch
them that generally does not cause a
problem in these uh and some of the
other tricks you can do with if you if
you need more data um and this is one
that's used regularly we're not going to
do it in here is you can also take these
images and not only resize them but you
can til them one way or the other crop
parts of them um so they process
slightly differently and it'll actually
increase your accuracy of some of these
predictions uh and so you can see here
we have Mountain equals zero that's what
this class name label is Street equals 1
Glacier equals 2 buildings equals 3 C4
Forest equals 5 now now we did this as
an enumerator so each one is 0 through
five uh a lot of times we do this
instead as um uh uh 0 one 0 one0 one so
you have five outputs and each one's a
zero or a one coming out so the next
thing we really want to do is we want to
go ahead and load the data up and just
put a label in there loading
data just just so you know what we're
doing we going to put in the loading
data down here uh make sure it's well
labeled uh and we'll create a definition
for this and this is all part of your
pre-processing at this point you could
replace this with all kinds of different
things depending on what you're working
on and if you once you download you can
go download this data set uh send a note
to the simply learn team here in YouTube
um and they'll be happy to direct you in
the right direction and make sure you
get this path here um so you have it
right whatever wherever you saved it a
lot of times I'll just abbreviate the
path or put it as a sub thing and just
get rid of the directory um but again
double check your paths um we're going
to separate this into a segment for
training and a segment for testing and
that's actually how it is in the folder
let me just show you what that looks
like so when I have my uh lengthy path
here where I keep all my programming
simply learned this particular setup
we're working on image classification
and image classification clearly you
probably wouldn't have that lengthy a
list and when we go in here uh you'll
see sequence train sequence test they've
already split this up this is what we're
going to train the data in and again you
can see buildings Forest Glacier
Mountain Sea Street uh and if we double
click let's go under Forest you can see
all these different Forest uh images and
and there's a lot of variety here I mean
we have wintertime we have
summertime um so it's kind of
interesting you know here's like a
Fallen Tree versus um a road going down
the middle middle that's really hard to
train and if you look at the
buildings A lot of these buildings
you're looking up a skyscraper we're
looking down the
setup here's some trees with one I want
to highlight this one it has trees in it
uh let me just open that up so you can
see it a little
closer the reason I want to highlight
this is I want you to think about this
we have trees growing is this the city
or a forest um so this kind of imagery
makes it really hard for a classifier
and if you start looking at these you'll
see a lot of these images do have trees
and other things in the foreground weird
angles really a hard thing for a
computer to sort out and figure out
whether it's going to be a forest or a
um
city and so in our loading of data uh
one we have to have the path the
directory we're going to come in here we
have our images and our labels so we're
going to load the images in one section
the labels in another
um and if you look through here it just
goes through the different folders uh in
fact let me do this let
me there we go uh as we look at this
we're just going to Loop through the
three the six different folders that
have the different Landscapes and then
we're going to go through and pull each
file
out and each label uh so we set the
label we set the folder for file and
list
uh here's our image path join the paths
this is all kind of General stuff um so
I'm kind of skipping through it really
quick and here's our image setup uh if
you remember we're talking about the
images we have our CV2 reader so it
reads the the image in uh it's going to
go ahead and take the image and convert
it to from blue green red to red green
green blue this is a CV2 thing um almost
all the time it Imports it and instead
of importing it as a standard that's
used just about everywhere it Imports it
with the BGR versus RGB um RGB is pretty
much a standard in here you have to
remember that was CV2 uh and then we're
going to go ahead and resize it this is
the important part right here we've set
a we've decided what the size is and we
want to make sure all the images have
the same size on
them and then we just take our images
and we're just going to pin the image
pin the label uh and then the images is
going to turn into a numpy array this
just makes it easier to process and
manipulate and then the labels is also a
numpy array and then we just return the
output pend images and labels and we
return the output down
here so we've loaded these all into
memory uh we haven't talked to much
there'd be a different setup in there
because there is ways to feed the files
directly into your cross model uh but we
want to go ahead and just load them all
it's
really for today's processing and that
what our computers can handle that's not
a big deal and then we go ahead and set
the uh train images train labels test
images test labels and that's going to
be returned in our output app pinned and
you can see here we did um uh images and
labels set up in there and it just loads
them in there so we'll have these four
different categories let me just go
ahead and run that
uh so now we've gone ahead and loaded
everything on
there and then if you remember from
before uh we imported just go back up
there Shuffle here we go here's our
sklearn utilities import Shuffle and so
we want to take these labels and shuffle
them around a little bit um just mix
them up so it's not having the same if
you run the same process over over and
over uh then you might run into some
problems on
there and just real quick let's go ahead
and do uh um a plot so we can just you
know we we've looked at them as far as
from outside of our code we pulled up
the files and I showed you what that was
going on we can go and just display them
here too and tell you when you're
working with different
people this should be highlighted right
here um this thing is like when I'm
working on code and I'm looking at this
data and I'm trying to figure out what
I'm doing I skip this process the second
I get into a meeting and I'm showing
what's going on to other people I skip
everything we just did so and go right
to here where we want to go ahead and
display some images and take a look at
it and in this display um I've taken
them and I resized the images to 20 by
20 that's pretty small
uh so we're going to lose just a massive
amount of detail and you can see here
these nice pixelated images um I might
even just stick with the folder showing
them what images we're
processing uh again this is you got to
be a little careful this maybe resizing
it was a bad idea um in fact let me try
it without resizing it and see what
happens oops so I took out the image
size and then we put this straight in
here one of the things again this is
um put the D there we go one of the
things again that we want to
know whenever we're working on these
things uh is the
CV2 there are so many different uh image
classification setups it's really a
powerful package when you're doing
images but you do need to switch it
around so that it works with the p plot
and so make sure you take your numpy
array and change it to a u integer 8
format uh because it comes in as a float
otherwise you'll get some weird images
down there um and so this is just
basically we split up our we've created
a plot we went ahead and did the plot 20
by 20 um or the plot figure size is 20
by 20 um and then we're doing 25 so a
5x5 subplot um nothing really going on
here too exciting but you can see here
where we get the images and really when
you're showing people what's going on
this is what they want to see uh so you
skip over all the code and you have your
meeting you say okay here's our images
of the
building um don't get caught up in how
much work you do get caught up in what
they want to see so if you want to work
in data science that's really important
to
know and this is where we're going to
start uh having fun uh here's our model
this is where it gets exciting when
you're digging into these models and you
have here uh let me get
there we
go when you have here if you look here
here's our convolutional neural network
uh
2D and uh 2D is an image you have two
different dimensions x y and even though
there's three colors it's still
considered 2D if you're running a video
you'd be convolutional neural network 3D
if you're doing a series going across um
a Time series it might be
1D and on these you need to go ahead and
have your convolutional n network if you
look here there's a lot of really cool
settings going on to dig into um we have
our input shape so everything's been set
to 150 by 150 uh and it has of course
three different color schemes in it
that's important to notice um
activation default is railu uh this is
small amounts of data being processed on
a bunch of little um neural networks
and right here is the 32 that's how many
of these convolutional null networks are
being strung up on here and then the
3X3 uh when it's doing its steps it's
actually looking at uh a little 3x3
Square on each image and so that's
what's going on here and with
convolutional noral networks the window
floats across and adds up all these
numbers going across on this data and
then EV it comes up with 30 in this
casee 32 different feature options uh
that it's looking for and of course you
can change that 32 you can change the
3X3 so you might have a larger setup you
know if you're going across
150 um by 150 that's a lot of steps so
we might run this as 15 by 15 uh there's
all kinds of different things you can do
here we're just putting this together
again that would be something you would
play with to find out which ones are
going to work better on this setup um um
and there's a lot of play
involved that's really where it becomes
an art form is guessing at what that's
going to be the second part I mentioned
earlier and I I can only begin to
highlight this um when you get to these
dense layers one is the activation is a
railu they use a railu and a softmax
here um it's a whole whole uh setup just
explaining why these are different um
and how they're different because
there's also an expan itial there's a
tangent in fact uh there's just a ton of
these and you can build your own custom
activations depending on what you're
doing a lot of different things go into
these activations uh there are two or
three major thoughts on these
activations and Ru and softmax are uh
well Ru uh you're really looking at just
the number you're adding all the numbers
together and you're looking at ukian
geometry um ax +
BX 2 plus
cx3 plus bias with softmax this belongs
to the party of um it's activated or
it's not except it's they call it
softmax because when you get to the to
zero instead of it just being zero uh
it's actually slightly a little bit less
than zero so that when it trains it
doesn't get lost um there's a whole
series of these activations another
activation is the tangent
um where it just drops off and you have
like a very narrow area where you have
from minus one to one or exponential
which is 0 to one so there's a lot of
different ways to do the
activation again we can do that' be a
whole separate lesson on here we're
looking at the convolutional neural
network um and we're doing the two pools
this is so common you'll see two two
convolutional n networks stacked on top
of each other each with its own Max pull
underneath and let's go ahead and run
that so we built our model there and we
need to go ahead and
um compile the model so let's go ahead
and do
that uh we are going to use the atom uh
Optimizer the bigger the data the atom
fits better on there there's some other
Optimizer but I think atom is a default
um I don't really play with the
optimizer too much that's like the if
once you get a model that works really
good you might try some different
optimizer uh but Adam's usually the most
and then we're looking at
loss pretty standard we want to minimize
our LW we want
to maximize the loss of error and then
we're going to look at accuracy um
everybody likes say accuracy I'm going
to tell you right
now I start talking to people and like
okay what's what's the loss on this and
that and as a data science yeah I want
to know how the law what what's going on
with that and we'll show you why in a
minute but everybody wants to see
accuracy we want to know how accurate
this is uh and then we're going to run
the fit and I wanted to do this just so
I can show you even though we're in a
python setup in here where Jupiter
notebook is using only a single
processor I'm going to bring over my
little CPU Tool uh this is eight cores
on 16 dedicated threats so it shows up
as 16
processors and actually I got to run
this and then move it over so we're
going to run this and hopefully it
doesn't destroy my
mic uh and as it comes in you can see
it's starting to do go through the epics
we said I set it for five epics and then
this is really nice because carass uses
all the different uh threads available
so it does a really good job of doing
that uh this is going to take a while if
you look at here it's um ETA 2 minutes
and 25 seconds 24 seconds so this is
roughly 2 and a half minutes per epic uh
and we're doing five epics so this is
going to be done in roughly 15 minutes I
don't know about you but I don't think
you want to sit here for 15 minutes
watching The Green bars go across so
we'll go ahead and let that run and
there we go uh there was our 15 minutes
it's actually less than that uh because
I did when I went in here realized that
uh uh where was
it here we go here's our model compile
here's our model flit uh fit and here's
our epics uh so I did four epics so a
little bit better more like 10 to 11
minutes instead of uh uh doing the full
uh 15 and when we look at this here's
our model we did talked about the
compiler uh here's our history we're
going to um history equals the model fit
we'll go into that in just a
minute and what we're looking at is we
have our epics um here's our validation
split so as we train it uh we're
weighing the accuracy versus you kind of
pull some data off to the side uh while
you're training it and the reason we do
that is that um you don't want to
overfit and we'll look at that chart in
just a
minute uh here's batch
size this is just how many images you're
sending through at a time the larger the
batch it actually increases the
processing speed um and there's reasons
to go up or down on the batch size
because of the U the the smaller the
batch there's a certain point where um
you get too large of a batch and it's
trying to fit everything at once uh so I
128's kind of big um depends on the
computer you're on what it can handle
and then of course we have our train
images and our train labels going in
telling it what we're going to train
on
and then we look at our four epics here
uh here's our accuracy we want the
accuracy to go up and we get all the way
up to
83 or
83% uh this is actual percentage based
pretty much and we can see over here our
loss we want our loss to go down really
fluctuates uh 55 1.2
7748 uh so we have a lot of things going
on there let's ahead and graph
those turn that off and our our team in
the back did a wonderful job of putting
together um this basic plot setup um
here's our subplot coming in we're going
to be looking at um uh from the history
we're going to send it the accuracy and
the value accuracy labeles and set up on
there um and we're going to also look at
loss and value loss so you can see what
this looks like what's really
interesting about this setup and let me
let me just go ahead and show you cuz uh
without actually seeing the plots it
doesn't make a whole lot of sense uh
it's just basic plotting of uh of the
data using the pi plot library and I
want you to look at this this is really
interesting um when I ran this the first
time I had very different
results um and they they vary greatly
and you can see here our accuracy
continues to climb
um and there's a crossover
here put it in here right here's our
crossover and I point that out because
as we get to the right of that crossover
where our
accuracy U and we're like oh yeah I got
8% we're starting to get an overfit here
that's what this this switch over means
um as our value um as a training set
versus a value um accuracy stays the
same and so that this is the one we're
actually really want to be aware of and
where it
crosses that's kind of where you want to
stop at um and we can see that also with
the train loss versus the value loss
right here we did one Epic and look how
it just flat lines right there with our
loss so really one Epic is probably
enough and you're going to say wow okay
8% um certainly if I was working with
the shareholders um telling them that it
has an 80% accuracy isn't quite true and
and we'll look at that a little deeper
it really comes out here that the
accuracy of our actual values is closer
to 0 41% right here um even after
running it this number of times and so
you really want to stop right here at
that crossover one Epic would have been
enough um so the data is a little
overfitted on this when we do four epics
and uh oops there we are
okay I drawing won't go away um let me
see if I can get there we
go uh for some reason I've killed my
drawing ability on my
recorder all right took a couple extra
clicks uh so let's go ahead and take a
look at our actual test loss um so you
see where cross is over that's where I'm
looking at that's where we start over
fitting the model and this is where if
we were going to go back and continually
upgrade the model we would start taking
a look at the images and start rotating
them uh we might start playing with the
convolutional neural network instead of
doing the 3X3 window um we might expand
that or you know find different things
that might make a big difference as far
as the way it processes these things um
so let's go ahead and take a CLI at our
uh our test loss now remember we had our
training data now we're going to look at
our test images and our test
labels for our test loss here and this
is just model evaluate uh just like we
did fit up here where was it um one more
model fit with our trending data going
in now we're going to evaluate it on the
and and this data has not been touched
yet so this model's never seen this data
this is on uh completely new information
as far as the model is concerned of
course we
already know what it is from the labels
we
have and this is what I was talking
about here's the actual accuracy right
here
048 uh or
4847 so this 49% of the Time guesses
what the image
is uh and I mean really that's a bottom
dollar uh does this work for what you're
needing does 49% work do we need to
upgrade the model more um
in some cases this might be uh oh what
was I doing I was working on uh stock
evaluations and we were looking at what
stocks were the top
performers well if I get that 50%
correct on top
performers uh I'm good with that um
that's actually pretty good for stock
evaluation in fact the number I had for
stock was more like U um 30 something
per as far as being a top performer
stock much harder to predict um but at
that point you're like well I'm you'll
make money off of that so again this
number right here depends a lot on the
domain you're working
on then we want to go ahead and bring
this home a little bit more uh as far as
looking at the different setup in here
and one of the uh from sklearn if you
remember actually let's go back to the
top uh we had the classif ification
report and this came in from our sklearn
or S kit setup and that's right here you
can see it right here on the
um see there we go uh classification
report right here uh sklearn metrics
import classification report that's
we're going to look at
next a lot of this stuff uh depends on
who you're working with so when we start
looking at um
Precision you know this is like for each
value I can't remember what one one one
was probably mountains so if 44% is not
good enough if if you're doing like um
you're in the medical department and
you're doing cancer is it is this
cancerous or not I'm only 44% accurate
not a good deal you know I would not go
with that um so it depends on what
you're working with on the different
labels and what they're used for
Facebook you know 44% I'm guessing the
right person I would hope it does a
little bit better than that um but
here's our main accuracy this is what
almost everybody looks at they say oh
48% that's what's important um again it
depends on what domain you're in and
what you're working
with and now we're going to do the same
model somehow I got my there it goes I
thought I was going to get stuck on
there again uh this time we're going to
be using the
vgg16 and remember this one
uh all those layers going into it so
it's basically a bunch of convolutional
n networks getting smaller and smaller
on here uh and so we need to go ahead
and um import all our different stuff
from carass uh we're importing the main
one is the V g16 setup on there just aim
that there we go
um there's kind of a pre-processing
images um applications pre-process input
this is all part of the V b g g16 setup
on there uh and once we have all those
we need to go ahead and create our
model and we're just going to create a
vgg16 model in here um inputs model
inputs outputs model inputs I'm not
going to spend as much time as I did on
the other one uh we're going to go
through it really quickly one of the
first things I would do is if you
remember in carass you can treat treat a
model like you would a layer um and so
at this point I would probably add a lot
of dense layers on after the vgg16 model
and create a new model with all those
things in there and we'll go ahead and
uh run this uh because here's our model
coming in and our setup and it'll take
it just a moment to compile that what's
funny about this is I'm I'm waiting for
it to download the um package since I
prean this um it takes it a couple
minutes to download the vgg 6 model into
here um and so we want to go ahead and
train features for the model we're going
to predict that we're going to predict
the train images and we're going to test
features on the predict test images on
here and then I told you I was going to
create another model too and the people
in the back uh did not disappoint me
they went ahead and did just that and
this is really an important part um this
is worth stopping for I told you I was
going to go through this really quick so
here's our
uh we we have our model
two um coming in and we we've created a
model up here with the vgg16 model
equals model inputs model inputs and so
we have our
vgg16 this has already been
pre-programmed uh and then we come down
here and I want you to notice on this um
right here layer model two layers minus
4 to 1 x layer X um we're basically
taking this model and we're adding stuff
onto it and so uh we've taken we've just
basically duplicated this model we could
have done the same thing by using model
up here as a layer um we could have had
the input go to this model and then have
that go down here so we've added on this
whole setup this whole block of code
from 13 to 17 has been added on to our
vgg 16 model and we have a new model uh
with the layer input and X down here
let's go ahead and run that and compile
it and that was a lot to go through
right there uh when you're building
these models this is the part that gets
so
complicated did you get stuck playing in
and yet it's so fun uh it's like a
puzzle how can I Loop these models
together and in this case you can see
right here that the layers uh we're just
copying layers over and adding each
layer in um this is one way to build a
new model and we'll go ahead and run
that like I said the other way is you
can actually use the model as a layer I
had a little trouble playing with it uh
sometimes when you're using the Straight
model
over you run into issues
um it seems like it's going to work and
then you mess up on uh the input and the
output layers there's all kinds of
things that come
up let's go ahead and do the new model
we're going to compile it uh again
here's our metrics accuracy sparse
categorical loss uh pretty
straightforward just like we did before
you got to compile the
model and just like before we're going
to take our create a history uh the
history is going to be uh new model fit
train
128 and just like before if you remember
when we started running this stuff we're
going to have to go ahead and it's going
to light up our uh setup on here and
this is going to take a little bit to
get us all set up uh it's not going to
just just happen in in a couple minutes
so let me go ahead and pause the video
and run it and then we'll talk about
what
happened okay now when I ran that these
actually took about six minutes each um
so it's a good thing I put it on hold we
did four epics uh actually had to stopic
say at 10: and switch it to four because
I didn't want to wait an
hour and you can see here our
accuracy um and our L numers going down
and just at a glance
it actually performed if you look at the
accuracy.
2658 um so our accuracy is going down or
you know
26% um 34% 35% and you can see here at
some point it just kind of kicks a
bucket again this is
overfitting that's always an issue when
you're running on uh programming these
different neural
networks and then we're going to goad
ahead and plot the accuracy um history
we built that nice little sub routine up
above so we might as well use it and you
can see it right
here um there's that crossover
again and if you look at this look how
the how the um uh the red shifts up how
the uh our loss functions and everything
crosses over we're overfitting after one
Epic um we're
clearly not helping the problem or doing
better um we're just going to it's just
going to Baseline this one actually
shows with the training versus the
loss um value loss maybe second epic so
on here we're now talking more between
the first and the SE second epic and and
that also shows kind of here so
somewhere in here it starts
overfitting and right about now you
should be saying uhoh uh something went
wrong there I thought that um when we
went up here and ran this look at this
we have the accur accy up here is
hitting that
48% and we're down here
um you look at the score down here that
looks closer to 20% not nearly anywhere
in the ballpark of what we're looking
for and we'll go ahead and run it
through the uh the actual test features
here and and there it is um we actually
run this on the Unseen data and
everything uh8 or
18% um I don't know about you but I
wouldn't want you know at 18% this did a
lot worse than the other one I thought
this is supposed to be the super model
the model that beats all models the
vgg16 that won the awards and everything
well the reason is is that um one we're
not pre-processing the data uh so it
needs to be more there needs to be more
um as far as like rotating the data at
you know you know 45 angle taking
partials of it so you can create a lot
more data to go through here um and that
would actually greatly changed the
outcome on here and then we went up here
we only added a couple dense layers um
we added a couple convolutional neural
networks this huge pre-trained setup is
looking for a lot more information
coming in as far as how it's going to
train and so uh this is one of those
things where I thought it would have
done better and I had to go back and
research it and look at it and say why
didn't this work why am I getting only
uh 18% here instead of 44% or better and
that would be wise it doesn't have
enough training data coming in uh and
again you can make your own training
data so it's not that we have a shortage
of data it's that that some of that has
to be switched around and moved around a
little bit and this is interesting right
here too if you look at the
Precision we're getting it on number two
and yet we had zero on everything else
else so for some reason is not
seeing uh the different variables in
here so it'd be something else to look
in and try to F track down um and that
probably has to do with the input but
you can see right here we have a really
good solid Point 48 up here uh and
that's where I'd really go with is
starting with this model and then we
look at this model and find out why are
these numbers not coming up better is it
the data coming in um where's the setup
on there and that is the artart of data
science right there is finding out which
models work better and why and we went
through the very basics of convolutional
neural networks along with the vgg16
import and how you can get started with
that and again the art is the data going
in and learning to play with it find out
what works and that wraps up today's
episode of our neural Netto crash course
I hope you found it insightful and It
sped your curiosity to learn more don't
forget to like subscribe and hit the
Bell icon so you won't won't miss any of
our upcoming episodes we have got a lot
more exciting content lined up where we
will delve deeper into the world of
neural networks if you have any
questions or topics you would like us to
cover leave a comment below and for
additional resources and reading
materials check out the description box
thanks for watching and we'll see you in
the next episode of a neural network
crash course keep learning and stay
curious staying ahead in your career
requires continuous learning and
upskilling whether you're a student
aiming to learn today's top skills or a
working professional looking to advance
your career we've got you covered
explore our impressive catalog of
certification programs in cuttingedge
domains including data science cloud
computing cyber security AI machine
learning or digital marketing designed
in collaboration with leading
universities and top corporations and
delivered by industry experts choose any
any of our programs and set yourself on
the path to Career Success click the
link in the description to know
more hi there if you like this video
subscribe to the simply learn YouTube
channel and click here to watch similar
videos to nerd up and get certified
click
here